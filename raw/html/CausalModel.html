<!DOCTYPE html>
<!-- saved from url=(0054)https://en.wikipedia.org/wiki/Causal_model#Do_calculus -->
<html class="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-enabled vector-feature-sticky-header-disabled vector-feature-page-tools-disabled vector-feature-page-tools-pinned-disabled vector-feature-main-menu-pinned-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled vector-animations-ready ve-available" lang="en" dir="ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Causal model - Wikipedia</title>
<script>document.documentElement.className="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-enabled vector-feature-sticky-header-disabled vector-feature-page-tools-disabled vector-feature-page-tools-pinned-disabled vector-feature-main-menu-pinned-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled";(function(){var cookie=document.cookie.match(/(?:^|; )enwikimwclientprefs=([^;]+)/);if(cookie){var featureName=cookie[1];document.documentElement.className=document.documentElement.className.replace(featureName+'-enabled',featureName+'-disabled');}}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"3bf7f33c-f9da-49e4-b6ca-0debf0c97c95",
"wgCSPNonce":false,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Causal_model","wgTitle":"Causal model","wgCurRevisionId":1134560543,"wgRevisionId":1134560543,"wgArticleId":6672748,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","Articles with short description","Short description is different from Wikidata","Wikipedia articles needing rewrite from March 2020","All articles needing rewrite","Wikipedia articles needing clarification from January 2019","Causal diagrams","Causality","Formal epistemology","Scientific models"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Causal_model","wgRelevantArticleId":6672748,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgVisualEditor":{
"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist":true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":50000,"wgNoticeProject":"wikipedia","wgVector2022PreviewPages":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":10,"wgULSCurrentAutonym":"English","wgEditSubmitButtonLabelPublish":true,"wgCentralAuthMobileDomain":false,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":true,"wgULSisLanguageSelectorEmpty":false,"wgWikibaseItemId":"Q5054567","GEHomepageSuggestedEditsEnableTopics":true,"wgGETopicsMatchModeEnabled":false,"wgGEStructuredTaskRejectionReasonTextInputEnabled":false};RLSTATE={"skins.vector.user.styles":"ready","ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","skins.vector.user":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading",
"ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.ui.button":"ready","skins.vector.styles":"ready","skins.vector.icons":"ready","mediawiki.ui.icon":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.wikimediaBadges":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","ext.scribunto.logs","site","mediawiki.page.ready","mediawiki.toc","skins.vector.js","skins.vector.es6","mmv.head","mmv.bootstrap.autostart","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.cx.eventlogging.campaigns","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","ext.popups","ext.echo.centralauth","ext.uls.compactlinks","ext.uls.interface",
"ext.cx.uls.quick.actions","wikibase.client.vector-2022","ext.growthExperiments.SuggestedEditSession"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});});});</script>
<link rel="stylesheet" href="./Causal model - Wikipedia_files/load.php">
<script async="" src="./Causal model - Wikipedia_files/load(1).php"></script>
<style>
.mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{  font-size:13px;  -moz-tab-size:4; tab-size:4; }.mw-editfont-monospace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textInputWidget{font-size:inherit}.mw-editfont-monospace.oo-ui-textInputWidget > .oo-ui-inputWidget-input,.mw-editfont-sans-serif.oo-ui-textInputWidget > .oo-ui-inputWidget-input,.mw-editfont-serif.oo-ui-textInputWidget > .oo-ui-inputWidget-input{  font-size:13px}.mw-editfont-monospace.oo-ui-textInputWidget > input.oo-ui-inputWidget-input,.mw-editfont-sans-serif.oo-ui-textInputWidget > input.oo-ui-inputWidget-input,.mw-editfont-serif.oo-ui-textInputWidget > input.oo-ui-inputWidget-input{min-height:32px}
.oo-ui-icon-add,.mw-ui-icon-add:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=add&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E add %3C/title%3E%3Cpath d=%22M11 9V4H9v5H4v2h5v5h2v-5h5V9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-add,.mw-ui-icon-add-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=add&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E add %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M11 9V4H9v5H4v2h5v5h2v-5h5V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-add,.mw-ui-icon-add-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=add&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E add %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M11 9V4H9v5H4v2h5v5h2v-5h5V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-browser,.mw-ui-icon-browser:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=browser&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E browser %3C/title%3E%3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5zM18 16H2V8h16z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-browser,.mw-ui-icon-browser-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=browser&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E browser %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5zM18 16H2V8h16z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-browser,.mw-ui-icon-browser-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=browser&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E browser %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5zM18 16H2V8h16z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-cancel,.mw-ui-icon-cancel:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=cancel&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zM2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10zm14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-cancel,.mw-ui-icon-cancel-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=cancel&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zM2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10zm14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-cancel,.mw-ui-icon-cancel-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=cancel&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zM2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10zm14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-cancel,.mw-ui-icon-cancel-destructive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=cancel&variant=destructive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cg fill=%22%23d33%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zM2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10zm14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-check,.mw-ui-icon-check:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=check&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-check,.mw-ui-icon-check-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=check&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-check,.mw-ui-icon-check-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=check&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-check,.mw-ui-icon-check-destructive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=check&variant=destructive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%23d33%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-success.oo-ui-icon-check,.mw-ui-icon-check-success:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=check&variant=success&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%2314866d%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-checkAll,.mw-ui-icon-checkAll:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=checkAll&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check all %3C/title%3E%3Cpath d=%22m.29 12.71 1.42-1.42 2.22 2.22 8.3-10.14 1.54 1.26-9.7 11.86zM12 10h5v2h-5zm-3 4h5v2H9zm6-8h5v2h-5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-checkAll,.mw-ui-icon-checkAll-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=checkAll&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check all %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22m.29 12.71 1.42-1.42 2.22 2.22 8.3-10.14 1.54 1.26-9.7 11.86zM12 10h5v2h-5zm-3 4h5v2H9zm6-8h5v2h-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-checkAll,.mw-ui-icon-checkAll-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=checkAll&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check all %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22m.29 12.71 1.42-1.42 2.22 2.22 8.3-10.14 1.54 1.26-9.7 11.86zM12 10h5v2h-5zm-3 4h5v2H9zm6-8h5v2h-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-clear,.mw-ui-icon-clear:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=clear&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clear %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm5.66 14.24-1.41 1.41L10 11.41l-4.24 4.25-1.42-1.42L8.59 10 4.34 5.76l1.42-1.42L10 8.59l4.24-4.24 1.41 1.41L11.41 10z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-clear,.mw-ui-icon-clear-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=clear&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clear %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm5.66 14.24-1.41 1.41L10 11.41l-4.24 4.25-1.42-1.42L8.59 10 4.34 5.76l1.42-1.42L10 8.59l4.24-4.24 1.41 1.41L11.41 10z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-clear,.mw-ui-icon-clear-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=clear&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clear %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm5.66 14.24-1.41 1.41L10 11.41l-4.24 4.25-1.42-1.42L8.59 10 4.34 5.76l1.42-1.42L10 8.59l4.24-4.24 1.41 1.41L11.41 10z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-clock,.mw-ui-icon-clock:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=clock&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clock %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm2.5 14.5L9 11V4h2v6l3 3z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-clock,.mw-ui-icon-clock-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=clock&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clock %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm2.5 14.5L9 11V4h2v6l3 3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-clock,.mw-ui-icon-clock-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=clock&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clock %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm2.5 14.5L9 11V4h2v6l3 3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-close,.mw-ui-icon-close:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=close&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E close %3C/title%3E%3Cpath d=%22m4.3 2.9 12.8 12.8-1.4 1.4L2.9 4.3z%22/%3E%3Cpath d=%22M17.1 4.3 4.3 17.1l-1.4-1.4L15.7 2.9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-close,.mw-ui-icon-close-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=close&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E close %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22m4.3 2.9 12.8 12.8-1.4 1.4L2.9 4.3z%22/%3E%3Cpath d=%22M17.1 4.3 4.3 17.1l-1.4-1.4L15.7 2.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-close,.mw-ui-icon-close-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=close&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E close %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22m4.3 2.9 12.8 12.8-1.4 1.4L2.9 4.3z%22/%3E%3Cpath d=%22M17.1 4.3 4.3 17.1l-1.4-1.4L15.7 2.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-ellipsis,.mw-ui-icon-ellipsis:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=ellipsis&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E ellipsis %3C/title%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%223%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2217%22 cy=%2210%22 r=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-ellipsis,.mw-ui-icon-ellipsis-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=ellipsis&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E ellipsis %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%223%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2217%22 cy=%2210%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-ellipsis,.mw-ui-icon-ellipsis-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=ellipsis&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E ellipsis %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%223%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2217%22 cy=%2210%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-feedback,.mw-ui-icon-feedback:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=feedback&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E feedback %3C/title%3E%3Cpath d=%22M19 16 2 12a3.83 3.83 0 0 1-1-2.5A3.83 3.83 0 0 1 2 7l17-4z%22/%3E%3Crect width=%224%22 height=%228%22 x=%224%22 y=%229%22 rx=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-feedback,.mw-ui-icon-feedback-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=feedback&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E feedback %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M19 16 2 12a3.83 3.83 0 0 1-1-2.5A3.83 3.83 0 0 1 2 7l17-4z%22/%3E%3Crect width=%224%22 height=%228%22 x=%224%22 y=%229%22 rx=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-feedback,.mw-ui-icon-feedback-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=feedback&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E feedback %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M19 16 2 12a3.83 3.83 0 0 1-1-2.5A3.83 3.83 0 0 1 2 7l17-4z%22/%3E%3Crect width=%224%22 height=%228%22 x=%224%22 y=%229%22 rx=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-funnel,.mw-ui-icon-funnel:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=funnel&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-funnel,.mw-ui-icon-funnel-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=funnel&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-funnel,.mw-ui-icon-funnel-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=funnel&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-funnel,.mw-ui-icon-funnel-destructive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=funnel&variant=destructive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cg fill=%22%23d33%22%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-hand,.mw-ui-icon-hand:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=hand&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-hand,.mw-ui-icon-hand-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=hand&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-hand,.mw-ui-icon-hand-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=hand&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-hand,.mw-ui-icon-hand-destructive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=hand&variant=destructive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cg fill=%22%23d33%22%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-heart,.mw-ui-icon-heart:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=heart&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E heart %3C/title%3E%3Cpath d=%22M14.75 1A5.24 5.24 0 0 0 10 4 5.24 5.24 0 0 0 0 6.25C0 11.75 10 19 10 19s10-7.25 10-12.75A5.25 5.25 0 0 0 14.75 1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-heart,.mw-ui-icon-heart-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=heart&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E heart %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M14.75 1A5.24 5.24 0 0 0 10 4 5.24 5.24 0 0 0 0 6.25C0 11.75 10 19 10 19s10-7.25 10-12.75A5.25 5.25 0 0 0 14.75 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-heart,.mw-ui-icon-heart-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=heart&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E heart %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M14.75 1A5.24 5.24 0 0 0 10 4 5.24 5.24 0 0 0 0 6.25C0 11.75 10 19 10 19s10-7.25 10-12.75A5.25 5.25 0 0 0 14.75 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-help,.mw-ui-icon-help:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=help&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cpath d=%22M10.06 1C13 1 15 2.89 15 5.53a4.59 4.59 0 0 1-2.29 4.08c-1.42.92-1.82 1.53-1.82 2.71V13H8.38v-.81a3.84 3.84 0 0 1 2-3.84c1.34-.9 1.79-1.53 1.79-2.71a2.1 2.1 0 0 0-2.08-2.14h-.17a2.3 2.3 0 0 0-2.38 2.22v.17H5A4.71 4.71 0 0 1 9.51 1a5 5 0 0 1 .55 0z%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-help,.mw-ui-icon-help-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=help&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10.06 1C13 1 15 2.89 15 5.53a4.59 4.59 0 0 1-2.29 4.08c-1.42.92-1.82 1.53-1.82 2.71V13H8.38v-.81a3.84 3.84 0 0 1 2-3.84c1.34-.9 1.79-1.53 1.79-2.71a2.1 2.1 0 0 0-2.08-2.14h-.17a2.3 2.3 0 0 0-2.38 2.22v.17H5A4.71 4.71 0 0 1 9.51 1a5 5 0 0 1 .55 0z%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-help,.mw-ui-icon-help-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=help&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10.06 1C13 1 15 2.89 15 5.53a4.59 4.59 0 0 1-2.29 4.08c-1.42.92-1.82 1.53-1.82 2.71V13H8.38v-.81a3.84 3.84 0 0 1 2-3.84c1.34-.9 1.79-1.53 1.79-2.71a2.1 2.1 0 0 0-2.08-2.14h-.17a2.3 2.3 0 0 0-2.38 2.22v.17H5A4.71 4.71 0 0 1 9.51 1a5 5 0 0 1 .55 0z%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-helpNotice,.mw-ui-icon-helpNotice:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=helpNotice&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm1 16H9v-2h2zm2.71-7.6a2.64 2.64 0 0 1-.33.74 3.16 3.16 0 0 1-.48.55l-.54.48c-.21.18-.41.35-.58.52a2.54 2.54 0 0 0-.47.56A2.3 2.3 0 0 0 11 12a3.79 3.79 0 0 0-.11 1H9.08a8.9 8.9 0 0 1 .07-1.25 3.28 3.28 0 0 1 .25-.9 2.79 2.79 0 0 1 .41-.67 4 4 0 0 1 .58-.58c.17-.16.34-.3.51-.44a3 3 0 0 0 .43-.44 1.83 1.83 0 0 0 .3-.55 2 2 0 0 0 .11-.72 2.06 2.06 0 0 0-.17-.86 1.71 1.71 0 0 0-1-.9 1.7 1.7 0 0 0-.5-.1 1.77 1.77 0 0 0-1.53.68 3 3 0 0 0-.5 1.82H6.16a4.74 4.74 0 0 1 .28-1.68 3.56 3.56 0 0 1 .8-1.29 3.88 3.88 0 0 1 1.28-.83A4.59 4.59 0 0 1 10.18 4a4.44 4.44 0 0 1 1.44.23 3.51 3.51 0 0 1 1.15.65 3.08 3.08 0 0 1 .78 1.06 3.54 3.54 0 0 1 .29 1.45 3.39 3.39 0 0 1-.13 1.01z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-helpNotice,.mw-ui-icon-helpNotice-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=helpNotice&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm1 16H9v-2h2zm2.71-7.6a2.64 2.64 0 0 1-.33.74 3.16 3.16 0 0 1-.48.55l-.54.48c-.21.18-.41.35-.58.52a2.54 2.54 0 0 0-.47.56A2.3 2.3 0 0 0 11 12a3.79 3.79 0 0 0-.11 1H9.08a8.9 8.9 0 0 1 .07-1.25 3.28 3.28 0 0 1 .25-.9 2.79 2.79 0 0 1 .41-.67 4 4 0 0 1 .58-.58c.17-.16.34-.3.51-.44a3 3 0 0 0 .43-.44 1.83 1.83 0 0 0 .3-.55 2 2 0 0 0 .11-.72 2.06 2.06 0 0 0-.17-.86 1.71 1.71 0 0 0-1-.9 1.7 1.7 0 0 0-.5-.1 1.77 1.77 0 0 0-1.53.68 3 3 0 0 0-.5 1.82H6.16a4.74 4.74 0 0 1 .28-1.68 3.56 3.56 0 0 1 .8-1.29 3.88 3.88 0 0 1 1.28-.83A4.59 4.59 0 0 1 10.18 4a4.44 4.44 0 0 1 1.44.23 3.51 3.51 0 0 1 1.15.65 3.08 3.08 0 0 1 .78 1.06 3.54 3.54 0 0 1 .29 1.45 3.39 3.39 0 0 1-.13 1.01z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-helpNotice,.mw-ui-icon-helpNotice-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=helpNotice&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0zm1 16H9v-2h2zm2.71-7.6a2.64 2.64 0 0 1-.33.74 3.16 3.16 0 0 1-.48.55l-.54.48c-.21.18-.41.35-.58.52a2.54 2.54 0 0 0-.47.56A2.3 2.3 0 0 0 11 12a3.79 3.79 0 0 0-.11 1H9.08a8.9 8.9 0 0 1 .07-1.25 3.28 3.28 0 0 1 .25-.9 2.79 2.79 0 0 1 .41-.67 4 4 0 0 1 .58-.58c.17-.16.34-.3.51-.44a3 3 0 0 0 .43-.44 1.83 1.83 0 0 0 .3-.55 2 2 0 0 0 .11-.72 2.06 2.06 0 0 0-.17-.86 1.71 1.71 0 0 0-1-.9 1.7 1.7 0 0 0-.5-.1 1.77 1.77 0 0 0-1.53.68 3 3 0 0 0-.5 1.82H6.16a4.74 4.74 0 0 1 .28-1.68 3.56 3.56 0 0 1 .8-1.29 3.88 3.88 0 0 1 1.28-.83A4.59 4.59 0 0 1 10.18 4a4.44 4.44 0 0 1 1.44.23 3.51 3.51 0 0 1 1.15.65 3.08 3.08 0 0 1 .78 1.06 3.54 3.54 0 0 1 .29 1.45 3.39 3.39 0 0 1-.13 1.01z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-home,.mw-ui-icon-home:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=home&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E home %3C/title%3E%3Cpath d=%22M10 1 0 10h3v9h4v-4.6c0-1.47 1.31-2.66 3-2.66s3 1.19 3 2.66V19h4v-9h3L10 1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-home,.mw-ui-icon-home-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=home&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E home %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 1 0 10h3v9h4v-4.6c0-1.47 1.31-2.66 3-2.66s3 1.19 3 2.66V19h4v-9h3L10 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-home,.mw-ui-icon-home-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=home&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E home %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 1 0 10h3v9h4v-4.6c0-1.47 1.31-2.66 3-2.66s3 1.19 3 2.66V19h4v-9h3L10 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-key,.mw-ui-icon-key:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=key&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E key %3C/title%3E%3Cpath d=%22M15 6a1.54 1.54 0 0 1-1.5-1.5 1.5 1.5 0 0 1 3 0A1.54 1.54 0 0 1 15 6zm-1.5-5A5.55 5.55 0 0 0 8 6.5a6.81 6.81 0 0 0 .7 2.8L1 17v2h4v-2h2v-2h2l3.2-3.2a5.85 5.85 0 0 0 1.3.2A5.55 5.55 0 0 0 19 6.5 5.55 5.55 0 0 0 13.5 1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-key,.mw-ui-icon-key-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=key&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E key %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M15 6a1.54 1.54 0 0 1-1.5-1.5 1.5 1.5 0 0 1 3 0A1.54 1.54 0 0 1 15 6zm-1.5-5A5.55 5.55 0 0 0 8 6.5a6.81 6.81 0 0 0 .7 2.8L1 17v2h4v-2h2v-2h2l3.2-3.2a5.85 5.85 0 0 0 1.3.2A5.55 5.55 0 0 0 19 6.5 5.55 5.55 0 0 0 13.5 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-key,.mw-ui-icon-key-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=key&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E key %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M15 6a1.54 1.54 0 0 1-1.5-1.5 1.5 1.5 0 0 1 3 0A1.54 1.54 0 0 1 15 6zm-1.5-5A5.55 5.55 0 0 0 8 6.5a6.81 6.81 0 0 0 .7 2.8L1 17v2h4v-2h2v-2h2l3.2-3.2a5.85 5.85 0 0 0 1.3.2A5.55 5.55 0 0 0 19 6.5 5.55 5.55 0 0 0 13.5 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-keyboard,.mw-ui-icon-keyboard:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=keyboard&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E keyboard %3C/title%3E%3Cpath d=%22M0 15a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H2a2 2 0 0 0-2 2zm9-9h2v2H9zm0 3h2v2H9zM6 6h2v2H6zm0 3h2v2H6zm-1 5H3v-2h2zm0-3H3V9h2zm0-3H3V6h2zm9 6H6v-2h8zm0-3h-2V9h2zm0-3h-2V6h2zm3 6h-2v-2h2zm0-3h-2V9h2zm0-3h-2V6h2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-keyboard,.mw-ui-icon-keyboard-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=keyboard&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E keyboard %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M0 15a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H2a2 2 0 0 0-2 2zm9-9h2v2H9zm0 3h2v2H9zM6 6h2v2H6zm0 3h2v2H6zm-1 5H3v-2h2zm0-3H3V9h2zm0-3H3V6h2zm9 6H6v-2h8zm0-3h-2V9h2zm0-3h-2V6h2zm3 6h-2v-2h2zm0-3h-2V9h2zm0-3h-2V6h2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-keyboard,.mw-ui-icon-keyboard-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=keyboard&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E keyboard %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M0 15a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H2a2 2 0 0 0-2 2zm9-9h2v2H9zm0 3h2v2H9zM6 6h2v2H6zm0 3h2v2H6zm-1 5H3v-2h2zm0-3H3V9h2zm0-3H3V6h2zm9 6H6v-2h8zm0-3h-2V9h2zm0-3h-2V6h2zm3 6h-2v-2h2zm0-3h-2V9h2zm0-3h-2V6h2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-lightbulb,.mw-ui-icon-lightbulb:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=lightbulb&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E lightbulb %3C/title%3E%3Cpath d=%22M8 19a1 1 0 0 0 1 1h2a1 1 0 0 0 1-1v-1H8zm9-12a7 7 0 1 0-12 4.9S7 14 7 15v1a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1c0-1 2-3.1 2-3.1A7 7 0 0 0 17 7z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-lightbulb,.mw-ui-icon-lightbulb-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=lightbulb&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E lightbulb %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M8 19a1 1 0 0 0 1 1h2a1 1 0 0 0 1-1v-1H8zm9-12a7 7 0 1 0-12 4.9S7 14 7 15v1a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1c0-1 2-3.1 2-3.1A7 7 0 0 0 17 7z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-lightbulb,.mw-ui-icon-lightbulb-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=lightbulb&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E lightbulb %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M8 19a1 1 0 0 0 1 1h2a1 1 0 0 0 1-1v-1H8zm9-12a7 7 0 1 0-12 4.9S7 14 7 15v1a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1c0-1 2-3.1 2-3.1A7 7 0 0 0 17 7z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-logIn,.mw-ui-icon-logIn:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=logIn&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log in %3C/title%3E%3Cpath d=%22M1 11v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V3c0-1.1-.9-2-2-2H3c-1.1 0-2 .9-2 2v6h8V5l4.75 5L9 15v-4H1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-logIn,.mw-ui-icon-logIn-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=logIn&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log in %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M1 11v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V3c0-1.1-.9-2-2-2H3c-1.1 0-2 .9-2 2v6h8V5l4.75 5L9 15v-4H1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-logIn,.mw-ui-icon-logIn-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=logIn&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log in %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M1 11v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V3c0-1.1-.9-2-2-2H3c-1.1 0-2 .9-2 2v6h8V5l4.75 5L9 15v-4H1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-logOut,.mw-ui-icon-logOut:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=logOut&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log out %3C/title%3E%3Cpath d=%22M3 3h8V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h8v-2H3z%22/%3E%3Cpath d=%22M13 5v4H5v2h8v4l6-5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-logOut,.mw-ui-icon-logOut-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=logOut&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log out %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M3 3h8V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h8v-2H3z%22/%3E%3Cpath d=%22M13 5v4H5v2h8v4l6-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-logOut,.mw-ui-icon-logOut-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=logOut&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log out %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M3 3h8V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h8v-2H3z%22/%3E%3Cpath d=%22M13 5v4H5v2h8v4l6-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-network,.mw-ui-icon-network:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=network&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network %3C/title%3E%3Ccircle cx=%2210%22 cy=%2215%22 r=%222%22/%3E%3Cpath d=%22M1 7.4a12 13 0 0 1 18 0l-1.5 1.4a10 11.1 0 0 0-15 0zm3.7 3.2a7 7.3 0 0 1 10.7 0L14 12a5 5.3 0 0 0-7.8 0z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-network,.mw-ui-icon-network-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=network&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2215%22 r=%222%22/%3E%3Cpath d=%22M1 7.4a12 13 0 0 1 18 0l-1.5 1.4a10 11.1 0 0 0-15 0zm3.7 3.2a7 7.3 0 0 1 10.7 0L14 12a5 5.3 0 0 0-7.8 0z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-network,.mw-ui-icon-network-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=network&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2215%22 r=%222%22/%3E%3Cpath d=%22M1 7.4a12 13 0 0 1 18 0l-1.5 1.4a10 11.1 0 0 0-15 0zm3.7 3.2a7 7.3 0 0 1 10.7 0L14 12a5 5.3 0 0 0-7.8 0z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-networkOff,.mw-ui-icon-networkOff:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=networkOff&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network off %3C/title%3E%3Ccircle cx=%2210%22 cy=%2216%22 r=%222%22/%3E%3Cpath d=%22M16.4 11.6A7.1 7.1 0 0 0 12 9.1l3.4 3.4zM19 8.4A12.2 14 0 0 0 8.2 4.2L10 6a9.9 9.9 0 0 1 7.4 3.7zM3.5 2 2 3.4l2.2 2.2A13.1 13.1 0 0 0 1 8.4l1.5 1.3a10.7 10.7 0 0 1 3.2-2.6L8 9.3a7.3 7.3 0 0 0-3.3 2.3L6.1 13a5.2 5.2 0 0 1 3.6-2l6.8 7 1.5-1.5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-networkOff,.mw-ui-icon-networkOff-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=networkOff&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network off %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2216%22 r=%222%22/%3E%3Cpath d=%22M16.4 11.6A7.1 7.1 0 0 0 12 9.1l3.4 3.4zM19 8.4A12.2 14 0 0 0 8.2 4.2L10 6a9.9 9.9 0 0 1 7.4 3.7zM3.5 2 2 3.4l2.2 2.2A13.1 13.1 0 0 0 1 8.4l1.5 1.3a10.7 10.7 0 0 1 3.2-2.6L8 9.3a7.3 7.3 0 0 0-3.3 2.3L6.1 13a5.2 5.2 0 0 1 3.6-2l6.8 7 1.5-1.5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-networkOff,.mw-ui-icon-networkOff-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=networkOff&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network off %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2216%22 r=%222%22/%3E%3Cpath d=%22M16.4 11.6A7.1 7.1 0 0 0 12 9.1l3.4 3.4zM19 8.4A12.2 14 0 0 0 8.2 4.2L10 6a9.9 9.9 0 0 1 7.4 3.7zM3.5 2 2 3.4l2.2 2.2A13.1 13.1 0 0 0 1 8.4l1.5 1.3a10.7 10.7 0 0 1 3.2-2.6L8 9.3a7.3 7.3 0 0 0-3.3 2.3L6.1 13a5.2 5.2 0 0 1 3.6-2l6.8 7 1.5-1.5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-newWindow,.mw-ui-icon-newWindow:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=newWindow&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E new window %3C/title%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.3 3.3L8.6 10l1.4 1.4 5.7-5.7L19 9V1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-newWindow,.mw-ui-icon-newWindow-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=newWindow&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E new window %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.3 3.3L8.6 10l1.4 1.4 5.7-5.7L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-newWindow,.mw-ui-icon-newWindow-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=newWindow&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E new window %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.3 3.3L8.6 10l1.4 1.4 5.7-5.7L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-pageSettings,.mw-ui-icon-pageSettings:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=pageSettings&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E page settings %3C/title%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%221.75%22/%3E%3Cpath d=%22M15 1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2zm0 9.75-1.37.25a3.73 3.73 0 0 1-.38.93l.82 1.07L13 14.07l-1.12-.82a3.73 3.73 0 0 1-.93.38l-.2 1.37h-1.5L9 13.63a3.73 3.73 0 0 1-.93-.38L7 14.07 5.93 13l.82-1.12a3.73 3.73 0 0 1-.38-.88L5 10.75v-1.5L6.37 9a3.72 3.72 0 0 1 .38-.93L5.93 7 7 5.93l1.12.82A3.73 3.73 0 0 1 9 6.37L9.25 5h1.5L11 6.37a3.74 3.74 0 0 1 .93.38L13 5.93 14.07 7l-.82 1.12a3.73 3.73 0 0 1 .38.93l1.37.2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-pageSettings,.mw-ui-icon-pageSettings-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=pageSettings&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E page settings %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%221.75%22/%3E%3Cpath d=%22M15 1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2zm0 9.75-1.37.25a3.73 3.73 0 0 1-.38.93l.82 1.07L13 14.07l-1.12-.82a3.73 3.73 0 0 1-.93.38l-.2 1.37h-1.5L9 13.63a3.73 3.73 0 0 1-.93-.38L7 14.07 5.93 13l.82-1.12a3.73 3.73 0 0 1-.38-.88L5 10.75v-1.5L6.37 9a3.72 3.72 0 0 1 .38-.93L5.93 7 7 5.93l1.12.82A3.73 3.73 0 0 1 9 6.37L9.25 5h1.5L11 6.37a3.74 3.74 0 0 1 .93.38L13 5.93 14.07 7l-.82 1.12a3.73 3.73 0 0 1 .38.93l1.37.2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-pageSettings,.mw-ui-icon-pageSettings-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=pageSettings&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E page settings %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%221.75%22/%3E%3Cpath d=%22M15 1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2zm0 9.75-1.37.25a3.73 3.73 0 0 1-.38.93l.82 1.07L13 14.07l-1.12-.82a3.73 3.73 0 0 1-.93.38l-.2 1.37h-1.5L9 13.63a3.73 3.73 0 0 1-.93-.38L7 14.07 5.93 13l.82-1.12a3.73 3.73 0 0 1-.38-.88L5 10.75v-1.5L6.37 9a3.72 3.72 0 0 1 .38-.93L5.93 7 7 5.93l1.12.82A3.73 3.73 0 0 1 9 6.37L9.25 5h1.5L11 6.37a3.74 3.74 0 0 1 .93.38L13 5.93 14.07 7l-.82 1.12a3.73 3.73 0 0 1 .38.93l1.37.2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-printer,.mw-ui-icon-printer:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=printer&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E printer %3C/title%3E%3Cpath d=%22M5 1h10v4H5zM3 6a2 2 0 0 0-2 2v7h4v4h10v-4h4V8a2 2 0 0 0-2-2zm11 12H6v-6h8zm2-8a1 1 0 1 1 1-1 1 1 0 0 1-1 1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-printer,.mw-ui-icon-printer-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=printer&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E printer %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M5 1h10v4H5zM3 6a2 2 0 0 0-2 2v7h4v4h10v-4h4V8a2 2 0 0 0-2-2zm11 12H6v-6h8zm2-8a1 1 0 1 1 1-1 1 1 0 0 1-1 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-printer,.mw-ui-icon-printer-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=printer&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E printer %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M5 1h10v4H5zM3 6a2 2 0 0 0-2 2v7h4v4h10v-4h4V8a2 2 0 0 0-2-2zm11 12H6v-6h8zm2-8a1 1 0 1 1 1-1 1 1 0 0 1-1 1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-reload,.mw-ui-icon-reload:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=reload&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E reload %3C/title%3E%3Cpath d=%22M15.65 4.35A8 8 0 1 0 17.4 13h-2.22a6 6 0 1 1-1-7.22L11 9h7V2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-reload,.mw-ui-icon-reload-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=reload&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E reload %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M15.65 4.35A8 8 0 1 0 17.4 13h-2.22a6 6 0 1 1-1-7.22L11 9h7V2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-reload,.mw-ui-icon-reload-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=reload&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E reload %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M15.65 4.35A8 8 0 1 0 17.4 13h-2.22a6 6 0 1 1-1-7.22L11 9h7V2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-search,.mw-ui-icon-search:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=search&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E search %3C/title%3E%3Cpath d=%22M12.2 13.6a7 7 0 1 1 1.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1 0 10 0A5 5 0 0 0 3 8z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-search,.mw-ui-icon-search-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=search&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E search %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M12.2 13.6a7 7 0 1 1 1.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1 0 10 0A5 5 0 0 0 3 8z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-search,.mw-ui-icon-search-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=search&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E search %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M12.2 13.6a7 7 0 1 1 1.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1 0 10 0A5 5 0 0 0 3 8z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-settings,.mw-ui-icon-settings:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=settings&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-settings,.mw-ui-icon-settings-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=settings&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cg xmlns:xlink=%22http://www.w3.org/1999/xlink%22 transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-settings,.mw-ui-icon-settings-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=settings&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cg xmlns:xlink=%22http://www.w3.org/1999/xlink%22 transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-subtract,.mw-ui-icon-subtract:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=subtract&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-subtract,.mw-ui-icon-subtract-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=subtract&variant=invert&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-subtract,.mw-ui-icon-subtract-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=subtract&variant=progressive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-subtract,.mw-ui-icon-subtract-destructive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-interactions&image=subtract&variant=destructive&format=rasterized&skin=vector-2022&version=15mgb);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cg fill=%22%23d33%22%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/g%3E%3C/svg%3E")}
.mw-ui-icon-wikimedia-speechBubbleAdd:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbleAdd&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbleAdd&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-speechBubbleAdd-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbleAdd&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbleAdd&variant=progressive&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-speechBubbles:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbles&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbles&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-speechBubbles-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbles&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbles&variant=progressive&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-article:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=article&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=article&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-article-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=article&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=article&variant=progressive&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-history:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=history&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=history&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-history-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=history&variant=progressive&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=history&variant=progressive&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-wikiText:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=wikiText&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=wikiText&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-wikiText-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=wikiText&variant=progressive&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=wikiText&variant=progressive&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-edit:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=edit&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=edit&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-edit-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=edit&variant=progressive&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=edit&variant=progressive&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-editLock:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=editLock&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=editLock&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-editLock-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=editLock&variant=progressive&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=editLock&variant=progressive&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-star:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=star&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=star&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-star-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=star&variant=progressive&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=star&variant=progressive&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-halfStar:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=halfStar&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=halfStar&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-halfStar-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=halfStar&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=halfStar&variant=progressive&format=original&lang=en&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-unStar:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=unStar&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=unStar&format=original&skin=vector-2022&version=141s3)}.mw-ui-icon-wikimedia-unStar-progressive:before{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=unStar&variant=progressive&format=rasterized&skin=vector-2022&version=141s3);background-image:linear-gradient(transparent,transparent),url(/w/load.php?modules=skins.vector.icons.js&image=unStar&variant=progressive&format=original&skin=vector-2022&version=141s3)}
.cite-accessibility-label{ top:-99999px;clip:rect(1px,1px,1px,1px); position:absolute !important;padding:0 !important;border:0 !important;height:1px !important;width:1px !important; overflow:hidden}:target .mw-cite-targeted-backlink{font-weight:bold}.mw-cite-up-arrow-backlink{display:none}:target .mw-cite-up-arrow-backlink{display:inline}:target .mw-cite-up-arrow{display:none}
.ve-init-mw-progressBarWidget{height:1em;overflow:hidden;margin:0 25%}.ve-init-mw-progressBarWidget-bar{height:1em;width:0} .ve-init-mw-progressBarWidget{background-color:#fff;box-sizing:border-box;height:0.875em;border:1px solid #36c;border-radius:0.875em;box-shadow:0 1px 1px rgba(0,0,0,0.15)}.ve-init-mw-progressBarWidget-bar{background-color:#36c;height:0.875em}
.scribunto-limitreport-logs{margin:0;white-space:pre-wrap}
.rt-tooltip{position:absolute;z-index:100;max-width:350px;background:#fff;color:#222;font-size:13px;line-height:1.5em;border:1px solid #c8ccd1;border-radius:3px;box-shadow:0 15px 45px -10px rgba(0,0,0,0.3);overflow-wrap:break-word}.rt-tooltip.rt-tooltip-insideWindow{z-index:110}.rt-tooltipContent{padding:8px 11px}.rt-tooltip-above .rt-tooltipContent{margin-bottom:-8px;padding-bottom:16px}.rt-tooltip-below .rt-tooltipContent{margin-top:-10px;padding-top:18px}.rt-tooltipTail,.rt-tooltipTail:after{position:absolute;width:12px;height:12px}.rt-tooltipTail{background:linear-gradient(to top right,#c8ccd1 50%,rgba(0,0,0,0) 50%)}.rt-tooltipTail:after{content:"";background:#fff;bottom:1px;left:1px}.rt-tooltip-above .rt-tooltipTail{transform:rotate(-45deg);transform-origin:100% 100%;bottom:0;left:15px}.rt-tooltip-below .rt-tooltipTail{transform:rotate(135deg);transform-origin:0 0;top:0;left:27px}.rt-settingsLink{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%2024%2024%22%3E%0D%0A%20%20%20%20%3Cpath%20fill%3D%22%23555%22%20d%3D%22M20%2014.5v-2.9l-1.8-.3c-.1-.4-.3-.8-.6-1.4l1.1-1.5-2.1-2.1-1.5%201.1c-.5-.3-1-.5-1.4-.6L13.5%205h-2.9l-.3%201.8c-.5.1-.9.3-1.4.6L7.4%206.3%205.3%208.4l1%201.5c-.3.5-.4.9-.6%201.4l-1.7.2v2.9l1.8.3c.1.5.3.9.6%201.4l-1%201.5%202.1%202.1%201.5-1c.4.2.9.4%201.4.6l.3%201.8h3l.3-1.8c.5-.1.9-.3%201.4-.6l1.5%201.1%202.1-2.1-1.1-1.5c.3-.5.5-1%20.6-1.4l1.5-.3zM12%2016c-1.7%200-3-1.3-3-3s1.3-3%203-3%203%201.3%203%203-1.3%203-3%203z%22%2F%3E%0D%0A%3C%2Fsvg%3E);float:right;cursor:pointer;margin:-4px -4px 0 8px;height:24px;width:24px;border-radius:2px;background-position:center center;background-repeat:no-repeat;background-size:24px 24px}.rt-settingsLink:hover{background-color:#eee}.rt-target{background-color:#def}.rt-enableSelect{font-weight:bold}.rt-settingsFormSeparator{margin:0.85714286em 0}.rt-numberInput.rt-numberInput{width:150px}.rt-tooltipsForCommentsField.rt-tooltipsForCommentsField.rt-tooltipsForCommentsField{margin-top:1.64285714em}.rt-disabledHelp{border-collapse:collapse}.rt-disabledHelp td{padding:0}.rt-disabledNote.rt-disabledNote{vertical-align:bottom;padding-left:0.36em;font-weight:bold}@keyframes rt-fade-in-up{0%{opacity:0;transform:translate(0,20px) }100%{opacity:1;transform:translate(0,0) }}@keyframes rt-fade-in-down{0%{opacity:0;transform:translate(0,-20px) }100%{opacity:1;transform:translate(0,0) }}@keyframes rt-fade-out-down{0%{opacity:1;transform:translate(0,0) }100%{opacity:0;transform:translate(0,20px) }}@keyframes rt-fade-out-up{0%{opacity:1;transform:translate(0,0) }100%{opacity:0;transform:translate(0,-20px) }}.rt-fade-in-up{animation:rt-fade-in-up 0.2s ease forwards }.rt-fade-in-down{animation:rt-fade-in-down 0.2s ease forwards }.rt-fade-out-down{animation:rt-fade-out-down 0.2s ease forwards }.rt-fade-out-up{animation:rt-fade-out-up 0.2s ease forwards }
@media screen {
	.toctoggle{-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;user-select:none;font-size:94%}}
@-webkit-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-webkit-transform:translateY(-20px)}100%{opacity:1;-webkit-transform:translateY(0)}}@keyframes centralAuthPPersonalAnimation{0%{opacity:0;transform:translateY(-20px)}100%{opacity:1;transform:translateY(0)}}.centralAuthPPersonalAnimation{-webkit-animation-duration:1s;animation-duration:1s;-webkit-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-name:centralAuthPPersonalAnimation;animation-name:centralAuthPPersonalAnimation}
.uls-menu{border-radius:2px; font-size:medium}.uls-search,.uls-language-settings-close-block{border-top-right-radius:2px;border-top-left-radius:2px}.uls-language-list{border-bottom-right-radius:2px;border-bottom-left-radius:2px}.uls-menu.callout:before,.uls-menu.callout:after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.uls-menu.callout.selector-right:before{ border-left:10px solid #c8ccd1; right:-11px}.uls-menu.callout.selector-right:after{ border-left:10px solid #fff; right:-10px}.uls-menu.callout.selector-left:before{ border-right:10px solid #c8ccd1; left:-11px}.uls-menu.callout.selector-left:after{ border-right:10px solid #fff; left:-10px}.uls-ui-languages button{margin:5px 15px 5px 0;white-space:nowrap;overflow:hidden}.uls-search-wrapper-wrapper{position:relative;padding-left:40px;margin-top:5px;margin-bottom:5px}.uls-icon-back{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/back-grey-ltr.svg?01868) no-repeat scroll center center;background-size:28px;height:32px;width:40px;display:block;position:absolute;left:0;border-right:1px solid #c8ccd1;opacity:0.8}.uls-icon-back:hover{opacity:1;cursor:pointer}.uls-menu .uls-no-results-view .uls-no-found-more{background-color:#fff}.uls-menu .uls-no-results-view h3{padding:0 28px;margin:0;color:#54595d;font-size:1em;font-weight:normal}   .skin-vector .uls-menu{border-color:#c8ccd1;box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);font-size:0.875em;z-index:3}.skin-vector .uls-search{border-bottom-color:#c8ccd1}.skin-vector .uls-search-label{opacity:0.51;transition:opacity 250ms}.skin-vector .uls-search-wrapper:hover .uls-search-label{opacity:0.87}.skin-vector .uls-filtersuggestion{color:#72777d}.skin-vector .uls-lcd-region-title{color:#54595d}
@media print{#centralNotice{display:none}}.cn-closeButton{display:inline-block;background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUBAMAAAB/pwA+AAAAElBMVEUAAAAQEBDPz88AAABAQEDv7+9oe1vvAAAABnRSTlMA3rLe3rJS22KzAAAARElEQVQI12PAAUIUQCSTK5BwFgIxFU1AhKECUFAYKAAioXwwBeZChMGCEGGQIFQYJohgIhQgtCEMQ7ECYTHCOciOxA4AADgJTXIb9s8AAAAASUVORK5CYII=) no-repeat;width:20px;height:20px;text-indent:20px;white-space:nowrap;overflow:hidden}
.mw-mmv-overlay{position:fixed;top:0;left:0;right:0;bottom:0;z-index:1000;background-color:#000}body.mw-mmv-lightbox-open{overflow-y:auto}body.mw-mmv-lightbox-open > *:not(.mw-notification-area-overlay){display:none}body.mw-mmv-lightbox-open > .mw-mmv-overlay,body.mw-mmv-lightbox-open > .mw-mmv-wrapper{display:block}.mw-mmv-filepage-buttons{margin-top:5px}.mw-mmv-filepage-buttons .mw-mmv-view-expanded,.mw-mmv-filepage-buttons .mw-mmv-view-config{display:block;line-height:inherit}.mw-mmv-filepage-buttons .mw-mmv-view-expanded .mw-ui-icon:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 1024 768%22%3E %3Cpath d=%22M851.2 71.6 690.7 232.1l-40.1-40.3-9.6 164.8 164.8-9.3-40.3-40.4L926 146.4l58.5 58.5L997.6 0 792.7 13.1%22/%3E %3Cpath d=%22M769.6 89.3H611.9l70.9 70.8 7.9 7.5m-47.1 234.6-51.2 3 3-51.2 9.4-164.4 5.8-100.3H26.4V768h883.1V387l-100.9 5.8-165 9.4zM813.9 678H113.6l207.2-270.2 31.5-12.9L548 599.8l105.9-63.2 159.8 140.8.2.6zm95.6-291.9V228l-79.1 78.9 7.8 7.9%22/%3E %3C/svg%3E")}.mw-mmv-filepage-buttons .mw-mmv-view-config .mw-ui-icon:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 1024 768%22%3E %3Cpath d=%22M897 454.6V313.4L810.4 299c-6.4-23.3-16-45.7-27.3-65.8l50.5-71.4-99.4-100.2-71.4 50.5c-20.9-11.2-42.5-20.9-65.8-27.3L582.6-1H441.4L427 85.6c-23.3 6.4-45.7 16-65.8 27.3l-71.4-50.5-100.3 99.5 50.5 71.4c-11.2 20.9-20.9 42.5-27.3 66.6L127 313.4v141.2l85.8 14.4c6.4 23.3 16 45.7 27.3 66.6L189.6 607l99.5 99.5 71.4-50.5c20.9 11.2 42.5 20.9 66.6 27.3l14.4 85.8h141.2l14.4-86.6c23.3-6.4 45.7-16 65.8-27.3l71.4 50.5 99.5-99.5-50.5-71.4c11.2-20.9 20.9-42.5 27.3-66.6l86.4-13.6zm-385 77c-81.8 0-147.6-66.6-147.6-147.6 0-81.8 66.6-147.6 147.6-147.6S659.6 302.2 659.6 384 593.8 531.6 512 531.6z%22/%3E %3C/svg%3E");margin-right:0;opacity:0.75}.mw-mmv-filepage-buttons .mw-mmv-view-config .mw-ui-icon:before:hover{opacity:1}.mw-mmv-filepage-buttons .mw-mmv-view-config .mw-ui-icon span{display:none}.mw-mmv-button{background-color:transparent;min-width:0;border:0;padding:0;overflow-x:hidden;text-indent:-9999em}
#uls-settings-block.uls-settings-block--vector-2022{display:flex;justify-content:space-between;padding:8px 12px}#uls-settings-block.uls-settings-block--vector-2022.row:before,#uls-settings-block.uls-settings-block--vector-2022.row:after{content:none}#uls-settings-block.uls-settings-block--vector-2022.uls-settings-block--with-add-languages{background-color:#f8f9fa;border-top:1px solid #c8ccd1}#uls-settings-block.uls-settings-block--vector-2022 > button.uls-add-languages-button{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/add.svg?3165e) no-repeat left center;margin-right:32px;padding-left:32px}#uls-settings-block.uls-settings-block--vector-2022 > button.uls-language-settings-button{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/cog.svg?d6cee) no-repeat center;margin-left:auto;min-width:unset;border:0}#uls-settings-block:not(.uls-settings-block--vector-2022){background-color:#f8f9fa;border-top:1px solid #c8ccd1;padding-left:10px;line-height:1.2em;border-radius:0 0 2px 2px}#uls-settings-block:not(.uls-settings-block--vector-2022) > button{background:left top transparent no-repeat;background-size:20px auto;color:#54595d;display:inline-block;margin:8px 15px;border:0;padding:0 0 0 26px;font-size:medium;cursor:pointer}#uls-settings-block:not(.uls-settings-block--vector-2022) > button:hover{color:#202122}#uls-settings-block:not(.uls-settings-block--vector-2022) > button.display-settings-block{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/display.svg?b78f7)}#uls-settings-block:not(.uls-settings-block--vector-2022) > button.input-settings-block{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/input.svg?e7c85)}.uls-tipsy.uls-tipsy{z-index:1000}.uls-empty-state{padding:28px}.uls-empty-state .uls-empty-state__header,.uls-empty-state .uls-empty-state__desc{color:#54595d}.uls-empty-state .uls-language-action-items{list-style:none;margin:1em 0}.empty-language-selector__language-settings-button{margin:12px}.uls-menu.uls-language-actions-dialog{min-width:248px}.uls-menu.uls-language-actions-dialog .uls-language-actions-title{border-bottom:1px solid #c8ccd1;display:flex;align-items:center;height:32px;padding:5px 0}.uls-menu.uls-language-actions-dialog .uls-language-actions-title .uls-language-actions-close{min-width:unset;width:44px;background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/arrow-previous.svg?279af) no-repeat center}.uls-menu.uls-language-actions-dialog .uls-language-action-items .uls-language-action.oo-ui-widget{margin:0;padding:12px 8px;display:block}.uls-menu.uls-language-actions-dialog .uls-language-action-items .uls-language-action.oo-ui-widget .oo-ui-buttonElement-button{padding-left:36px}.mw-interlanguage-selector-disabled #p-lang-btn-sticky-header{display:none}
.mw-ui-checkbox{display:table;position:relative;line-height:1.5625em;vertical-align:middle}.mw-ui-checkbox *{font-size:inherit;vertical-align:middle}.mw-ui-checkbox [type='checkbox']{display:table-cell;position:relative;width:1.5625em;height:1.5625em;max-width:none;opacity:0;z-index:1}.mw-ui-checkbox [type='checkbox'] + label{display:table-cell;padding-left:0.4em}.mw-ui-checkbox [type='checkbox'] + label:before{content:'';background-color:#fff;background-origin:border-box;background-position:center center;background-repeat:no-repeat;background-size:0 0;box-sizing:border-box;position:absolute;top:50%;left:0;width:1.5625em;height:1.5625em;margin-top:-0.78125em;border:1px solid #72777d;border-radius:2px}.mw-ui-checkbox [type='checkbox']:checked + label:before{background-image:url(/w/resources/src/mediawiki.ui.checkbox/images/checkbox-checked.svg?8153e);background-size:90% 90%}.mw-ui-checkbox [type='checkbox']:enabled{cursor:pointer}.mw-ui-checkbox [type='checkbox']:enabled + label{cursor:pointer}.mw-ui-checkbox [type='checkbox']:enabled + label:before{cursor:pointer;transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms}.mw-ui-checkbox [type='checkbox']:enabled:focus + label:before{border-color:#3366cc;box-shadow:inset 0 0 0 1px #3366cc}.mw-ui-checkbox [type='checkbox']:enabled:hover + label:before{border-color:#447ff5}.mw-ui-checkbox [type='checkbox']:enabled:active + label:before{background-color:#2a4b8d;border-color:#2a4b8d;box-shadow:inset 0 0 0 1px #2a4b8d}.mw-ui-checkbox [type='checkbox']:enabled:checked + label:before{background-color:#3366cc;border-color:#3366cc}.mw-ui-checkbox [type='checkbox']:enabled:checked:focus + label:before{background-color:#3366cc;border-color:#3366cc;box-shadow:inset 0 0 0 1px #3366cc,inset 0 0 0 2px #ffffff}.mw-ui-checkbox [type='checkbox']:enabled:checked:hover + label:before{background-color:#447ff5;border-color:#447ff5}.mw-ui-checkbox [type='checkbox']:enabled:checked:active + label:before{background-color:#2a4b8d;border-color:#2a4b8d}.mw-ui-checkbox [type='checkbox']:disabled + label:before{background-color:#c8ccd1;border-color:#c8ccd1}
.oo-ui-icon-infoFilled,.mw-ui-icon-infoFilled:before{background-image:url(/w/load.php?modules=ext.popups.icons&image=infoFilled&format=rasterized&lang=en&skin=vector-2022&version=1e4s5);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E info %3C/title%3E%3Cpath d=%22M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0zM9 5h2v2H9zm0 4h2v6H9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-infoFilled,.mw-ui-icon-infoFilled-invert:before{background-image:url(/w/load.php?modules=ext.popups.icons&image=infoFilled&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=1e4s5);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E info %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0zM9 5h2v2H9zm0 4h2v6H9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-infoFilled,.mw-ui-icon-infoFilled-progressive:before{background-image:url(/w/load.php?modules=ext.popups.icons&image=infoFilled&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=1e4s5);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E info %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0zM9 5h2v2H9zm0 4h2v6H9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-settings,.mw-ui-icon-settings:before{background-image:url(/w/load.php?modules=ext.popups.icons&image=settings&format=rasterized&skin=vector-2022&version=1e4s5);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-settings,.mw-ui-icon-settings-invert:before{background-image:url(/w/load.php?modules=ext.popups.icons&image=settings&variant=invert&format=rasterized&skin=vector-2022&version=1e4s5);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cg xmlns:xlink=%22http://www.w3.org/1999/xlink%22 transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-settings,.mw-ui-icon-settings-progressive:before{background-image:url(/w/load.php?modules=ext.popups.icons&image=settings&variant=progressive&format=rasterized&skin=vector-2022&version=1e4s5);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cg xmlns:xlink=%22http://www.w3.org/1999/xlink%22 transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/g%3E%3C/svg%3E")}
.mw-ui-icon-popups-close:before{background-image:url(/w/load.php?modules=ext.popups.images&image=popups-close&format=rasterized&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E close %3C/title%3E %3Cpath d=%22m4.34 2.93 12.73 12.73-1.41 1.41L2.93 4.35z%22/%3E %3Cpath d=%22M17.07 4.34 4.34 17.07l-1.41-1.41L15.66 2.93z%22/%3E %3C/svg%3E")}.mw-ui-icon-preview-generic:before{background-image:url(/w/load.php?modules=ext.popups.images&image=preview-generic&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E sad face %3C/title%3E %3Cpath d=%22M2 0a2 2 0 0 0-2 2v18l4-4h14a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2zm4 4c1.336 0 2.007 1.617 1.06 2.56-.943.947-2.56.276-2.56-1.06A1.5 1.5 0 0 1 6 4zm8 0c1.336 0 2.007 1.617 1.06 2.56-.943.947-2.56.276-2.56-1.06A1.5 1.5 0 0 1 14 4zm-4 5c2.61 0 4.83.67 5.65 3H4.35C5.17 9.67 7.39 9 10 9z%22/%3E %3C/svg%3E")}.mw-ui-icon-footer:before{background-image:url(/w/load.php?modules=ext.popups.images&image=footer&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%22230%22 height=%22179%22 viewBox=%220 0 230 179%22%3E %3Cdefs%3E %3Crect id=%22a%22 width=%22201%22 height=%2213%22 rx=%222%22/%3E %3Crect id=%22b%22 width=%22201%22 height=%22169%22 y=%2210%22 rx=%222%22/%3E %3Crect id=%22c%22 width=%2230%22 height=%222%22 x=%22135%22 y=%22158%22 rx=%221%22/%3E %3C/defs%3E %3Cg fill=%22none%22 fill-rule=%22evenodd%22%3E %3Cg transform=%22matrix%281 0 0 -1 0 13%29%22%3E %3Cuse xlink:href=%22%23a%22 fill=%22%23f8f9fa%22/%3E %3Crect width=%22199%22 height=%2211%22 x=%221%22 y=%221%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E %3C/g%3E %3Cuse xlink:href=%22%23b%22 fill=%22%23fff%22/%3E %3Crect width=%22199%22 height=%22167%22 x=%221%22 y=%2211%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E %3Cg fill=%22%2372777d%22 opacity=%22.4%22 transform=%22translate%2867 35%29%22%3E %3Crect width=%2273%22 height=%222%22 y=%227%22 fill=%22%23c8ccd1%22 rx=%221%22/%3E %3Crect width=%2281%22 height=%222%22 y=%2231%22 rx=%221%22/%3E %3Crect width=%2232%22 height=%222%22 y=%2285%22 rx=%221%22/%3E %3Crect width=%2273%22 height=%222%22 x=%2235%22 y=%2285%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 x=%2291%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2268%22 height=%222%22 x=%2220%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2237%22 height=%222%22 x=%2272%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2249%22 height=%222%22 x=%2220%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2224%22 height=%222%22 x=%2284%22 y=%2231%22 rx=%221%22 transform=%22matrix%28-1 0 0 1 192 0%29%22/%3E %3Crect width=%2281%22 height=%222%22 y=%2266%22 rx=%221%22/%3E %3Crect width=%2214%22 height=%222%22 x=%2254%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%2237%22 height=%222%22 x=%2271%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%2251%22 height=%222%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2259%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2252%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2292%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2238%22 rx=%221%22/%3E %3Crect width=%2251%22 height=%222%22 rx=%221%22/%3E %3C/g%3E %3Crect width=%2230%22 height=%222%22 x=%2267%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E %3Crect width=%2230%22 height=%222%22 x=%2299%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E %3Cuse xlink:href=%22%23c%22 fill=%22%2336c%22/%3E %3Crect width=%2233%22 height=%225%22 x=%22133.5%22 y=%22156.5%22 stroke=%22%23ffc057%22 stroke-opacity=%22.447%22 stroke-width=%223%22 rx=%222.5%22/%3E %3Ccircle cx=%2234%22 cy=%2249%22 r=%2219%22 fill=%22%23eaecf0%22/%3E %3Cg fill=%22%23a2a9b1%22 transform=%22translate%285 5%29%22%3E %3Ccircle cx=%221.5%22 cy=%221.5%22 r=%221.5%22/%3E %3Ccircle cx=%226%22 cy=%221.5%22 r=%221.5%22/%3E %3Ccircle cx=%2210.5%22 cy=%221.5%22 r=%221.5%22/%3E %3C/g%3E %3Cpath stroke=%22%23ff00af%22 stroke-linecap=%22square%22 d=%22M174.5 159.5h54.01%22/%3E %3C/g%3E %3C/svg%3E")}.mw-ui-icon-preview-disambiguation:before{background-image:url(/w/load.php?modules=ext.popups.images&image=preview-disambiguation&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E articles %3C/title%3E %3Cpath d=%22M5 0v2h11v14h2V2a2 2 0 0 0-2-2z%22/%3E %3Cpath d=%22M13 20a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H4a2 2 0 0 0-2 2v13a2 2 0 0 0 2 2zM9 5h4v5H9zM4 5h4v1H4zm0 2h4v1H4zm0 2h4v1H4zm0 2h9v1H4zm0 2h9v1H4zm0 2h9v1H4z%22/%3E %3C/svg%3E")}.mw-ui-icon-reference-generic:before{background-image:url(/w/load.php?modules=ext.popups.images&image=reference-generic&format=rasterized&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E reference %3C/title%3E %3Cpath d=%22m15 10-2.78-2.78L9.44 10V1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2z%22/%3E %3C/svg%3E")}.mw-ui-icon-reference-book:before{background-image:url(/w/load.php?modules=ext.popups.images&image=reference-book&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E book %3C/title%3E %3Cpath d=%22M15 2a7.65 7.65 0 0 0-5 2 7.65 7.65 0 0 0-5-2H1v15h4a7.65 7.65 0 0 1 5 2 7.65 7.65 0 0 1 5-2h4V2zm2.5 13.5H14a4.38 4.38 0 0 0-3 1V5s1-1.5 4-1.5h2.5z%22/%3E %3Cpath d=%22M9 3.5h2v1H9z%22/%3E %3C/svg%3E")}.mw-ui-icon-reference-journal:before{background-image:url(/w/load.php?modules=ext.popups.images&image=reference-journal&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E journal %3C/title%3E %3Cpath d=%22M2 18.5A1.5 1.5 0 0 0 3.5 20H5V0H3.5A1.5 1.5 0 0 0 2 1.5zM6 0v20h10a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2zm7 8H8V7h5zm3-2H8V5h8z%22/%3E %3C/svg%3E")}.mw-ui-icon-reference-news:before{background-image:url(/w/load.php?modules=ext.popups.images&image=reference-news&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E newspaper %3C/title%3E %3Cpath d=%22M5 2a2 2 0 0 0-2 2v12a1 1 0 0 1-1-1V5h-.5A1.5 1.5 0 0 0 0 6.5v10A1.5 1.5 0 0 0 1.5 18H18a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm1 2h11v4H6zm0 6h6v1H6zm0 2h6v1H6zm0 2h6v1H6zm7-4h4v5h-4z%22/%3E %3C/svg%3E")}.mw-ui-icon-reference-web:before{background-image:url(/w/load.php?modules=ext.popups.images&image=reference-web&format=rasterized&lang=en&skin=vector-2022&version=8bc13);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E browser %3C/title%3E %3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5zM18 16H2V8h16z%22/%3E %3C/svg%3E")}
.oo-ui-icon-edit,.mw-ui-icon-edit:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=edit&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit %3C/title%3E%3Cpath d=%22m16.77 8 1.94-2a1 1 0 0 0 0-1.41l-3.34-3.3a1 1 0 0 0-1.41 0L12 3.23zM1 14.25V19h4.75l9.96-9.96-4.75-4.75z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-edit,.mw-ui-icon-edit-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=edit&variant=invert&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22m16.77 8 1.94-2a1 1 0 0 0 0-1.41l-3.34-3.3a1 1 0 0 0-1.41 0L12 3.23zM1 14.25V19h4.75l9.96-9.96-4.75-4.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-edit,.mw-ui-icon-edit-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=edit&variant=progressive&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22m16.77 8 1.94-2a1 1 0 0 0 0-1.41l-3.34-3.3a1 1 0 0 0-1.41 0L12 3.23zM1 14.25V19h4.75l9.96-9.96-4.75-4.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-editLock,.mw-ui-icon-editLock:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=editLock&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit lock %3C/title%3E%3Cpath d=%22M12 12a2 2 0 0 1-2-2V5.25l-9 9V19h4.75l7-7zm7-8h-.5V2.5a2.5 2.5 0 0 0-5 0V4H13a1 1 0 0 0-1 1v4a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V5a1 1 0 0 0-1-1zm-3 4a1 1 0 1 1 1-1 1 1 0 0 1-1 1zm1.5-4h-3V2.75C14.5 2 14.5 1 16 1s1.5 1 1.5 1.75z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-editLock,.mw-ui-icon-editLock-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=editLock&variant=invert&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit lock %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M12 12a2 2 0 0 1-2-2V5.25l-9 9V19h4.75l7-7zm7-8h-.5V2.5a2.5 2.5 0 0 0-5 0V4H13a1 1 0 0 0-1 1v4a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V5a1 1 0 0 0-1-1zm-3 4a1 1 0 1 1 1-1 1 1 0 0 1-1 1zm1.5-4h-3V2.75C14.5 2 14.5 1 16 1s1.5 1 1.5 1.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-editLock,.mw-ui-icon-editLock-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=editLock&variant=progressive&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit lock %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M12 12a2 2 0 0 1-2-2V5.25l-9 9V19h4.75l7-7zm7-8h-.5V2.5a2.5 2.5 0 0 0-5 0V4H13a1 1 0 0 0-1 1v4a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V5a1 1 0 0 0-1-1zm-3 4a1 1 0 1 1 1-1 1 1 0 0 1-1 1zm1.5-4h-3V2.75C14.5 2 14.5 1 16 1s1.5 1 1.5 1.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-editUndo,.mw-ui-icon-editUndo:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=editUndo&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo edit %3C/title%3E%3Cpath d=%22M1 14.25V19h4.75l8.33-8.33-5.27-4.23zM13 2.86V0L8 4l5 4V5h.86c2.29 0 4 1.43 4 4.29H20a6.51 6.51 0 0 0-6.14-6.43z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-editUndo,.mw-ui-icon-editUndo-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=editUndo&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo edit %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M1 14.25V19h4.75l8.33-8.33-5.27-4.23zM13 2.86V0L8 4l5 4V5h.86c2.29 0 4 1.43 4 4.29H20a6.51 6.51 0 0 0-6.14-6.43z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-editUndo,.mw-ui-icon-editUndo-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=editUndo&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo edit %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M1 14.25V19h4.75l8.33-8.33-5.27-4.23zM13 2.86V0L8 4l5 4V5h.86c2.29 0 4 1.43 4 4.29H20a6.51 6.51 0 0 0-6.14-6.43z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-link,.mw-ui-icon-link:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=link&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E link %3C/title%3E%3Cpath d=%22M4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5a3 3 0 1 1 0-6h3a3 3 0 0 1 2.82 4h2.1a4.82 4.82 0 0 0 .08-.83v-.34A4.83 4.83 0 0 0 8.17 5H4.83A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15z%22/%3E%3Cpath d=%22M15.17 5h-2.91a4.88 4.88 0 0 1 1.55 2H15a3 3 0 1 1 0 6h-3a3 3 0 0 1-2.82-4h-2.1a4.82 4.82 0 0 0-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-link,.mw-ui-icon-link-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=link&variant=invert&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E link %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5a3 3 0 1 1 0-6h3a3 3 0 0 1 2.82 4h2.1a4.82 4.82 0 0 0 .08-.83v-.34A4.83 4.83 0 0 0 8.17 5H4.83A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15z%22/%3E%3Cpath d=%22M15.17 5h-2.91a4.88 4.88 0 0 1 1.55 2H15a3 3 0 1 1 0 6h-3a3 3 0 0 1-2.82-4h-2.1a4.82 4.82 0 0 0-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-link,.mw-ui-icon-link-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=link&variant=progressive&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E link %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5a3 3 0 1 1 0-6h3a3 3 0 0 1 2.82 4h2.1a4.82 4.82 0 0 0 .08-.83v-.34A4.83 4.83 0 0 0 8.17 5H4.83A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15z%22/%3E%3Cpath d=%22M15.17 5h-2.91a4.88 4.88 0 0 1 1.55 2H15a3 3 0 1 1 0 6h-3a3 3 0 0 1-2.82-4h-2.1a4.82 4.82 0 0 0-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-unLink,.mw-ui-icon-unLink:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=unLink&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5c-4 0-4-6 0-6h3c.075.001.15.005.225.012L6.215 5zm7.43 0a4.88 4.88 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03zM7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34c.316 0 .631-.032.941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-unLink,.mw-ui-icon-unLink-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=unLink&variant=invert&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5c-4 0-4-6 0-6h3c.075.001.15.005.225.012L6.215 5zm7.43 0a4.88 4.88 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03zM7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34c.316 0 .631-.032.941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-unLink,.mw-ui-icon-unLink-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=unLink&variant=progressive&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5c-4 0-4-6 0-6h3c.075.001.15.005.225.012L6.215 5zm7.43 0a4.88 4.88 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03zM7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34c.316 0 .631-.032.941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-unLink,.mw-ui-icon-unLink-destructive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=unLink&variant=destructive&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cg fill=%22%23d33%22%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.88 4.88 0 0 1-1.55-2H5c-4 0-4-6 0-6h3c.075.001.15.005.225.012L6.215 5zm7.43 0a4.88 4.88 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03zM7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34c.316 0 .631-.032.941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-linkExternal,.mw-ui-icon-linkExternal:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=linkExternal&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E external link %3C/title%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.29 3.29-5.73 5.73 1.42 1.42 5.73-5.73L19 9V1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-linkExternal,.mw-ui-icon-linkExternal-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=linkExternal&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E external link %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.29 3.29-5.73 5.73 1.42 1.42 5.73-5.73L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-linkExternal,.mw-ui-icon-linkExternal-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=linkExternal&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E external link %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.29 3.29-5.73 5.73 1.42 1.42 5.73-5.73L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-linkSecure,.mw-ui-icon-linkSecure:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=linkSecure&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E secure link %3C/title%3E%3Cpath d=%22M16.07 8H15V5s0-5-5-5-5 5-5 5v3H3.93A1.93 1.93 0 0 0 2 9.93v8.15A1.93 1.93 0 0 0 3.93 20h12.14A1.93 1.93 0 0 0 18 18.07V9.93A1.93 1.93 0 0 0 16.07 8zM7 5.5C7 4 7 2 10 2s3 2 3 3.5V8H7zM10 16a2 2 0 1 1 2-2 2 2 0 0 1-2 2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-linkSecure,.mw-ui-icon-linkSecure-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=linkSecure&variant=invert&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E secure link %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M16.07 8H15V5s0-5-5-5-5 5-5 5v3H3.93A1.93 1.93 0 0 0 2 9.93v8.15A1.93 1.93 0 0 0 3.93 20h12.14A1.93 1.93 0 0 0 18 18.07V9.93A1.93 1.93 0 0 0 16.07 8zM7 5.5C7 4 7 2 10 2s3 2 3 3.5V8H7zM10 16a2 2 0 1 1 2-2 2 2 0 0 1-2 2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-linkSecure,.mw-ui-icon-linkSecure-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=linkSecure&variant=progressive&format=rasterized&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E secure link %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M16.07 8H15V5s0-5-5-5-5 5-5 5v3H3.93A1.93 1.93 0 0 0 2 9.93v8.15A1.93 1.93 0 0 0 3.93 20h12.14A1.93 1.93 0 0 0 18 18.07V9.93A1.93 1.93 0 0 0 16.07 8zM7 5.5C7 4 7 2 10 2s3 2 3 3.5V8H7zM10 16a2 2 0 1 1 2-2 2 2 0 0 1-2 2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-redo,.mw-ui-icon-redo:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=redo&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E redo %3C/title%3E%3Cpath d=%22M19 8.5 12 3v11zM12 7v3h-1c-4 0-7 2-7 6v1H1v-1c0-6 5-9 10-9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-redo,.mw-ui-icon-redo-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=redo&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E redo %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M19 8.5 12 3v11zM12 7v3h-1c-4 0-7 2-7 6v1H1v-1c0-6 5-9 10-9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-redo,.mw-ui-icon-redo-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=redo&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E redo %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M19 8.5 12 3v11zM12 7v3h-1c-4 0-7 2-7 6v1H1v-1c0-6 5-9 10-9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-undo,.mw-ui-icon-undo:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=undo&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo %3C/title%3E%3Cpath d=%22M1 8.5 8 14v-4h1c4 0 7 2 7 6v1h3v-1c0-6-5-9-10-9H8V3z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-undo,.mw-ui-icon-undo-invert:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=undo&variant=invert&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M1 8.5 8 14v-4h1c4 0 7 2 7 6v1h3v-1c0-6-5-9-10-9H8V3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-undo,.mw-ui-icon-undo-progressive:before{background-image:url(/w/load.php?modules=oojs-ui.styles.icons-editing-core&image=undo&variant=progressive&format=rasterized&lang=en&skin=vector-2022&version=sgusq);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M1 8.5 8 14v-4h1c4 0 7 2 7 6v1h3v-1c0-6-5-9-10-9H8V3z%22/%3E%3C/g%3E%3C/svg%3E")}</style><style>
.vector-limited-width-toggle{display:none}@media (min-width:1400px){.vector-limited-width-toggle{display:block;position:fixed;bottom:8px;right:8px}.vector-feature-limited-width-disabled .vector-limited-width-toggle:before{background-image:url(/w/skins/Vector/resources/skins.vector.es6/images/fullscreen-close.svg?7de46)}.vector-feature-limited-width-enabled .vector-limited-width-toggle:before{background-image:url(/w/skins/Vector/resources/skins.vector.es6/images/fullscreen.svg?ead1e)}}
@keyframes mwe-popups-fade-in-up{0%{opacity:0;transform:translate(0,20px)}100%{opacity:1;transform:translate(0,0)}}@keyframes mwe-popups-fade-in-down{0%{opacity:0;transform:translate(0,-20px)}100%{opacity:1;transform:translate(0,0)}}@keyframes mwe-popups-fade-out-down{0%{opacity:1;transform:translate(0,0)}100%{opacity:0;transform:translate(0,20px)}}@keyframes mwe-popups-fade-out-up{0%{opacity:1;transform:translate(0,0)}100%{opacity:0;transform:translate(0,-20px)}}.mwe-popups-fade-in-up{animation:mwe-popups-fade-in-up 0.2s ease forwards}.mwe-popups-fade-in-down{animation:mwe-popups-fade-in-down 0.2s ease forwards}.mwe-popups-fade-out-down{animation:mwe-popups-fade-out-down 0.2s ease forwards}.mwe-popups-fade-out-up{animation:mwe-popups-fade-out-up 0.2s ease forwards}  #mwe-popups-settings{z-index:1000;background:#fff;width:420px;border:1px solid #a2a9b1;box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);border-radius:2px;font-size:14px}#mwe-popups-settings header{box-sizing:border-box;border-bottom:1px solid #c8ccd1;position:relative;display:table;width:100%;padding:5px 7px 5px 0}#mwe-popups-settings header > div{display:table-cell;width:3.5em;vertical-align:middle;cursor:pointer}#mwe-popups-settings header h1{margin-bottom:0.6em;padding-top:0.5em;border:0;width:100%;font-family:sans-serif;font-size:18px;font-weight:bold;text-align:center}#mwe-popups-settings .mwe-ui-icon-popups-close{opacity:0.87;transition:opacity 100ms}#mwe-popups-settings .mwe-ui-icon-popups-close:hover{opacity:0.73}#mwe-popups-settings .mwe-ui-icon-popups-close:active{opacity:1}#mwe-popups-settings main#mwe-popups-settings-form{display:block;width:350px;padding:32px 0 24px;margin:0 auto}#mwe-popups-settings main#mwe-popups-settings-form p{color:#54595d;font-size:14px;margin:16px 0 0}#mwe-popups-settings main#mwe-popups-settings-form p:first-child{margin-top:0}#mwe-popups-settings main#mwe-popups-settings-form form img{margin-right:60px}#mwe-popups-settings main#mwe-popups-settings-form form input{margin-right:10px}#mwe-popups-settings main#mwe-popups-settings-form form label{font-size:13px;line-height:16px;width:300px}#mwe-popups-settings main#mwe-popups-settings-form form label > span{color:#000;font-size:14px;font-weight:bold;display:block;margin-bottom:5px}#mwe-popups-settings main#mwe-popups-settings-form form label:before{top:0.78125em !important}.mwe-popups-settings-help{font-size:13px;font-weight:800;margin:40px;position:relative}.mwe-popups-settings-help .mw-ui-icon:before,.mwe-popups-settings-help .mw-ui-icon{background-size:contain;height:140px;width:180px;max-width:none;margin:0;padding:0}.mwe-popups-settings-help p{left:180px;bottom:20px;position:absolute}.mwe-popups{background:#fff;position:absolute;z-index:110;box-shadow:0 30px 90px -20px rgba(0,0,0,0.3),0 0 1px 1px rgba(0,0,0,0.05);padding:0;display:none;font-size:14px;line-height:20px;min-width:300px;border-radius:2px; }.mwe-popups .mw-ui-icon-preview-disambiguation,.mwe-popups .mw-ui-icon-preview-generic{opacity:0.25}.mwe-popups .mwe-popups-container{color:#202122;margin-top:-8px;padding-top:9px;text-decoration:none}.mwe-popups .mwe-popups-container footer{padding:0 16px 16px;margin:0;position:absolute;bottom:0;left:0;pointer-events:none}.mwe-popups .mwe-popups-container footer a{pointer-events:auto}.mwe-popups .mwe-popups-settings-icon{display:block;float:right;border-radius:2px;opacity:0.67;transition:background-color 100ms,opacity 100ms}.mwe-popups .mwe-popups-settings-icon:hover{background-color:#eaecf0}.mwe-popups .mwe-popups-settings-icon:active{background-color:#c8ccd1;opacity:1}.mwe-popups .mwe-popups-extract{margin:16px;display:block;color:#202122;text-decoration:none;position:relative;   }.mwe-popups .mwe-popups-extract:hover{text-decoration:none}.mwe-popups .mwe-popups-extract:after,.mwe-popups .mwe-popups-extract blockquote:after{content:' ';position:absolute;bottom:0;width:25%;height:20px;background-color:transparent;pointer-events:none}.mwe-popups .mwe-popups-extract[dir='ltr']:after{ right:0; background-image:linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract[dir='rtl']:after{ left:0; background-image:linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract blockquote:after{width:100%;height:25px; bottom:0; background-image:linear-gradient(to bottom,rgba(255,255,255,0),#ffffff 75%)}.mwe-popups .mwe-popups-extract p{margin:0}.mwe-popups .mwe-popups-extract ul,.mwe-popups .mwe-popups-extract ol,.mwe-popups .mwe-popups-extract li,.mwe-popups .mwe-popups-extract dl,.mwe-popups .mwe-popups-extract dd,.mwe-popups .mwe-popups-extract dt{margin-top:0;margin-bottom:0}.mwe-popups svg{overflow:hidden}.mwe-popups.mwe-popups-is-tall{width:450px}.mwe-popups.mwe-popups-is-tall > div > a > svg{vertical-align:middle}.mwe-popups.mwe-popups-is-tall .mwe-popups-extract{width:215px;height:176px;overflow:hidden;float:left}.mwe-popups.mwe-popups-is-tall .mwe-popups-extract + footer{left:0;right:203px}.rtl .mwe-popups.mwe-popups-is-tall .mwe-popups-extract + footer{ right:-12px;width:215px}.mwe-popups.mwe-popups-is-not-tall{width:320px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-extract{min-height:58px;max-height:136px;overflow:hidden;margin-bottom:58px;padding-bottom:0}.mwe-popups.mwe-popups-is-not-tall footer{width:288px}.mwe-popups .mwe-popups-container.footer-empty .mwe-popups-extract{margin-bottom:16px}.mwe-popups .mwe-popups-container.footer-empty .mwe-popups-extract .mwe-popups-scroll{max-height:379px}.mwe-popups.flipped-y .mwe-popups-container.footer-empty .mwe-popups-extract,.mwe-popups.flipped-x-y .mwe-popups-container.footer-empty .mwe-popups-extract{margin-bottom:24px}.mwe-popups.mwe-popups-type-generic .mwe-popups-extract,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-extract{min-height:auto;padding-top:4px;margin-top:0;margin-bottom:var(--margin-bottom);--margin-bottom:60px}.mwe-popups.mwe-popups-type-generic .mwe-popups-read-link,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-read-link{font-weight:bold;font-size:12px}.mwe-popups.mwe-popups-type-generic .mwe-popups-extract:hover + footer .mwe-popups-read-link,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-extract:hover + footer .mwe-popups-read-link{text-decoration:underline}.mwe-popups.mwe-popups-no-image-pointer:before{content:'';position:absolute;border:8px solid transparent;border-top:0;border-bottom:8px solid rgba(0,0,0,0.07000000000000001);top:-8px;left:10px}.mwe-popups.mwe-popups-no-image-pointer:after{content:'';position:absolute;border:11px solid transparent;border-top:0;border-bottom:11px solid #ffffff;top:-7px;left:7px}.mwe-popups.flipped-x.mwe-popups-no-image-pointer:before{left:auto;right:10px}.mwe-popups.flipped-x.mwe-popups-no-image-pointer:after{left:auto;right:7px}.mwe-popups.mwe-popups-image-pointer:before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:9px;z-index:111}.mwe-popups.mwe-popups-image-pointer:after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #ffffff;top:-8px;left:6px;z-index:112}.mwe-popups.mwe-popups-image-pointer.flipped-x:before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:293px}.mwe-popups.mwe-popups-image-pointer.flipped-x:after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #ffffff;top:-8px;left:290px}.mwe-popups.mwe-popups-image-pointer .mwe-popups-extract{padding-top:16px;margin-top:200px}.mwe-popups.mwe-popups-image-pointer > div > a > svg{margin-top:-8px;position:absolute;z-index:113;left:0}.mwe-popups.flipped-x.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped-x.mwe-popups-is-tall:before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:420px;z-index:111}.mwe-popups.flipped-x.mwe-popups-is-tall > div > a > svg{margin:0;margin-top:-8px;margin-bottom:-7px;position:absolute;z-index:113;right:0}.mwe-popups.flipped-x.mwe-popups-is-tall .mwe-popups-extract{margin-top:8px}.mwe-popups.flipped-x-y:before{content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px;left:293px;z-index:111}.mwe-popups.flipped-x-y:after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #ffffff;bottom:-8px;left:290px;z-index:112}.mwe-popups.flipped-x-y.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped-x-y.mwe-popups-is-tall:before{content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px;left:420px}.mwe-popups.flipped-x-y.mwe-popups-is-tall:after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #ffffff;bottom:-8px;left:417px}.mwe-popups.flipped-x-y.mwe-popups-is-tall > div > a > svg{margin:0;margin-bottom:-9px;position:absolute;z-index:113;right:0}.mwe-popups.flipped-y:before{content:'';position:absolute;border:8px solid transparent;border-bottom:0;border-top:8px solid #a2a9b1;bottom:-8px;left:10px}.mwe-popups.flipped-y:after{content:'';position:absolute;border:11px solid transparent;border-bottom:0;border-top:11px solid #ffffff;bottom:-7px;left:7px}.mwe-popups-is-tall polyline{transform:translate(0,0)}.mwe-popups-is-tall.flipped-x-y polyline{transform:translate(0,-8px)}.mwe-popups-is-tall.flipped-x polyline{transform:translate(0,8px)}.rtl .mwe-popups-is-tall polyline{transform:translate(-100%,0)}.rtl .mwe-popups-is-tall.flipped-x-y polyline{transform:translate(-100%,-8px)}.rtl .mwe-popups-is-tall.flipped-x polyline{transform:translate(-100%,8px)}@supports (clip-path:polygon(1px 1px)){.mwe-popups .mwe-popups-thumbnail{display:block;object-fit:cover;outline:1px solid rgba(0,0,0,0.1)}.mwe-popups .mwe-popups-extract[dir='rtl'] + footer{ left:unset; right:0}.mwe-popups .mwe-popups-extract[dir='rtl'] + footer .mwe-popups-settings-icon{ float:left}.mwe-popups.flipped-y .mwe-popups-discreet,.mwe-popups.flipped-x-y .mwe-popups-discreet{margin-bottom:0}.mwe-popups.flipped-y .mwe-popups-container,.mwe-popups.flipped-x-y .mwe-popups-container{--y1:100%;--y2:calc(100% - var(--pointer-height));--y3:calc(100% - var(--pointer-height) - var(--pseudo-radius));--y4:var(--pseudo-radius);--y5:0;margin-bottom:-9px;margin-top:0}.mwe-popups .mwe-popups-container{--x1:0;--x2:var(--pseudo-radius);--x3:calc(var(--pointer-offset) - (var(--pointer-width) / 2));--x4:var(--pointer-offset);--x5:calc(var(--pointer-offset) + (var(--pointer-width) / 2));--x6:calc(100% - var(--pseudo-radius));--x7:100%;--y1:0;--y2:var(--pointer-height);--y3:calc(var(--pointer-height) + var(--pseudo-radius));--y4:calc(100% - var(--pseudo-radius));--y5:100%;padding-top:0;display:flex;background:#fff;--pseudo-radius:2px;--pointer-height:8px;--pointer-width:16px;--pointer-offset:26px;clip-path:polygon(var(--x2) var(--y2),var(--x3) var(--y2),var(--x4) var(--y1),var(--x5) var(--y2),var(--x6) var(--y2),var(--x7) var(--y3),var(--x7) var(--y4),var(--x6) var(--y5),var(--x2) var(--y5),var(--x1) var(--y4),var(--x1) var(--y3))}.mwe-popups.mwe-popups-is-tall{flex-direction:row}.mwe-popups.mwe-popups-is-tall .mwe-popups-discreet{order:1}.mwe-popups.mwe-popups-is-tall .mwe-popups-discreet .mwe-popups-thumbnail{width:203px;box-sizing:border-box;height:250px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-thumbnail{width:320px;height:192px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-container{flex-direction:column}.mwe-popups:before{display:none}.mwe-popups:after{display:none}.mwe-popups.mwe-popups-image-pointer .mwe-popups-discreet{margin-bottom:0}.mwe-popups.mwe-popups-image-pointer .mwe-popups-extract{margin-top:0}.mwe-popups:not(.flipped-y):not(.flipped-x-y):not(.mwe-popups-image-pointer):not(.mwe-popups-type-disambiguation) .mwe-popups-extract{padding-top:var(--pointer-height)}.mwe-popups.mwe-popups-type-generic:not(.flipped-y):not(.flipped-x-y) .mwe-popups-container,.mwe-popups.mwe-popups-type-disambiguation:not(.flipped-y):not(.flipped-x-y) .mwe-popups-container{padding-top:var(--pointer-height)}.mwe-popups.mwe-popups-type-generic:not(.flipped-y):not(.flipped-x-y) .mwe-popups-container .mwe-popups-extract,.mwe-popups.mwe-popups-type-disambiguation:not(.flipped-y):not(.flipped-x-y) .mwe-popups-container .mwe-popups-extract{margin-bottom:calc(var(--margin-bottom) - var(--pointer-height))}body.ltr .mwe-popups.flipped-x .mwe-popups-container,body.ltr .mwe-popups.flipped-x-y .mwe-popups-container,body.rtl .mwe-popups:not(.flipped-x):not(.flipped-x-y) .mwe-popups-container{--x3:calc(100% - var(--pointer-offset) - (var(--pointer-width) / 2));--x4:calc(100% - var(--pointer-offset));--x5:calc(100% - var(--pointer-offset) + (var(--pointer-width) / 2))}}.mwe-popups .mwe-popups-title{display:block;font-weight:bold;margin:0 16px}#mw-content-text .reference a[href*='#'] *{pointer-events:none}.mwe-popups.mwe-popups-type-reference .mwe-popups-title{margin:0 0 12px 0}.mwe-popups.mwe-popups-type-reference .mwe-popups-title .mw-ui-icon{padding:0 8px 0 0}.mwe-popups.mwe-popups-type-reference .mwe-popups-title .mw-ui-icon:hover{ background-color:transparent !important}.mwe-popups.mwe-popups-type-reference .mwe-popups-title .mw-ui-icon-reference-note{display:none}.mwe-popups.mwe-popups-type-reference .mwe-popups-extract{margin-right:0;max-height:inherit}.mwe-popups.mwe-popups-type-reference .mwe-popups-extract .mwe-popups-scroll{max-height:348px;overflow:auto;padding-right:16px}.mwe-popups.mwe-popups-type-reference .mwe-popups-extract .mw-parser-output{overflow-wrap:break-word}.mwe-popups.mwe-popups-type-reference .mwe-popups-extract:after{display:none}.mwe-popups.mwe-popups-type-reference .mwe-popups-extract .mwe-popups-fade{position:absolute;width:100%;height:20px;background-color:transparent;background-image:linear-gradient(rgba(255,255,255,0),#ffffff);opacity:0;pointer-events:none;transition:opacity 250ms ease}.mwe-popups.mwe-popups-type-reference .mwe-popups-extract.mwe-popups-fade-out .mwe-popups-fade{opacity:1}.mwe-popups.mwe-popups-type-reference .mwe-collapsible-placeholder{font-weight:bold;margin:1em 0;position:relative}.mwe-popups.mwe-popups-type-reference .mwe-collapsible-placeholder .mw-ui-icon{margin-left:-0.78em;position:absolute}.mwe-popups.mwe-popups-type-reference .mwe-collapsible-placeholder .mwe-collapsible-placeholder-label{margin-left:2.5em}.mwe-popups-overlay{background-color:rgba(255,255,255,0.9);z-index:999;position:fixed;height:100%;width:100%;top:0;bottom:0;left:0;right:0;display:flex;justify-content:center;align-items:center}#mwe-popups-svg{position:absolute;top:-1000px}
.ve-init-mw-tempWikitextEditorWidget{border:0;padding:0;color:inherit;line-height:1.5em;width:100%; -moz-tab-size:4; tab-size:4; }.ve-init-mw-tempWikitextEditorWidget:focus{outline:0;padding:0}.ve-init-mw-tempWikitextEditorWidget::selection{background:rgba(109,169,247,0.5); }
#p-lang .body ul .uls-trigger,#p-lang .pBody ul .uls-trigger{background-image:none;padding:0}#p-lang .mw-interlanguage-selector,#p-lang .mw-interlanguage-selector:active{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/language-base20.svg?b7954);background-position:left 4px center;background-repeat:no-repeat;background-size:16px;margin:4px 0 8px;padding:4px 8px 4px 26px;font-size:13px;font-weight:normal;text-align:left;cursor:pointer}#p-lang .mw-interlanguage-selector.selector-open{background-color:#c8ccd1}  .interlanguage-uls-menu:before,.interlanguage-uls-menu:after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.interlanguage-uls-menu.selector-right:before{ border-left:10px solid #c8ccd1; right:-11px}.interlanguage-uls-menu.selector-right:after{ border-left:10px solid #fff; right:-10px}.interlanguage-uls-menu.selector-left:before{ border-right:10px solid #c8ccd1; left:-11px}.interlanguage-uls-menu.selector-left:after{ border-right:10px solid #fff; left:-10px}.uls-dialog-sticky .uls-menu{position:fixed}.uls-dialog-sticky.uls-dialog-sticky-hide .uls-menu{ display:none !important}</style><style>
.ve-active .ve-init-mw-desktopArticleTarget-targetContainer #siteNotice,.ve-active .mw-indicators,.ve-active #t-print,.ve-active #t-permalink,.ve-active #p-coll-print_export,.ve-active #t-cite,.ve-active .ve-init-mw-desktopArticleTarget-editableContent,.ve-active .ve-init-mw-tempWikitextEditorWidget{display:none}.ve-deactivating .ve-ui-surface{display:none}.ve-activating{ }.ve-activating .ve-ui-surface{height:0;padding:0 !important; overflow:hidden} .ve-loading .ve-init-mw-desktopArticleTarget-targetContainer > :not(.ve-init-mw-desktopArticleTarget-toolbarPlaceholder):not(.ve-init-mw-desktopArticleTarget),.ve-loading .ve-init-mw-desktopArticleTarget-originalContent,.ve-activated:not(.ve-loading) .ve-init-mw-desktopArticleTarget-uneditableContent{pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;opacity:0.5}.ve-activated .ve-init-mw-desktopArticleTarget-targetContainer #firstHeading{ -webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;pointer-events:auto;cursor:text}.ve-activated .ve-init-mw-desktopArticleTarget-targetContainer #firstHeading a{ pointer-events:none}.ve-activated .ve-init-mw-desktopArticleTarget-originalContent #catlinks{cursor:pointer}.ve-activated .ve-init-mw-desktopArticleTarget-originalContent #catlinks:hover{ background:#e9f2fd}.ve-activated .ve-init-mw-desktopArticleTarget-originalContent #catlinks a{opacity:1} .ve-init-mw-desktopArticleTarget-loading-overlay{z-index:2;position:absolute;width:100%;top:1em}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder{overflow:hidden;transition:height 250ms ease;height:0;padding-bottom:2px; }.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{transform:translateY(-100%);transition:transform 250ms ease}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-open .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{transform:translateY(0)}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-floating{transition:none}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-floating .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{position:fixed;top:0;z-index:1;background:#fff} .oo-ui-element-hidden{display:none !important; } .mw-editsection{ unicode-bidi:-moz-isolate;unicode-bidi:-webkit-isolate;unicode-bidi:isolate}.mw-editsection:before{content:'\200B'}.mw-editsection a{white-space:nowrap}.mw-editsection-divider{color:#54595d} .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{height:42px;border-bottom:1px solid #c8ccd1;box-shadow:0 1px 1px 0 rgba(0,0,0,0.1)}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-floating,.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-open{height:42px} .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar,.ve-init-mw-desktopArticleTarget-toolbar.ve-ui-toolbar > .oo-ui-toolbar-bar{box-shadow:0 2px 1px -1px rgba(0,0,0,0.1)} .ve-ui-mwSaveDialog-preview .mw-body .firstHeading{grid-area:titlebar}.ve-ui-mwSaveDialog-preview .mw-body .mw-body-content{grid-area:content}.ve-init-mw-desktopArticleTarget .ve-init-mw-target-surface > .ve-ce-surface .ve-ce-attachedRootNode{min-height:15em}</style><meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="./Causal model - Wikipedia_files/load(2).php">
<meta name="generator" content="MediaWiki 1.40.0-wmf.22">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-crossorigin">
<meta name="referrer" content="origin-when-cross-origin">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/1/1f/Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="1314">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/1/1f/Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png">
<meta property="og:image:width" content="800">
<meta property="og:image:height" content="876">
<meta property="og:image:width" content="640">
<meta property="og:image:height" content="701">
<meta name="viewport" content="width=1000">
<meta property="og:title" content="Causal model - Wikipedia">
<meta property="og:type" content="website">
<link rel="preconnect" href="https://upload.wikimedia.org/">
<link rel="alternate" media="only screen and (max-width: 720px)" href="https://en.m.wikipedia.org/wiki/Causal_model">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit">
<link rel="apple-touch-icon" href="https://en.wikipedia.org/static/apple-touch/wikipedia.png">
<link rel="icon" href="https://en.wikipedia.org/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="https://en.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://en.wikipedia.org/w/api.php?action=rsd">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/">
<link rel="canonical" href="https://en.wikipedia.org/wiki/Causal_model">
<link rel="dns-prefetch" href="https://meta.wikimedia.org/">
<link rel="dns-prefetch" href="https://login.wikimedia.org/">
</head>
<body class="skin-vector skin-vector-search-vue vector-toc-pinned mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Causal_model rootpage-Causal_model skin-vector-2022 action-view uls-dialog-sticky-hide vector-below-page-title" data-new-gr-c-s-check-loaded="14.1096.0" data-gr-ext-installed="" data-new-gr-c-s-loaded="14.1096.0" cz-shortcut-listen="true"><div class="mw-page-container">
	<a class="mw-jump-link" href="https://en.wikipedia.org/wiki/Causal_model#bodyContent">Jump to content</a>
	<div class="mw-page-container-inner">
		<input type="checkbox" id="mw-sidebar-checkbox" class="mw-checkbox-hack-checkbox">
		<header class="mw-header mw-ui-icon-flush-left mw-ui-icon-flush-right">
			<div class="vector-header-start">
					<label id="mw-sidebar-button" class="mw-checkbox-hack-button mw-ui-icon mw-ui-button mw-ui-quiet mw-ui-icon-element mw-ui-icon-flush-right" for="mw-sidebar-checkbox" role="button" aria-controls="mw-panel" data-event-name="ui.sidebar" tabindex="0" title="Main menu" aria-expanded="false">
				<span>Toggle sidebar</span>
			</label>
		
<a href="https://en.wikipedia.org/wiki/Main_Page" class="mw-logo">
	<img class="mw-logo-icon" src="./Causal model - Wikipedia_files/wikipedia.png" alt="" aria-hidden="true" height="50" width="50">
	<span class="mw-logo-container">
		<img class="mw-logo-wordmark" alt="Wikipedia" src="./Causal model - Wikipedia_files/wikipedia-wordmark-en.svg" style="width: 7.5em; height: 1.125em;">
		<img class="mw-logo-tagline" alt="The Free Encyclopedia" src="./Causal model - Wikipedia_files/wikipedia-tagline-en.svg" width="117" height="13" style="width: 7.3125em; height: 0.8125em;">
	</span>
</a>

			</div>
			<div class="vector-header-end">
				
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-collapses  vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<a href="https://en.wikipedia.org/wiki/Special:Search" title="Search Wikipedia [alt-shift-f]" accesskey="f" class="mw-ui-button mw-ui-quiet mw-ui-icon mw-ui-icon-element mw-ui-icon-wikimedia-search search-toggle">
		<span>Search</span>
	</a>
	
	<div>
		<form action="https://en.wikipedia.org/w/index.php" id="searchform" class="vector-search-box-form">
			<div id="simpleSearch" class="vector-search-box-inner" data-search-loc="header-moved">
				<input class="vector-search-box-input" type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [alt-shift-f]" accesskey="f" id="searchInput" autocomplete="off">
				<input type="hidden" name="title" value="Special:Search">
				<input id="mw-searchButton" class="searchButton mw-fallbackSearchButton" type="submit" name="fulltext" title="Search Wikipedia for this text" value="Search">
				<input id="searchButton" class="searchButton" type="submit" name="go" title="Go to a page with this exact name if it exists" value="Go">
			</div>
		</form>
	</div>
</div>

				<nav class="vector-user-links" aria-label="Personal tools" role="navigation">
	
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet mw-portlet-vector-user-menu-overflow">
	<div class="vector-menu-heading">
		
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&amp;returnto=Causal+model" title="You are encouraged to create an account and log in; however, it is not mandatory"><span>Create account</span></a></li><li id="pt-login-2" class="user-links-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Causal+model" title="You&#39;re encouraged to log in; however, it&#39;s not mandatory. [alt-shift-o]" accesskey="o"><span>Log in</span></a></li></ul>
		
	</div>
</div>

	
<div id="p-personal" class="vector-menu vector-dropdown vector-menu-dropdown mw-portlet mw-portlet-personal vector-user-menu vector-user-menu-logged-out" title="Log in and more options">
	<input type="checkbox" id="p-personal-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-personal" class="vector-menu-checkbox ">
	<label id="p-personal-label" for="p-personal-checkbox" class="vector-menu-heading mw-checkbox-hack-button mw-ui-icon mw-ui-button mw-ui-quiet mw-ui-icon-element mw-ui-icon-wikimedia-ellipsis">
		<span class="vector-menu-heading-label">Personal tools</span>
	</label>
	<div class="vector-menu-content">


		<div class="vector-menu-content">
	
	<ul class="vector-menu-content-list"><li class="vector-user-menu-create-account user-links-collapsible-item" id="pt-createaccount"><a data-mw="interface" href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&amp;returnto=Causal+model" title="You are encouraged to create an account and log in; however, it is not mandatory"><span class="mw-ui-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd"></span><span>Create account</span></a>
</li><li class="vector-user-menu-login user-links-collapsible-item" id="pt-login"><a data-mw="interface" href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Causal+model" title="You&#39;re encouraged to log in; however, it&#39;s not mandatory. [alt-shift-o]" accesskey="o"><span class="mw-ui-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn"></span><span>Log in</span></a>
</li></ul>
	
</div>

	<div class="vector-user-menu-anon-editor">
		<p>
			Pages for logged out editors <a data-mw="interface" href="https://en.wikipedia.org/wiki/Help:Introduction" aria-label="Learn more about editing"><span>learn more</span></a>

		</p>
	</div>
		<div class="vector-menu-content">
	
	<ul class="vector-menu-content-list"><li id="pt-anontalk" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:MyTalk" title="Discussion about edits from this IP address [alt-shift-n]" accesskey="n"><span>Talk</span></a></li><li id="pt-anoncontribs" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:MyContributions" title="A list of edits made from this IP address [alt-shift-y]" accesskey="y"><span>Contributions</span></a></li></ul>
	
</div>

	
	</div>
</div>
</nav>

			</div>
		</header>
		<div class="vector-main-menu-container ">
			<div id="mw-navigation">
				<nav id="mw-panel" class="vector-main-menu-landmark" aria-label="Site" role="navigation">
						
<div id="vector-main-menu" class="vector-main-menu vector-pinnable-element">
	
	
<div id="p-navigation" class="vector-main-menu-group vector-menu mw-portlet mw-portlet-navigation">
	<div id="p-navigation-label" class="vector-menu-heading ">
		<span class="vector-menu-heading-label">Navigation</span>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="n-mainpage-description" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Main_Page" title="Visit the main page [alt-shift-z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:Random" title="Visit a randomly selected article [alt-shift-x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li><li id="n-sitesupport" class="mw-list-item"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation"><span>Donate</span></a></li></ul>
		
	</div>
</div>

	
	
<div id="p-interaction" class="vector-main-menu-group vector-menu mw-portlet mw-portlet-interaction">
	<div id="p-interaction-label" class="vector-menu-heading ">
		<span class="vector-menu-heading-label">Contribute</span>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="n-help" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [alt-shift-r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li></ul>
		
	</div>
</div>

<div id="p-tb" class="vector-main-menu-group vector-menu mw-portlet mw-portlet-tb">
	<div id="p-tb-label" class="vector-menu-heading ">
		<span class="vector-menu-heading-label">Tools</span>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="t-whatlinkshere" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:WhatLinksHere/Causal_model" title="List of all English Wikipedia pages containing links to this page [alt-shift-j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Causal_model" rel="nofollow" title="Recent changes in pages linked from this page [alt-shift-k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [alt-shift-u]" accesskey="u"><span>Upload file</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:SpecialPages" title="A list of all special pages [alt-shift-q]" accesskey="q"><span>Special pages</span></a></li><li id="t-permalink" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;oldid=1134560543#Do_calculus" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&amp;page=Causal_model&amp;id=1134560543&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-wikibase" class="mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q5054567" title="Structured data on this page hosted by Wikidata [alt-shift-g]" accesskey="g"><span>Wikidata item</span></a></li><li class="wb-langlinks-link mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q5054567#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit interlanguage links</a></li></ul>
		
	</div>
</div>

<div id="p-coll-print_export" class="vector-main-menu-group vector-menu mw-portlet mw-portlet-coll-print_export">
	<div id="p-coll-print_export-label" class="vector-menu-heading ">
		<span class="vector-menu-heading-label">Print/export</span>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="coll-download-as-rl" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&amp;page=Causal_model&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;printable=yes" title="Printable version of this page [alt-shift-p]" accesskey="p"><span>Printable version</span></a></li></ul>
		
	</div>
</div>

	
<div class="vector-main-menu-action vector-main-menu-action-lang-alert">
	<div class="vector-main-menu-action-item">
		<div class="vector-main-menu-action-heading vector-menu-heading">Languages</div>
		<div class="vector-main-menu-action-content vector-menu-content">
			<div class="mw-message-box-notice vector-language-sidebar-alert mw-message-box">On this Wikipedia the language links are at the top of the page across from the article title. <a href="https://en.wikipedia.org/wiki/Causal_model#p-lang-btn">Go to top</a>.</div>
		</div>
	</div>
</div>


</div>

				</nav>
			</div>
		</div>
		<div class="vector-sitenotice-container">
			<div id="siteNotice"><div id="centralNotice"></div><!-- CentralNotice --></div>
		</div>
		<input type="checkbox" id="vector-toc-collapsed-checkbox" class="mw-checkbox-hack-checkbox">
		<nav id="mw-panel-toc" role="navigation" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container">
			<div id="vector-toc-pinned-container" class="vector-pinned-container">
			<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned" data-name="vector-toc" data-saved-pinned-state="true">
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text" class="vector-toc-list-item vector-toc-level-1">
			<a href="https://en.wikipedia.org/wiki/Causal_model#" class="vector-toc-link">
				<div class="vector-toc-text">(Top)</div>
			</a>
		</li>
		<li id="toc-Definition" class="vector-toc-list-item vector-toc-level-1 vector-toc-level-1-active vector-toc-list-item-active">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Definition">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">1</span>Definition</div>
		</a>
		
		<ul id="toc-Definition-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-History" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#History">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">2</span>History</div>
		</a>
		
		<ul id="toc-History-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Ladder_of_causation" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Ladder_of_causation">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">3</span>Ladder of causation</div>
		</a>
		
			<button aria-controls="toc-Ladder_of_causation-sublist" class="mw-ui-icon mw-ui-icon-wikimedia-expand mw-ui-icon-small vector-toc-toggle" aria-expanded="false">
				
			</button>
		
		<ul id="toc-Ladder_of_causation-sublist" class="vector-toc-list">
			<li id="toc-Association" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Association">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.1</span>Association</div>
			</a>
			
			<ul id="toc-Association-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Intervention" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Intervention">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.2</span>Intervention</div>
			</a>
			
			<ul id="toc-Intervention-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Counterfactuals" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Counterfactuals">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.3</span>Counterfactuals</div>
			</a>
			
			<ul id="toc-Counterfactuals-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Causality" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Causality">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">4</span>Causality</div>
		</a>
		
			<button aria-controls="toc-Causality-sublist" class="mw-ui-icon mw-ui-icon-wikimedia-expand mw-ui-icon-small vector-toc-toggle" aria-expanded="false">
				
			</button>
		
		<ul id="toc-Causality-sublist" class="vector-toc-list">
			<li id="toc-Causality_vs_correlation" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Causality_vs_correlation">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.1</span>Causality vs correlation</div>
			</a>
			
			<ul id="toc-Causality_vs_correlation-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Types" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Types">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2</span>Types</div>
			</a>
			
			<ul id="toc-Types-sublist" class="vector-toc-list">
				<li id="toc-Necessary" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Necessary">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2.1</span>Necessary</div>
			</a>
			
			<ul id="toc-Necessary-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Sufficient_causes" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Sufficient_causes">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2.2</span>Sufficient causes</div>
			</a>
			
			<ul id="toc-Sufficient_causes-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Contributory_causes" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Contributory_causes">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2.3</span>Contributory causes</div>
			</a>
			
			<ul id="toc-Contributory_causes-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Model" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Model">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">5</span>Model</div>
		</a>
		
			<button aria-controls="toc-Model-sublist" class="mw-ui-icon mw-ui-icon-wikimedia-expand mw-ui-icon-small vector-toc-toggle" aria-expanded="false">
				
			</button>
		
		<ul id="toc-Model-sublist" class="vector-toc-list">
			<li id="toc-Causal_diagram" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Causal_diagram">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.1</span>Causal diagram</div>
			</a>
			
			<ul id="toc-Causal_diagram-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Model_elements" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Model_elements">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2</span>Model elements</div>
			</a>
			
			<ul id="toc-Model_elements-sublist" class="vector-toc-list">
				<li id="toc-Junction_patterns" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Junction_patterns">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.1</span>Junction patterns</div>
			</a>
			
			<ul id="toc-Junction_patterns-sublist" class="vector-toc-list">
				<li id="toc-Chain" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Chain">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.1.1</span>Chain</div>
			</a>
			
			<ul id="toc-Chain-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Fork" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Fork">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.1.2</span>Fork</div>
			</a>
			
			<ul id="toc-Fork-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Collider" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Collider">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.1.3</span>Collider</div>
			</a>
			
			<ul id="toc-Collider-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Node_types" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Node_types">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.2</span>Node types</div>
			</a>
			
			<ul id="toc-Node_types-sublist" class="vector-toc-list">
				<li id="toc-Mediator" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Mediator">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.2.1</span>Mediator</div>
			</a>
			
			<ul id="toc-Mediator-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Confounder" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Confounder">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.2.2</span>Confounder</div>
			</a>
			
			<ul id="toc-Confounder-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Instrumental_variable" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Instrumental_variable">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.3</span>Instrumental variable</div>
			</a>
			
			<ul id="toc-Instrumental_variable-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Mendelian_randomization" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Mendelian_randomization">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">5.2.4</span>Mendelian randomization</div>
			</a>
			
			<ul id="toc-Mendelian_randomization-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Associations" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Associations">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">6</span>Associations</div>
		</a>
		
			<button aria-controls="toc-Associations-sublist" class="mw-ui-icon mw-ui-icon-wikimedia-expand mw-ui-icon-small vector-toc-toggle" aria-expanded="false">
				
			</button>
		
		<ul id="toc-Associations-sublist" class="vector-toc-list">
			<li id="toc-Independence_conditions" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Independence_conditions">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.1</span>Independence conditions</div>
			</a>
			
			<ul id="toc-Independence_conditions-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Confounder/deconfounder" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Confounder/deconfounder">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.2</span>Confounder/deconfounder</div>
			</a>
			
			<ul id="toc-Confounder/deconfounder-sublist" class="vector-toc-list">
				<li id="toc-Backdoor_adjustment" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Backdoor_adjustment">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.2.1</span>Backdoor adjustment</div>
			</a>
			
			<ul id="toc-Backdoor_adjustment-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Frontdoor_adjustment" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Frontdoor_adjustment">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">6.2.2</span>Frontdoor adjustment</div>
			</a>
			
			<ul id="toc-Frontdoor_adjustment-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Interventions" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Interventions">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">7</span>Interventions</div>
		</a>
		
			<button aria-controls="toc-Interventions-sublist" class="mw-ui-icon mw-ui-icon-wikimedia-expand mw-ui-icon-small vector-toc-toggle" aria-expanded="false">
				
			</button>
		
		<ul id="toc-Interventions-sublist" class="vector-toc-list">
			<li id="toc-Queries" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Queries">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.1</span>Queries</div>
			</a>
			
			<ul id="toc-Queries-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Do_calculus" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Do_calculus">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2</span>Do calculus</div>
			</a>
			
			<ul id="toc-Do_calculus-sublist" class="vector-toc-list">
				<li id="toc-Rules" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Rules">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2.1</span>Rules</div>
			</a>
			
			<ul id="toc-Rules-sublist" class="vector-toc-list">
				<li id="toc-Rule_1" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Rule_1">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2.1.1</span>Rule 1</div>
			</a>
			
			<ul id="toc-Rule_1-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Rule_2" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Rule_2">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2.1.2</span>Rule 2</div>
			</a>
			
			<ul id="toc-Rule_2-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Rule_3" class="vector-toc-list-item vector-toc-level-4">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Rule_3">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2.1.3</span>Rule 3</div>
			</a>
			
			<ul id="toc-Rule_3-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Extensions" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Extensions">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">7.2.2</span>Extensions</div>
			</a>
			
			<ul id="toc-Extensions-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Counterfactuals_2" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Counterfactuals_2">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">8</span>Counterfactuals</div>
		</a>
		
			<button aria-controls="toc-Counterfactuals_2-sublist" class="mw-ui-icon mw-ui-icon-wikimedia-expand mw-ui-icon-small vector-toc-toggle" aria-expanded="false">
				
			</button>
		
		<ul id="toc-Counterfactuals_2-sublist" class="vector-toc-list">
			<li id="toc-Potential_outcome" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Potential_outcome">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.1</span>Potential outcome</div>
			</a>
			
			<ul id="toc-Potential_outcome-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Causal_inference" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Causal_inference">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.2</span>Causal inference</div>
			</a>
			
			<ul id="toc-Causal_inference-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Conducting_a_counterfactual" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Conducting_a_counterfactual">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3</span>Conducting a counterfactual</div>
			</a>
			
			<ul id="toc-Conducting_a_counterfactual-sublist" class="vector-toc-list">
				<li id="toc-Abduct" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Abduct">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3.1</span>Abduct</div>
			</a>
			
			<ul id="toc-Abduct-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Act" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Act">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3.2</span>Act</div>
			</a>
			
			<ul id="toc-Act-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Predict" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Predict">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.3.3</span>Predict</div>
			</a>
			
			<ul id="toc-Predict-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Mediation" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Mediation">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.4</span>Mediation</div>
			</a>
			
			<ul id="toc-Mediation-sublist" class="vector-toc-list">
				<li id="toc-Direct_effect" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Direct_effect">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.4.1</span>Direct effect</div>
			</a>
			
			<ul id="toc-Direct_effect-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Indirect_effect" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Indirect_effect">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">8.4.2</span>Indirect effect</div>
			</a>
			
			<ul id="toc-Indirect_effect-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Transportability" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Transportability">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">9</span>Transportability</div>
		</a>
		
		<ul id="toc-Transportability-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Bayesian_network" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Bayesian_network">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">10</span>Bayesian network</div>
		</a>
		
		<ul id="toc-Bayesian_network-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Invariants/context" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Invariants/context">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">11</span>Invariants/context</div>
		</a>
		
		<ul id="toc-Invariants/context-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-See_also" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#See_also">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">12</span>See also</div>
		</a>
		
		<ul id="toc-See_also-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-References" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#References">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">13</span>References</div>
		</a>
		
		<ul id="toc-References-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Sources" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#Sources">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">14</span>Sources</div>
		</a>
		
		<ul id="toc-Sources-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-External_links" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="https://en.wikipedia.org/wiki/Causal_model#External_links">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">15</span>External links</div>
		</a>
		
		<ul id="toc-External_links-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

			</div>
</nav>
		<div class="mw-content-container">
			<main id="content" class="mw-body" role="main">
				<header class="mw-body-header vector-page-titlebar">
					<label id="vector-toc-collapsed-button" class="mw-ui-button mw-ui-quiet mw-ui-icon mw-ui-icon-flush-left mw-ui-icon-element mw-ui-icon-wikimedia-listBullet mw-checkbox-hack-button" for="vector-toc-collapsed-checkbox" role="button" aria-controls="toc-toggle-list" data-event-name="vector.toc-toggle-list" tabindex="0" title="Table of Contents">
						Toggle the table of contents
					</label>
				
					
<div id="vector-page-titlebar-toc" class="vector-menu vector-dropdown vector-menu-dropdown vector-page-titlebar-toc mw-ui-icon-flush-left">
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-menu-checkbox ">
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-menu-heading mw-checkbox-hack-button mw-ui-icon mw-ui-button mw-ui-quiet mw-ui-icon-element mw-ui-icon-wikimedia-listBullet">
		<span class="vector-menu-heading-label"></span>
	</label>
	<div class="vector-menu-content">


						<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
		</div>
	
	</div>
</div>
				
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">Causal model</span></h1>
				
							
<div id="p-lang-btn" class="vector-menu vector-dropdown vector-menu-dropdown mw-portlet mw-portlet-lang mw-ui-icon-flush-right">
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-menu-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 4 languages">
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-menu-heading mw-ui-button mw-ui-quiet mw-ui-progressive mw-portlet-lang-heading-4">
		<span class="mw-ui-icon mw-ui-icon-wikimedia-language-progressive"></span><span class="vector-menu-heading-label">4 languages</span>
	</label>
	<div class="vector-menu-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-it mw-list-item"><a href="https://it.wikipedia.org/wiki/Modello_causale" title="Modello causale  Italian" lang="it" hreflang="it" class="interlanguage-link-target"><span>Italiano</span></a></li><li class="interlanguage-link interwiki-ru mw-list-item"><a href="https://ru.wikipedia.org/wiki/%D0%9A%D0%B0%D1%83%D0%B7%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C" title="   Russian" lang="ru" hreflang="ru" class="interlanguage-link-target"><span></span></a></li><li class="interlanguage-link interwiki-sr mw-list-item"><a href="https://sr.wikipedia.org/wiki/%D0%A3%D1%81%D0%BB%D0%BE%D0%B2%D0%BD%D0%B8_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB" title="   Serbian" lang="sr" hreflang="sr" class="interlanguage-link-target"><span> / srpski</span></a></li><li class="interlanguage-link interwiki-sh mw-list-item"><a href="https://sh.wikipedia.org/wiki/Uslovni_model" title="Uslovni model  Serbo-Croatian" lang="sh" hreflang="sh" class="interlanguage-link-target"><span>Srpskohrvatski / </span></a></li></ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"></span></div>
		</div>

	</div>
</div>
				</header>
				<div class="vector-page-toolbar">
					<div class="vector-page-toolbar-container">
						<div id="left-navigation">
							<nav aria-label="Namespaces">
								
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/wiki/Causal_model" title="View the content page [alt-shift-c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/wiki/Talk:Causal_model" rel="discussion" title="Discuss improvements to the content page [alt-shift-t]" accesskey="t"><span>Talk</span></a></li></ul>
		
	</div>
</div>

								

<div id="p-variants" class="vector-menu vector-dropdown vector-menu-dropdown mw-portlet mw-portlet-variants emptyPortlet">
	<input type="checkbox" id="p-variants-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-variants" class="vector-menu-checkbox" aria-label="Change language variant">
	<label id="p-variants-label" for="p-variants-checkbox" class="vector-menu-heading ">
		<span class="vector-menu-heading-label">English</span>
	</label>
	<div class="vector-menu-content">

	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"></ul>
		
	</div>

	</div>
</div>
							</nav>
						</div>
						<div id="right-navigation" class="vector-collapsible">
							<nav aria-label="Views">
								
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/wiki/Causal_model"><span>Read</span></a></li><li id="ca-edit" class="vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit" title="Edit this page [alt-shift-e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=history" title="Past revisions of this page [alt-shift-h]" accesskey="h"><span>View history</span></a></li></ul>
		
	</div>
</div>

							</nav>
				
							<nav class="vector-page-tools-landmark" aria-label="More options">
								

<div id="p-cactions" class="vector-menu vector-dropdown vector-menu-dropdown mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items" title="More options">
	<input type="checkbox" id="p-cactions-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-cactions" class="vector-menu-checkbox">
	<label id="p-cactions-label" for="p-cactions-checkbox" class="vector-menu-heading">
		<span class="vector-menu-heading-label">More</span>
	</label>
	<div class="vector-menu-content">

	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list"><li id="ca-more-view" class="selected vector-more-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/wiki/Causal_model"><span>Read</span></a></li><li id="ca-more-edit" class="vector-more-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit"><span>Edit</span></a></li><li id="ca-more-history" class="vector-more-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=history"><span>View history</span></a></li></ul>
		
	</div>

	</div>
</div>
							</nav>
						</div>
					</div>
				</div>
				
				<div id="bodyContent" class="vector-body ve-init-mw-desktopArticleTarget-targetContainer" aria-labelledby="firstHeading" data-mw-ve-target-container="">
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content mw-content-ltr" lang="en" dir="ltr"><div class="mw-parser-output"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Conceptual model in philosophy of science</div>
<style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-Cleanup_rewrite plainlinks metadata ambox ambox-content" role="presentation"><tbody><tr><td class="mbox-image"><div class="mbox-image-div"><a href="https://en.wikipedia.org/wiki/File:Crystal_Clear_app_kedit.svg" class="image"><img alt="Crystal Clear app kedit.svg" src="./Causal model - Wikipedia_files/40px-Crystal_Clear_app_kedit.svg.png" decoding="async" width="40" height="40" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Crystal_Clear_app_kedit.svg/60px-Crystal_Clear_app_kedit.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Crystal_Clear_app_kedit.svg/80px-Crystal_Clear_app_kedit.svg.png 2x" data-file-width="128" data-file-height="128"></a></div></td><td class="mbox-text"><div class="mbox-text-span">This article may need to be <b>rewritten</b> to comply with Wikipedia's <a href="https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style" title="Wikipedia:Manual of Style">quality standards</a>.<span class="hide-when-compact"> <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit">You can help</a>. The <a href="https://en.wikipedia.org/wiki/Talk:Causal_model" title="Talk:Causal model">talk page</a> may contain suggestions.</span>  <span class="date-container"><i>(<span class="date">March 2020</span>)</i></span></div></td></tr></tbody></table>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="https://en.wikipedia.org/wiki/File:Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png" class="image"><img alt="" src="./Causal model - Wikipedia_files/300px-Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png" decoding="async" width="300" height="328" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png/450px-Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png 1.5x, //upload.wikimedia.org/wikipedia/commons/1/1f/Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png 2x" data-file-width="548" data-file-height="600"></a>  <div class="thumbcaption"><div class="magnify"><a href="https://en.wikipedia.org/wiki/File:Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png" class="internal" title="Enlarge"></a></div>Comparison of two competing causal models (DCM, GCM) used for interpretation of <a href="https://en.wikipedia.org/wiki/FMRI" class="mw-redirect" title="FMRI">fMRI</a> images<sup id="cite_ref-1" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-1">[1]</a></sup></div></div></div>
<p>In the <a href="https://en.wikipedia.org/wiki/Philosophy_of_science" title="Philosophy of science">philosophy of science</a>, a <b>causal model</b> (or <b>structural causal model</b>)  is a <a href="https://en.wikipedia.org/wiki/Conceptual_model" title="Conceptual model">conceptual model</a> that describes the <a href="https://en.wikipedia.org/wiki/Causality" title="Causality">causal</a> mechanisms of a <a href="https://en.wikipedia.org/wiki/System" title="System">system</a>. Causal models can improve study designs by providing clear rules for deciding which independent variables need to be included/controlled for.
</p><p>They can allow some questions to be answered from existing observational data without the need for an interventional study such as a <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial" title="Randomized controlled trial">randomized controlled trial</a>. Some interventional studies are inappropriate for ethical or practical reasons, meaning that without a causal model, some hypotheses cannot be tested.
</p><p>Causal models can help with the question of <i>external validity</i> (whether results from one study apply to unstudied populations). Causal models can allow data from multiple studies to be merged (in certain circumstances) to answer questions that cannot be answered by any individual data set.
</p><p>Causal models have found applications in <a href="https://en.wikipedia.org/wiki/Signal_processing" title="Signal processing">signal processing</a>, <a href="https://en.wikipedia.org/wiki/Epidemiology" title="Epidemiology">epidemiology</a> and <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">machine learning</a>.<sup id="cite_ref-FOOTNOTEPearl2009_2-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-FOOTNOTEPearl2009-2">[2]</a></sup>
</p>
<style data-mw-deduplicate="TemplateStyles:r886046785">.mw-parser-output .toclimit-2 .toclevel-1 ul,.mw-parser-output .toclimit-3 .toclevel-2 ul,.mw-parser-output .toclimit-4 .toclevel-3 ul,.mw-parser-output .toclimit-5 .toclevel-4 ul,.mw-parser-output .toclimit-6 .toclevel-5 ul,.mw-parser-output .toclimit-7 .toclevel-6 ul{display:none}</style><div class="toclimit-3"><meta property="mw:PageProp/toc"></div>
<h2><span class="mw-headline" id="Definition">Definition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=1" title="Edit section: Definition">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r996844942">.mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}</style><blockquote class="templatequote"><p>Causal models are mathematical models representing causal relationships within an individual system or population. They facilitate inferences about causal relationships from statistical data. They can teach us a good deal about the epistemology of causation, and about the relationship between causation and probability. They have also been applied to topics of interest to philosophers, such as the logic of counterfactuals, decision theory, and the analysis of actual causation.<sup id="cite_ref-3" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-3">[3]</a></sup></p><div class="templatequotecite"><cite>Stanford Encyclopedia of Philosophy</cite></div></blockquote> <p><a href="https://en.wikipedia.org/wiki/Judea_Pearl" title="Judea Pearl">Judea Pearl</a> defines a causal model as an ordered triple <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \langle U,V,E\rangle }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false"><!--  --></mo>
        <mi>U</mi>
        <mo>,</mo>
        <mi>V</mi>
        <mo>,</mo>
        <mi>E</mi>
        <mo fence="false" stretchy="false"><!--  --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \langle U,V,E\rangle }</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/c2ef5398e9e78be2ed3eeb9a8e10635e5562d539" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.223ex; height:2.843ex;" alt="\langle U,V,E\rangle "></span>, where U is a set of <a href="https://en.wikipedia.org/wiki/Exogenous_variable" class="mw-redirect" title="Exogenous variable">exogenous variables</a> whose values are determined by factors outside the model; V is a set of endogenous variables whose values are determined by factors within the model; and E is a set of <a href="https://en.wikipedia.org/wiki/Structural_equation" class="mw-redirect" title="Structural equation">structural equations</a> that express the value of each endogenous variable as a function of the values of the other variables in U and V.<sup id="cite_ref-FOOTNOTEPearl2009_2-1" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-FOOTNOTEPearl2009-2">[2]</a></sup>
</p><h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=2" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><a href="https://en.wikipedia.org/wiki/Aristotle" title="Aristotle">Aristotle</a> defined a taxonomy of causality, including material, formal, efficient and final causes. Hume rejected Aristotle's taxonomy in favor of <a href="https://en.wikipedia.org/wiki/Counterfactual_conditional" title="Counterfactual conditional">counterfactuals</a>. At one point, he denied that objects have "powers" that make one a cause and another an effect. Later he adopted "if the first object had not been, the second had never existed" ("<a href="https://en.wikipedia.org/wiki/Sine_qua_non" title="Sine qua non">but-for</a>" causation).<sup id="cite_ref-:1_4-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>In the late 19th century, the discipline of statistics began to form. After a years-long effort to identify causal rules for domains such as biological inheritance, <a href="https://en.wikipedia.org/wiki/Francis_Galton" title="Francis Galton">Galton</a> introduced the concept of <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean" title="Regression toward the mean">mean regression</a> (epitomized by the <a href="https://en.wikipedia.org/wiki/Sophomore_slump" title="Sophomore slump">sophomore slump</a> in sports) which later led him to the non-causal concept of <a href="https://en.wikipedia.org/wiki/Correlation" title="Correlation">correlation</a>.<sup id="cite_ref-:1_4-1" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>As a <a href="https://en.wikipedia.org/wiki/Positivism" title="Positivism">positivist</a>, <a href="https://en.wikipedia.org/wiki/Karl_Pearson" title="Karl Pearson">Pearson</a> expunged the notion of causality from much of science as an unprovable special case of association and introduced the <a href="https://en.wikipedia.org/wiki/Correlation_coefficient" title="Correlation coefficient">correlation coefficient</a> as the metric of association. He wrote, "Force as a cause of motion is exactly the same as a tree god as a cause of growth" and that causation was only a "fetish among the inscrutable arcana of modern science". Pearson founded <i><a href="https://en.wikipedia.org/wiki/Biometrika" title="Biometrika">Biometrika</a></i> and the Biometrics Lab at <a href="https://en.wikipedia.org/wiki/University_College_London" title="University College London">University College London</a>, which became the world leader in statistics.<sup id="cite_ref-:1_4-2" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>In 1908 <a href="https://en.wikipedia.org/wiki/G._H._Hardy" title="G. H. Hardy">Hardy</a> and <a href="https://en.wikipedia.org/wiki/Wilhelm_Weinberg" title="Wilhelm Weinberg">Weinberg</a> solved the problem of <a href="https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle" title="HardyWeinberg principle">trait stability</a> that had led Galton to abandon causality, by resurrecting <a href="https://en.wikipedia.org/wiki/Mendelian_inheritance" title="Mendelian inheritance">Mendelian inheritance</a>.<sup id="cite_ref-:1_4-3" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>In 1921 <a href="https://en.wikipedia.org/wiki/Sewall_Wright" title="Sewall Wright">Wright</a>'s <a href="https://en.wikipedia.org/wiki/Path_analysis_(statistics)" title="Path analysis (statistics)">path analysis</a> became the theoretical ancestor of causal modeling and causal graphs.<sup id="cite_ref-5" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-5">[5]</a></sup> He developed this approach while attempting to untangle the relative impacts of <a href="https://en.wikipedia.org/wiki/Heredity" title="Heredity">heredity</a>, development and environment on <a href="https://en.wikipedia.org/wiki/Guinea_pig" title="Guinea pig">guinea pig</a> coat patterns. He backed up his then-heretical claims by showing how such analyses could explain the relationship between guinea pig birth weight, <i><a href="https://en.wikipedia.org/wiki/Uterus" title="Uterus">in utero</a></i> time and litter size. Opposition to these ideas by prominent statisticians led them to be ignored for the following 40 years (except among animal breeders). Instead scientists relied on correlations, partly at the behest of Wright's critic (and leading statistician), <a href="https://en.wikipedia.org/wiki/Ronald_Fisher" title="Ronald Fisher">Fisher</a>.<sup id="cite_ref-:1_4-4" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup> One exception was <a href="https://en.wikipedia.org/wiki/Barbara_Stoddard_Burks" title="Barbara Stoddard Burks"> Burks</a>, a student who in 1926 was the first to apply path diagrams to represent a mediating influence (<i>mediator</i>) and to assert that holding a mediator constant induces errors. She may have invented path diagrams independently.<sup id="cite_ref-:1_4-5" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 304">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA304">304</a></span></sup>
</p><p>In 1923, <a href="https://en.wikipedia.org/wiki/Jerzy_Neyman" title="Jerzy Neyman">Neyman</a> introduced the concept of a potential outcome, but his paper was not translated from Polish to English until 1990.<sup id="cite_ref-:1_4-6" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 271">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA271">271</a></span></sup>
</p><p>In 1958 <a href="https://en.wikipedia.org/wiki/David_Cox_(statistician)" title="David Cox (statistician)">Cox</a> warned that controlling for a variable Z is valid only if it is highly unlikely to be affected by independent variables.<sup id="cite_ref-:1_4-7" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 154">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA154">154</a></span></sup>
</p><p>In the 1960s, <a href="https://en.wikipedia.org/wiki/Otis_Dudley_Duncan" title="Otis Dudley Duncan">Duncan</a>, <a href="https://en.wikipedia.org/wiki/Hubert_M._Blalock_Jr." title="Hubert M. Blalock Jr.">Blalock</a>, <a href="https://en.wikipedia.org/wiki/Arthur_Goldberger" title="Arthur Goldberger">Goldberger</a> and others rediscovered path analysis. While reading Blalock's work on path diagrams, Duncan remembered a lecture by <a href="https://en.wikipedia.org/wiki/William_Fielding_Ogburn" title="William Fielding Ogburn">Ogburn</a> twenty years earlier that mentioned a paper by Wright that in turn mentioned Burks.<sup id="cite_ref-:1_4-8" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 308">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA308">308</a></span></sup>
</p><p>Sociologists originally called causal models <a href="https://en.wikipedia.org/wiki/Structural_equation_modeling" title="Structural equation modeling">structural equation modeling</a>, but once it became a rote method, it lost its utility, leading some practitioners to reject any relationship to causality. Economists adopted the algebraic part of path analysis, calling it simultaneous equation modeling. However, economists still avoided attributing causal meaning to their equations.<sup id="cite_ref-:1_4-9" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>Sixty years after his first paper, Wright published a piece that recapitulated it, following <a href="https://en.wikipedia.org/wiki/Samuel_Karlin" title="Samuel Karlin">Karlin</a> et al.'s critique, which objected that it handled only linear relationships and that robust, model-free presentations of data were more revealing.<sup id="cite_ref-:1_4-10" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>In 1973 <a href="https://en.wikipedia.org/wiki/David_Lewis_(philosopher)" title="David Lewis (philosopher)">Lewis</a> advocated replacing correlation with but-for causality (counterfactuals). He referred to humans' ability to envision alternative worlds in which a cause did or not occur, and in which an effect appeared only following its cause.<sup id="cite_ref-:1_4-11" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 266">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA266">266</a></span></sup> In 1974 <a href="https://en.wikipedia.org/wiki/Donald_Rubin" title="Donald Rubin">Rubin</a> introduced the notion of "potential outcomes" as a language for asking causal questions.<sup id="cite_ref-:1_4-12" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 269">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA269">269</a></span></sup>
</p><p>In 1983 <a href="https://en.wikipedia.org/wiki/Nancy_Cartwright_(philosopher)" title="Nancy Cartwright (philosopher)">Cartwright</a> proposed that any factor that is "causally relevant" to an effect be conditioned on, moving beyond simple probability as the only guide.<sup id="cite_ref-:1_4-13" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 48">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA48">48</a></span></sup>
</p><p>In 1986 Baron and Kenny introduced principles for detecting and evaluating mediation in a system of linear equations. As of 2014 their paper was the 33rd most-cited of all time.<sup id="cite_ref-:1_4-14" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 324">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA324">324</a></span></sup> That year <a href="https://en.wikipedia.org/wiki/Sander_Greenland" title="Sander Greenland">Greenland</a> and <a href="https://en.wikipedia.org/wiki/James_Robins" title="James Robins">Robins</a> introduced the "exchangeability" approach to handling confounding by considering a counterfactual. They proposed assessing what would have happened to the treatment group if they had not received the treatment and comparing that outcome to that of the control group. If they matched, confounding was said to be absent.<sup id="cite_ref-:1_4-15" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 154">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA154">154</a></span></sup>
</p>
<h2><span class="mw-headline" id="Ladder_of_causation">Ladder of causation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=3" title="Edit section: Ladder of causation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Pearl's causal <a href="https://en.wikipedia.org/wiki/Metamodeling" title="Metamodeling">metamodel</a> involves a three-level abstraction he calls the ladder of causation. The lowest level, Association (seeing/observing), entails the sensing of regularities or patterns in the input data, expressed as correlations. The middle level, Intervention (doing), predicts the effects of deliberate actions, expressed as causal relationships. The highest level, <a href="https://en.wikipedia.org/wiki/Counterfactual_conditional" title="Counterfactual conditional">Counterfactuals</a> (imagining), involves constructing a theory of (part of) the world that explains why specific actions have specific effects and what happens in the absence of such actions.<sup id="cite_ref-:1_4-16" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h3><span class="mw-headline" id="Association">Association</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=4" title="Edit section: Association">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>One object is associated with another if observing one changes the <a href="https://en.wikipedia.org/wiki/Probability" title="Probability">probability</a> of observing the other. Example: shoppers who buy toothpaste are more likely to also buy dental floss. Mathematically:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(floss\vline toothpaste)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>f</mi>
        <mi>l</mi>
        <mi>o</mi>
        <mi>s</mi>
        <mi>s</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mpadded height="0" depth="0">
            <mstyle mathsize="1.2em">
              <mo fence="false" stretchy="false">|<!-- | --></mo>
            </mstyle>
          </mpadded>
        </mrow>
        <mi>t</mi>
        <mi>o</mi>
        <mi>o</mi>
        <mi>t</mi>
        <mi>h</mi>
        <mi>p</mi>
        <mi>a</mi>
        <mi>s</mi>
        <mi>t</mi>
        <mi>e</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(floss\vline toothpaste)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/51638d88018bcb4b782b93cd5ff71fcf7fe518b2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.583ex; margin-top: -0.594ex; margin-bottom: -0.422ex; width:20.298ex; height:3.343ex;" alt="{\displaystyle P(floss\vline toothpaste)}"></span></dd></dl>
<p>or the probability of (purchasing) floss given (the purchase of) toothpaste. Associations can also be measured via computing the <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence" class="mw-redirect" title="Correlation and dependence">correlation</a> of the two events. Associations have no causal implications. One event could cause the other, the reverse could be true, or both events could be caused by some third event (unhappy hygienist shames shopper into treating their mouth better ).<sup id="cite_ref-:1_4-17" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h3><span class="mw-headline" id="Intervention">Intervention</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=5" title="Edit section: Intervention">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>This level asserts specific causal relationships between events. Causality is assessed by experimentally performing some action that affects one of the events. Example: after doubling the price of toothpaste, what would be the new probability of purchasing? Causality cannot be established by examining history (of price changes) because the price change may have been for some other reason that could itself affect the second event (a tariff that increases the price of both goods). Mathematically:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(floss\vline do(toothpaste))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>f</mi>
        <mi>l</mi>
        <mi>o</mi>
        <mi>s</mi>
        <mi>s</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mpadded height="0" depth="0">
            <mstyle mathsize="1.2em">
              <mo fence="false" stretchy="false">|<!-- | --></mo>
            </mstyle>
          </mpadded>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>t</mi>
        <mi>o</mi>
        <mi>o</mi>
        <mi>t</mi>
        <mi>h</mi>
        <mi>p</mi>
        <mi>a</mi>
        <mi>s</mi>
        <mi>t</mi>
        <mi>e</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(floss\vline do(toothpaste))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7f2bbebb38f04d2307eecb74479b4fe68380fc71" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.583ex; margin-top: -0.594ex; margin-bottom: -0.422ex; width:24.45ex; height:3.343ex;" alt="{\displaystyle P(floss\vline do(toothpaste))}"></span></dd></dl>
<p>where <i>do</i> is an operator that signals the experimental intervention (doubling the price).<sup id="cite_ref-:1_4-18" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup> The operator indicates performing the minimal change in the world necessary to create the intended effect, a "mini-surgery" on the model with as little change from reality as possible.<sup id="cite_ref-6" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-6">[6]</a></sup>
</p>
<h3><span class="mw-headline" id="Counterfactuals">Counterfactuals</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=6" title="Edit section: Counterfactuals">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The highest level, counterfactual, involves consideration of an alternate version of a past event, or what would happen under different circumstances for the same experimental unit. For example, what is the probability that, if a store had doubled the price of floss, the toothpaste-purchasing shopper would still have bought it?
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(floss\vline toothpaste,price*2)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>f</mi>
        <mi>l</mi>
        <mi>o</mi>
        <mi>s</mi>
        <mi>s</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mpadded height="0" depth="0">
            <mstyle mathsize="1.2em">
              <mo fence="false" stretchy="false">|<!-- | --></mo>
            </mstyle>
          </mpadded>
        </mrow>
        <mi>t</mi>
        <mi>o</mi>
        <mi>o</mi>
        <mi>t</mi>
        <mi>h</mi>
        <mi>p</mi>
        <mi>a</mi>
        <mi>s</mi>
        <mi>t</mi>
        <mi>e</mi>
        <mo>,</mo>
        <mi>p</mi>
        <mi>r</mi>
        <mi>i</mi>
        <mi>c</mi>
        <mi>e</mi>
        <mo><!--  --></mo>
        <mn>2</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(floss\vline toothpaste,price*2)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/11cbf3aaae0eb8b32cb089df7bcfff67877145f2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.583ex; margin-top: -0.594ex; margin-bottom: -0.422ex; width:29.8ex; height:3.343ex;" alt="{\displaystyle P(floss\vline toothpaste,price*2)}"></span></dd></dl>
<p>Counterfactuals can indicate the existence of a causal relationship. Models that can answer counterfactuals allow precise interventions whose consequences can be predicted. At the extreme, such models are accepted as physical laws (as in the laws of physics, e.g., inertia, which says that if force is not applied to a stationary object, it will not move).<sup id="cite_ref-:1_4-19" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h2><span class="mw-headline" id="Causality">Causality</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=7" title="Edit section: Causality">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Causality_vs_correlation">Causality vs correlation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=8" title="Edit section: Causality vs correlation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Statistics revolves around the analysis of relationships among multiple variables. Traditionally, these relationships are described as <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence" class="mw-redirect" title="Correlation and dependence">correlations</a>, associations without any implied causal relationships. Causal models attempt to extend this framework by adding the notion of causal relationships, in which changes in one variable cause changes in others.<sup id="cite_ref-FOOTNOTEPearl2009_2-2" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-FOOTNOTEPearl2009-2">[2]</a></sup>
</p><p>Twentieth century definitions of <a href="https://en.wikipedia.org/wiki/Causality" title="Causality">causality</a> relied purely on probabilities/associations. One event (<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"></span>) was said to cause another if it raises the probability of the other (<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"></span>). Mathematically this is expressed as:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y\vline X)&gt;P(Y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mpadded height="0" depth="0">
            <mstyle mathsize="1.2em">
              <mo fence="false" stretchy="false">|<!-- | --></mo>
            </mstyle>
          </mpadded>
        </mrow>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>&gt;</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y\vline X)&gt;P(Y)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/d87c453c3b254c2f456b354f8e137ce149895fa8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.583ex; margin-top: -0.594ex; margin-bottom: -0.422ex; width:16.511ex; height:3.343ex;" alt="{\displaystyle P(Y\vline X)&gt;P(Y)}"></span>.</dd></dl>
<p>Such definitions are inadequate because other relationships (e.g., a common cause for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"></span>) can satisfy the condition. Causality is relevant to the second ladder step. Associations are on the first step and provide only evidence to the latter.<sup id="cite_ref-:1_4-20" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>A later definition attempted to address this ambiguity by conditioning on background factors. Mathematically:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y\vline X,K=k)&gt;P(Y|K=k)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mpadded height="0" depth="0">
            <mstyle mathsize="1.2em">
              <mo fence="false" stretchy="false">|<!-- | --></mo>
            </mstyle>
          </mpadded>
        </mrow>
        <mi>X</mi>
        <mo>,</mo>
        <mi>K</mi>
        <mo>=</mo>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
        <mo>&gt;</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>K</mi>
        <mo>=</mo>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y\vline X,K=k)&gt;P(Y|K=k)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/e8820e426cf242b7d2953b3db1bff7943fc628fd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.583ex; margin-top: -0.594ex; margin-bottom: -0.422ex; width:30.943ex; height:3.343ex;" alt="{\displaystyle P(Y\vline X,K=k)&gt;P(Y|K=k)}"></span>,</dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle K}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>K</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle K}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/2b76fce82a62ed5461908f0dc8f037de4e3686b0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.066ex; height:2.176ex;" alt="K"></span> is the set of background variables and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle k}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.211ex; height:2.176ex;" alt="k"></span> represents the values of those variables in a specific context. However, the required set of background variables is indeterminate (multiple sets may increase the probability), as long as probability is the only criterion<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What do we mean by indeterminate? What does it mean &quot;as long as probability is the only criterion&quot;? Criterion for what? (January 2019)">clarification needed</span></a></i>]</sup>.<sup id="cite_ref-:1_4-21" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>Other attempts to define causality include <a href="https://en.wikipedia.org/wiki/Granger_causality" title="Granger causality">Granger causality</a>, a <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing" title="Statistical hypothesis testing">statistical hypothesis test</a> that <a href="https://en.wikipedia.org/wiki/Causality" title="Causality">causality</a> (in <a href="https://en.wikipedia.org/wiki/Economics" title="Economics">economics</a>) can be assessed by measuring the ability to predict the future values of one time series using prior values of another time series.<sup id="cite_ref-:1_4-22" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h3><span class="mw-headline" id="Types">Types</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=9" title="Edit section: Types">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A cause can be <a href="https://en.wikipedia.org/wiki/Causality#Necessary_and_sufficient_causes" title="Causality">necessary, sufficient, contributory</a> or some combination.<sup id="cite_ref-7" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-7">[7]</a></sup>
</p>
<h4><span class="mw-headline" id="Necessary">Necessary</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=10" title="Edit section: Necessary">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>For <i>x</i> to be a necessary cause of <i>y</i>, the presence of <i>y</i> must imply the prior occurrence of <i>x</i>. The presence of <i>x</i>, however, does not imply that <i>y</i> will occur.<sup id="cite_ref-CR_8-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-CR-8">[8]</a></sup> Necessary causes are also known as "but-for" causes, as in <i>y</i> would not have occurred but for the occurrence of <i>x</i>.<sup id="cite_ref-:1_4-23" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 261">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA261">261</a></span></sup>
</p>
<h4><span class="mw-headline" id="Sufficient_causes">Sufficient causes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=11" title="Edit section: Sufficient causes">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>For <i>x</i> to be a sufficient cause of <i>y</i>, the presence of <i>x</i> must imply the subsequent occurrence of <i>y</i>. However, another cause <i>z</i> may independently cause <i>y</i>. Thus the presence of <i>y</i> does not require the prior occurrence of <i>x</i>.<sup id="cite_ref-CR_8-1" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-CR-8">[8]</a></sup>
</p>
<h4><span class="mw-headline" id="Contributory_causes">Contributory causes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=12" title="Edit section: Contributory causes">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>For <i>x</i> to be a contributory cause of <i>y</i>, the presence of <i>x</i> must increase the likelihood of <i>y</i>. If the likelihood is 100%, then <i>x</i> is instead called sufficient. A contributory cause may also be necessary.<sup id="cite_ref-Riegelman_9-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-Riegelman-9">[9]</a></sup>
</p>
<h2><span class="mw-headline" id="Model">Model</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=13" title="Edit section: Model">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Causal_diagram">Causal diagram</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=14" title="Edit section: Causal diagram">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A causal diagram is a <a href="https://en.wikipedia.org/wiki/Directed_graph" title="Directed graph">directed graph</a> that displays <a href="https://en.wikipedia.org/wiki/Causality" title="Causality">causal</a> relationships between <a href="https://en.wikipedia.org/wiki/Variable_(mathematics)" title="Variable (mathematics)">variables</a> in a causal model. A causal diagram includes a set of variables (or <a href="https://en.wikipedia.org/wiki/Node_(graph_theory)" class="mw-redirect" title="Node (graph theory)">nodes</a>). Each node is connected by an arrow to one or more other nodes upon which it has a causal influence. An arrowhead delineates the direction of causality, e.g., an arrow connecting variables <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> with the arrowhead at <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> indicates that a change in <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> causes a change in <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> (with an associated probability). A <i>path</i> is a traversal of the graph between two nodes following causal arrows.<sup id="cite_ref-:1_4-24" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>Causal diagrams include <a href="https://en.wikipedia.org/wiki/Causal_loop_diagram" title="Causal loop diagram">causal loop diagrams</a>, <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" title="Directed acyclic graph">directed acyclic graphs</a>, and <a href="https://en.wikipedia.org/wiki/Ishikawa_diagram" title="Ishikawa diagram">Ishikawa diagrams</a>.<sup id="cite_ref-:1_4-25" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p><p>Causal diagrams are independent of the quantitative probabilities that inform them. Changes to those probabilities (e.g., due to technological improvements) do not require changes to the model.<sup id="cite_ref-:1_4-26" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h3><span class="mw-headline" id="Model_elements">Model elements</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=15" title="Edit section: Model elements">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Causal models have formal structures with elements with specific properties.<sup id="cite_ref-:1_4-27" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h4><span class="mw-headline" id="Junction_patterns">Junction patterns</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=16" title="Edit section: Junction patterns">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The three types of connections of three nodes are linear chains, branching forks and merging colliders.<sup id="cite_ref-:1_4-28" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<h5><span class="mw-headline" id="Chain">Chain</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=17" title="Edit section: Chain">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>Chains are straight line connections with arrows pointing from cause to effect. In this model, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> is a mediator in that it mediates the change that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> would otherwise have on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span>.<sup id="cite_ref-:1_4-29" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 113">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA113">113</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\rightarrow B\rightarrow C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\rightarrow B\rightarrow C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/87f249fd063cc3844f776d817c36127517f61dad" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.502ex; height:2.176ex;" alt="{\displaystyle A\rightarrow B\rightarrow C}"></span></dd></dl>
<h5><span class="mw-headline" id="Fork">Fork</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=18" title="Edit section: Fork">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>In forks, one cause has multiple effects. The two effects have a common cause. There exists a (non-causal) <a href="https://en.wikipedia.org/wiki/Spurious_correlation" class="mw-redirect" title="Spurious correlation">spurious correlation</a> between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span> that can be eliminated by conditioning on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> (for a specific value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>).<sup id="cite_ref-:1_4-30" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 114">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA114">114</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\leftarrow B\rightarrow C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\leftarrow B\rightarrow C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/d80def6621b44e39fc6e4507aa9cc77460c0c911" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.502ex; height:2.176ex;" alt="A\leftarrow B\rightarrow C"></span></dd></dl>
<p>"Conditioning on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>" means "given <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>" (i.e., given a value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>).
</p><p>An elaboration of a fork is the confounder:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\leftarrow B\rightarrow C\rightarrow A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\leftarrow B\rightarrow C\rightarrow A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/23df6eda3d2bf30c22ced348fa6c61b254de2be9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:17.859ex; height:2.176ex;" alt="{\displaystyle A\leftarrow B\rightarrow C\rightarrow A}"></span></dd></dl>
<p>In such models, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> is a common cause of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span> (which also causes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span>), making <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> the confounder<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="Why is this case interesting? Why is B called a cofounder? (January 2019)">clarification needed</span></a></i>]</sup>.<sup id="cite_ref-:1_4-31" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 114">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA114">114</a></span></sup>
</p>
<h5><span class="mw-headline" id="Collider">Collider</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=19" title="Edit section: Collider">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>In <a href="https://en.wikipedia.org/wiki/Collider_(statistics)" title="Collider (statistics)">colliders</a>, multiple causes affect one outcome. Conditioning on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> (for a specific value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>) often reveals a non-causal negative correlation between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span>. This negative correlation has been called collider bias and the "explain-away" effect as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> explains away the correlation between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span>.<sup id="cite_ref-:1_4-32" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 115">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA115">115</a></span></sup> The correlation can be positive in the case where contributions from both <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span> are necessary to affect <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>.<sup id="cite_ref-:1_4-33" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 197">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA197">197</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\rightarrow B\leftarrow C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\rightarrow B\leftarrow C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/5c74b19e5746c413e9c4b17f9f3ac4e3a53379aa" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.502ex; height:2.176ex;" alt="{\displaystyle A\rightarrow B\leftarrow C}"></span></dd></dl>
<h4><span class="mw-headline" id="Node_types">Node types</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=20" title="Edit section: Node types">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<h5><span class="mw-headline" id="Mediator">Mediator</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=21" title="Edit section: Mediator">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>A mediator node modifies the effect of other causes on an outcome (as opposed to simply affecting the outcome).<sup id="cite_ref-:1_4-34" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 113">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA113">113</a></span></sup> For example, in the chain example above, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> is a mediator, because it modifies the effect of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> (an indirect cause of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span>) on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span> (the outcome).
</p>
<h5><span class="mw-headline" id="Confounder">Confounder</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=22" title="Edit section: Confounder">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>A confounder node affects multiple outcomes, creating a positive correlation among them.<sup id="cite_ref-:1_4-35" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 114">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA114">114</a></span></sup>
</p>
<h4><span class="mw-headline" id="Instrumental_variable">Instrumental variable</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=23" title="Edit section: Instrumental variable">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>An <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation" title="Instrumental variables estimation"><i>instrumental variable</i></a> is one that:<sup id="cite_ref-:1_4-36" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 246">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA246">246</a></span></sup>
</p>
<ul><li>has a path to the outcome;</li>
<li>has no other path to causal variables;</li>
<li>has no direct influence on the outcome.</li></ul>
<p>Regression coefficients can serve as estimates of the causal effect of an instrumental variable on an outcome as long as that effect is not confounded. In this way, instrumental variables allow causal factors to be quantified without data on confounders.<sup id="cite_ref-:1_4-37" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 249">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA249">249</a></span></sup>
</p><p>For example, given the model:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z\rightarrow X\rightarrow Y\leftarrow U\rightarrow X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>U</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z\rightarrow X\rightarrow Y\leftarrow U\rightarrow X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/058b5ecf6dc967b28364ca5c3c0f334436b2c742" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:23.653ex; height:2.176ex;" alt="{\displaystyle Z\rightarrow X\rightarrow Y\leftarrow U\rightarrow X}"></span></dd></dl>
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span> is an instrumental variable, because it has a path to the outcome <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"></span> and is unconfounded, e.g., by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle U}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>U</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle U}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/458a728f53b9a0274f059cd695e067c430956025" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.783ex; height:2.176ex;" alt="U"></span>.
</p><p>In the above example, if <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"></span> take binary values, then the assumption that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z=0,X=1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z=0,X=1}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/d75b4e875fc1b167dc66f5ead8bc99350c770abf" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:13.216ex; height:2.509ex;" alt="{\displaystyle Z=0,X=1}"></span> does not occur is called <i>monotonicity</i><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What does this definition have to do with instrumental variables? (January 2019)">clarification needed</span></a></i>]</sup>.<sup id="cite_ref-:1_4-38" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 253">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA253">253</a></span></sup>
</p><p>Refinements to the technique<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What technique? (January 2019)">clarification needed</span></a></i>]</sup> include creating an instrument<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What is an instrument? (January 2019)">clarification needed</span></a></i>]</sup> by conditioning on other variable<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What other variable are we talking about? (January 2019)">clarification needed</span></a></i>]</sup> to block<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What does it mean to &quot;block a path&quot;? (January 2019)">clarification needed</span></a></i>]</sup> the paths<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What is the exact definition of a path? (January 2019)">clarification needed</span></a></i>]</sup> between the instrument and the confounder<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What cofounder are we talking about? (January 2019)">clarification needed</span></a></i>]</sup> and combining multiple variables to form a single instrument<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (January 2019)">clarification needed</span></a></i>]</sup>.<sup id="cite_ref-:1_4-39" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 257">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA257">257</a></span></sup>
</p>
<h4><span class="mw-headline" id="Mendelian_randomization">Mendelian randomization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=24" title="Edit section: Mendelian randomization">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Definition: <a href="https://en.wikipedia.org/wiki/Mendelian_randomization" title="Mendelian randomization">Mendelian randomization</a> uses measured variation in genes of known function to examine the causal effect of a modifiable exposure on disease in <a href="https://en.wikipedia.org/wiki/Observational_studies" class="mw-redirect" title="Observational studies">observational studies</a>.<sup id="cite_ref-Katan1986_10-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-Katan1986-10">[10]</a></sup><sup id="cite_ref-11" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-11">[11]</a></sup>
</p><p>Because genes vary randomly across populations, presence of a gene typically qualifies as an instrumental variable, implying that in many cases, causality can be quantified using regression on an observational study.<sup id="cite_ref-:1_4-40" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 255">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA255">255</a></span></sup>
</p>
<h2><span class="mw-headline" id="Associations">Associations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=25" title="Edit section: Associations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Independence_conditions">Independence conditions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=26" title="Edit section: Independence conditions">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Independence conditions are rules for deciding whether two variables are independent of each other. Variables are independent if the values of one do not directly affect the values of the other. Multiple causal models can share independence conditions. For example, the models
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\rightarrow B\rightarrow C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\rightarrow B\rightarrow C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/87f249fd063cc3844f776d817c36127517f61dad" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.502ex; height:2.176ex;" alt="{\displaystyle A\rightarrow B\rightarrow C}"></span></dd></dl>
<p>and
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\leftarrow B\rightarrow C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\leftarrow B\rightarrow C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/d80def6621b44e39fc6e4507aa9cc77460c0c911" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.502ex; height:2.176ex;" alt="A\leftarrow B\rightarrow C"></span></dd></dl>
<p>have the same independence conditions, because conditioning on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> leaves <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span> independent. However, the two models do not have the same meaning and can be falsified based on data (that is, if observational data show an association between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span> after conditioning on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span>, then both models are incorrect). Conversely, data cannot show which of these two models are correct, because they have the same independence conditions.
</p><p>Conditioning on a variable is a mechanism for conducting hypothetical experiments. Conditioning on a variable involves analyzing the values of other variables for a given value of the conditioned variable. In the first example, conditioning on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> implies that observations for a given value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/47136aad860d145f75f3eed3022df827cee94d7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="B"></span> should show no dependence between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/7daff47fa58cdfd29dc333def748ff5fa4c923e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;" alt="A"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="C"></span>. If such a dependence exists, then the model is incorrect. Non-causal models cannot make such distinctions, because they do not make causal assertions.<sup id="cite_ref-:1_4-41" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 129130">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA129">129130</a></span></sup>
</p>
<h3><span id="Confounder.2Fdeconfounder"></span><span class="mw-headline" id="Confounder/deconfounder">Confounder/deconfounder</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=27" title="Edit section: Confounder/deconfounder">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>An essential element of correlational study design is to identify potentially confounding influences on the variable under study, such as demographics. These variables are controlled for to eliminate those influences. However, the correct list of confounding variables cannot be determined <i>a priori</i>. It is thus possible that a study may control for irrelevant variables or even (indirectly) the variable under study.<sup id="cite_ref-:1_4-42" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 139">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA139">139</a></span></sup>
</p><p>Causal models offer a robust technique for identifying appropriate confounding variables. Formally, Z is a confounder if "Y is associated with Z via paths not going through X". These can often be determined using data collected for other studies. Mathematically, if
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|X)\neq P(Y|do(X))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo><!--  --></mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|X)\neq P(Y|do(X))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/6999c4862fb65d283375512567f8ec64e8163b0c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:23.161ex; height:2.843ex;" alt="{\displaystyle P(Y|X)\neq P(Y|do(X))}"></span></dd></dl>
<p>X and Y are confounded (by some confounder variable Z).<sup id="cite_ref-:1_4-43" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 151">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA151">151</a></span></sup>
</p><p>Earlier, allegedly incorrect definitions of confounder include:<sup id="cite_ref-:1_4-44" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 152">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA152">152</a></span></sup>
</p>
<ul><li>"Any variable that is correlated with both X and Y."</li>
<li>Y is associated with Z among the unexposed.</li>
<li>Noncollapsibility: A difference between the "crude relative risk and the relative risk resulting after adjustment for the potential confounder".</li>
<li>Epidemiological: A variable associated with X in the population at large and associated with Y among people unexposed to X.</li></ul>
<p>The latter is flawed in that given that in the model:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X\rightarrow Z\rightarrow Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Z</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X\rightarrow Z\rightarrow Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/26d5dce699d6d6f1b61496e5737eaa3dc064717c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.662ex; height:2.176ex;" alt="{\displaystyle X\rightarrow Z\rightarrow Y}"></span></dd></dl>
<p>Z matches the definition, but is a mediator, not a confounder, and is an example of controlling for the outcome.
</p><p>In the model
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X\leftarrow A\rightarrow B\leftarrow C\rightarrow Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>A</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>B</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>C</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X\leftarrow A\rightarrow B\leftarrow C\rightarrow Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/62b0449a8bf51fb512d226c264fc1a242d1263a7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:23.483ex; height:2.176ex;" alt="{\displaystyle X\leftarrow A\rightarrow B\leftarrow C\rightarrow Y}"></span></dd></dl>
<p>Traditionally, B was considered to be a confounder, because it is associated with X and with Y but is not on a causal path nor is it a descendant of anything on a causal path. Controlling for B causes it to become a confounder. This is known as M-bias.<sup id="cite_ref-:1_4-45" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 161">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA161">161</a></span></sup>
</p>
<h4><span class="mw-headline" id="Backdoor_adjustment">Backdoor adjustment</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=28" title="Edit section: Backdoor adjustment">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>For analysing the causal effect of X on Y in a causal model all confounder variables must be addressed (deconfounding). To identify the set of confounders, (1) every noncausal path between X and Y must be blocked by this set; (2) without disrupting any causal paths; and (3) without creating any spurious paths.<sup id="cite_ref-:1_4-46" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 158">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA158">158</a></span></sup>
</p><p><b>Definition</b>: a backdoor path from variable X to Y is any path from X to Y that starts with an arrow pointing to X.<sup id="cite_ref-:1_4-47" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 158">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA158">158</a></span></sup>
</p><p><b>Definition</b>: Given an ordered pair of variables (X,Y) in a model, a set of confounder variables Z satisfies the backdoor criterion if (1) no confounder variable Z is a descendent of X and (2) all backdoor paths between X and Y are blocked by the set of confounders.
</p><p>If the backdoor criterion is satisfied for (X,Y), X and Y are deconfounded by the set of confounder variables. It is not necessary to control for any variables other than the confounders.<sup id="cite_ref-:1_4-48" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 158">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA158">158</a></span></sup> The backdoor criterion is a sufficient but not necessary condition to find a set of variables Z to decounfound the analysis of the causal effect of X on y.
</p><p>When the causal model is a plausible representation of reality and the backdoor criterion is satisfied, then partial regression coefficients can be used as (causal) path coefficients (for linear relationships).<sup id="cite_ref-:1_4-49" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 223">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA223">223</a></span></sup><sup id="cite_ref-FOOTNOTEPearl2009[httpbayescsuclaeduBOOK-2Kch3-3pdf_chapter_3-3_Controlling_Confounding_Bias]_12-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-FOOTNOTEPearl2009[httpbayescsuclaeduBOOK-2Kch3-3pdf_chapter_3-3_Controlling_Confounding_Bias]-12">[12]</a></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|do(X))=\textstyle \sum _{z}\displaystyle P(Y|X,Z=z)P(Z=z)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mstyle displaystyle="false" scriptlevel="0">
          <munder>
            <mo><!--  --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>z</mi>
            </mrow>
          </munder>
          <mstyle displaystyle="true" scriptlevel="0">
            <mi>P</mi>
            <mo stretchy="false">(</mo>
            <mi>Y</mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mo stretchy="false">|</mo>
            </mrow>
            <mi>X</mi>
            <mo>,</mo>
            <mi>Z</mi>
            <mo>=</mo>
            <mi>z</mi>
            <mo stretchy="false">)</mo>
            <mi>P</mi>
            <mo stretchy="false">(</mo>
            <mi>Z</mi>
            <mo>=</mo>
            <mi>z</mi>
            <mo stretchy="false">)</mo>
          </mstyle>
        </mstyle>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|do(X))=\textstyle \sum _{z}\displaystyle P(Y|X,Z=z)P(Z=z)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/b76a93a0d881715e6df2f54ffe68102ba4e56a44" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:43.326ex; height:3.009ex;" alt="{\displaystyle P(Y|do(X))=\textstyle \sum _{z}\displaystyle P(Y|X,Z=z)P(Z=z)}"></span><sup id="cite_ref-:1_4-50" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 227">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA227">227</a></span></sup></dd></dl>
<h4><span class="mw-headline" id="Frontdoor_adjustment">Frontdoor adjustment</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=29" title="Edit section: Frontdoor adjustment">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>If the elements of a blocking path are all unobservable, the backdoor path is not calculable, but if all forward paths from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X\to Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X\to Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/290b16963d52e4a7995aae01ee854b97a6ea10c0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:7.367ex; height:2.176ex;" alt="X\to Y"></span> have elements <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/bf368e72c009decd9b6686ee84a375632e11de98" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.088ex; height:1.676ex;" alt="z"></span> where no open paths connect <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle z\to Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>z</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle z\to Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/21b71e525f2ffaa1e000cd92b1902dafd1b5e078" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:6.476ex; height:2.176ex;" alt="{\displaystyle z\to Y}"></span>, then <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span>, the set of all <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/bf368e72c009decd9b6686ee84a375632e11de98" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.088ex; height:1.676ex;" alt="z"></span>s, can measure <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|do(X))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|do(X))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/115a9e1451cfaeb321df56cb9a208a2703f9cbcb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.108ex; height:2.843ex;" alt="{\displaystyle P(Y|do(X))}"></span>. Effectively, there are conditions where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span> can act as a proxy for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"></span>.
</p><p><b>Definition</b>: a frontdoor path is a direct causal path for which data is available for all <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle z\in Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>z</mi>
        <mo><!--  --></mo>
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle z\in Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/c3472db536f24864ab268d42ae277fcfc90d2998" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:5.609ex; height:2.176ex;" alt="z\in Z"></span>,<sup id="cite_ref-:1_4-51" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 226">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA226">226</a></span></sup> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span> intercepts all directed paths <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"></span> to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"></span>, there are no unblocked paths from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span> to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"></span>, and all backdoor paths from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Z}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1cc6b75e09a8aa3f04d8584b11db534f88fb56bd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.68ex; height:2.176ex;" alt="Z"></span> to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"></span> are blocked by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle X}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>X</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle X}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"></span>. 
<sup id="cite_ref-13" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-13">[13]</a></sup>
</p><p>The following converts a do expression into a do-free expression by conditioning on the variables along the front-door path.<sup id="cite_ref-:1_4-52" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 226">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA226">226</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|do(X))=\textstyle \sum _{z}\left[\displaystyle P(Z=z|X)\textstyle \sum _{x}\displaystyle P(Y|X=x,Z=z)P(X=x)\right]}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mstyle displaystyle="false" scriptlevel="0">
          <munder>
            <mo><!--  --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>z</mi>
            </mrow>
          </munder>
          <mrow>
            <mo>[</mo>
            <mstyle displaystyle="true" scriptlevel="0">
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <mi>Z</mi>
              <mo>=</mo>
              <mi>z</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mo stretchy="false">|</mo>
              </mrow>
              <mi>X</mi>
              <mo stretchy="false">)</mo>
              <mstyle displaystyle="false" scriptlevel="0">
                <munder>
                  <mo><!--  --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>x</mi>
                  </mrow>
                </munder>
                <mstyle displaystyle="true" scriptlevel="0">
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <mi>Y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo stretchy="false">|</mo>
                  </mrow>
                  <mi>X</mi>
                  <mo>=</mo>
                  <mi>x</mi>
                  <mo>,</mo>
                  <mi>Z</mi>
                  <mo>=</mo>
                  <mi>z</mi>
                  <mo stretchy="false">)</mo>
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <mi>X</mi>
                  <mo>=</mo>
                  <mi>x</mi>
                  <mo stretchy="false">)</mo>
                </mstyle>
              </mstyle>
            </mstyle>
            <mo>]</mo>
          </mrow>
        </mstyle>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|do(X))=\textstyle \sum _{z}\left[\displaystyle P(Z=z|X)\textstyle \sum _{x}\displaystyle P(Y|X=x,Z=z)P(X=x)\right]}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/c21d82865d8caf01dc46cfab09995fa1a7214053" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:66.038ex; height:3.009ex;" alt="{\displaystyle P(Y|do(X))=\textstyle \sum _{z}\left[\displaystyle P(Z=z|X)\textstyle \sum _{x}\displaystyle P(Y|X=x,Z=z)P(X=x)\right]}"></span></dd></dl>
<p>Presuming data for these observable probabilities is available, the ultimate probability can be computed without an experiment, regardless of the existence of other confounding paths and without backdoor adjustment.<sup id="cite_ref-:1_4-53" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 226">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA226">226</a></span></sup>
</p>
<h2><span class="mw-headline" id="Interventions">Interventions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=30" title="Edit section: Interventions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Queries">Queries</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=31" title="Edit section: Queries">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Queries are questions asked based on a specific model. They are generally answered via performing experiments (interventions). Interventions take the form of fixing the value of one variable in a model and observing the result. Mathematically, such queries take the form (from the example):<sup id="cite_ref-:1_4-54" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 8">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA8">8</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P({\text{floss}}\vline do({\text{toothpaste}}))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>floss</mtext>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mpadded height="0" depth="0">
            <mstyle mathsize="1.2em">
              <mo fence="false" stretchy="false">|<!-- | --></mo>
            </mstyle>
          </mpadded>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>toothpaste</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P({\text{floss}}\vline do({\text{toothpaste}}))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/53b881cbf7e9e6e0012498a5f5a55849f7d5b14d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.583ex; margin-top: -0.594ex; margin-bottom: -0.422ex; width:23.572ex; height:3.343ex;" alt="{\displaystyle P({\text{floss}}\vline do({\text{toothpaste}}))}"></span></dd></dl>
<p>where the <i>do</i> operator indicates that the experiment explicitly modified the price of toothpaste. Graphically, this blocks any causal factors that would otherwise affect that variable. Diagramatically, this erases all causal arrows pointing at the experimental variable.<sup id="cite_ref-:1_4-55" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 40">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA40">40</a></span></sup>
</p><p>More complex queries are possible, in which the do operator is applied (the value is fixed) to multiple variables.
</p>
<h3><span class="mw-headline" id="Do_calculus">Do calculus</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=32" title="Edit section: Do calculus">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The do calculus is the set of manipulations that are available to transform one expression into another, with the general goal of transforming expressions that contain the do operator into expressions that do not. Expressions that do not include the do operator can be estimated from observational data alone, without the need for an experimental intervention, which might be expensive, lengthy or even unethical (e.g., asking subjects to take up smoking).<sup id="cite_ref-:1_4-56" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 231">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA231">231</a></span></sup> The set of rules is complete (it can be used to derive every true statement in this system).<sup id="cite_ref-:1_4-57" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 237">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA237">237</a></span></sup> An algorithm can determine whether, for a given model, a solution is computable in <a href="https://en.wikipedia.org/wiki/Time_complexity" title="Time complexity">polynomial time</a>.<sup id="cite_ref-:1_4-58" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 238">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA238">238</a></span></sup>
</p>
<h4><span class="mw-headline" id="Rules">Rules</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=33" title="Edit section: Rules">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The calculus includes three rules for the transformation of conditional probability expressions involving the do operator.
</p>
<h5><span class="mw-headline" id="Rule_1">Rule 1</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=34" title="Edit section: Rule 1">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>Rule 1 permits the addition or deletion of observations.:<sup id="cite_ref-:1_4-59" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 235">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA235">235</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|do(X),Z,W)=P(Y|do(X),Z)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mi>Z</mi>
        <mo>,</mo>
        <mi>W</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mi>Z</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|do(X),Z,W)=P(Y|do(X),Z)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/a1a474e8821eb59ad7fdd79e4a0378caa50d5748" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:36.212ex; height:2.843ex;" alt="{\displaystyle P(Y|do(X),Z,W)=P(Y|do(X),Z)}"></span></dd></dl>
<p>in the case that the variable set Z blocks all paths from W to Y and all arrows leading into X have been deleted.<sup id="cite_ref-:1_4-60" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 234">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA234">234</a></span></sup>
</p>
<h5><span class="mw-headline" id="Rule_2">Rule 2</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=35" title="Edit section: Rule 2">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>Rule 2 permits the replacement of an intervention with an observation or vice versa.:<sup id="cite_ref-:1_4-61" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 235">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA235">235</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|do(X),Z)=P(Y|X,Z)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mi>Z</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>X</mi>
        <mo>,</mo>
        <mi>Z</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|do(X),Z)=P(Y|X,Z)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/cd33d75387007e291201b64a3d5ca109f3608a6f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:28.59ex; height:2.843ex;" alt="{\displaystyle P(Y|do(X),Z)=P(Y|X,Z)}"></span></dd></dl>
<p>in the case that Z satisfies the <a href="https://en.wikipedia.org/wiki/Causal_model#Deconfounding">back-door criterion</a>.<sup id="cite_ref-:1_4-62" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 234">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA234">234</a></span></sup>
</p>
<h5><span class="mw-headline" id="Rule_3">Rule 3</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=36" title="Edit section: Rule 3">edit</a><span class="mw-editsection-bracket">]</span></span></h5>
<p>Rule 3 permits the deletion or addition of interventions.:<sup id="cite_ref-:1_4-63" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P(Y|do(X))=P(Y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(Y|do(X))=P(Y)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/cc8aeb684d4210fc5594c74cf188e988ab9e9860" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:20.534ex; height:2.843ex;" alt="{\displaystyle P(Y|do(X))=P(Y)}"></span></dd></dl>
<p>in the case where no causal paths connect X and Y.<sup id="cite_ref-:1_4-64" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 234">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA234">234</a></span></sup> <sup class="reference nowrap"><span title="Page / location: 235">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA235">235</a></span></sup>
</p>
<h4><span class="mw-headline" id="Extensions">Extensions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=37" title="Edit section: Extensions">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The rules do not imply that any query can have its do operators removed. In those cases, it may be possible to substitute a variable that is subject to manipulation (e.g., diet) in place of one that is not (e.g., blood cholesterol), which can then be transformed to remove the do. Example:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle P({\text{Heart disease}}|do({\text{blood cholesterol}}))=P({\text{Heart disease}}|do({\text{diet}}))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>Heart disease</mtext>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>blood cholesterol</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>Heart disease</mtext>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>diet</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P({\text{Heart disease}}|do({\text{blood cholesterol}}))=P({\text{Heart disease}}|do({\text{diet}}))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/12ae00124d1134079c6381c59e55b0dc617b5b77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:67.23ex; height:2.843ex;" alt="{\displaystyle P({\text{Heart disease}}|do({\text{blood cholesterol}}))=P({\text{Heart disease}}|do({\text{diet}}))}"></span></dd></dl>
<h2><span class="mw-headline" id="Counterfactuals_2">Counterfactuals</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=38" title="Edit section: Counterfactuals">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Counterfactuals consider possibilities that are not found in data, such as whether a nonsmoker would have developed cancer had they instead been a heavy smoker. They are the highest step on Pearl's causality ladder.
</p>
<h3><span class="mw-headline" id="Potential_outcome">Potential outcome</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=39" title="Edit section: Potential outcome">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Definition: A potential outcome for a variable Y is "the value Y would have taken for individual<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="What is an individual in this context? (January 2019)">clarification needed</span></a></i>]</sup> <i>u</i>, had X been assigned the value x". Mathematically:<sup id="cite_ref-:1_4-65" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 270">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA270">270</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y_{X=x}(u)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>X</mi>
            <mo>=</mo>
            <mi>x</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>u</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y_{X=x}(u)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/9232d9247c561c9967aa09a8ad17d97a051ef596" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.341ex; height:2.843ex;" alt="{\displaystyle Y_{X=x}(u)}"></span> or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y_{x}(u)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>x</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>u</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y_{x}(u)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/42a2ead37df1d6c4dfc3a42b92b952391dda79da" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.662ex; height:2.843ex;" alt="{\displaystyle Y_{x}(u)}"></span>.</dd></dl>
<p>The potential outcome is defined at the level of the individual <i>u.<sup id="cite_ref-:1_4-66" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup></i><sup class="reference nowrap"><span title="Page / location: 270">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA270">270</a></span></sup>
</p><p>The conventional approach to potential outcomes is data-, not model-driven, limiting its ability to untangle causal relationships. It treats causal questions as problems of missing data and gives incorrect answers to even standard scenarios.<sup id="cite_ref-:1_4-67" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 275">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA275">275</a></span></sup>
</p>
<h3><span class="mw-headline" id="Causal_inference">Causal inference</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=40" title="Edit section: Causal inference">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In the context of causal models, potential outcomes are interpreted causally, rather than statistically.
</p><p>The first law of <a href="https://en.wikipedia.org/wiki/Causal_inference" title="Causal inference">causal inference</a> states that the potential outcome
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y_{X}(u)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>X</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>u</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y_{X}(u)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/73e867c243bb52dfbb1dd584ed4c6f8d14354e8c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.122ex; height:2.843ex;" alt="{\displaystyle Y_{X}(u)}"></span></dd></dl>
<p>can be computed by modifying causal model M (by deleting arrows into X) and computing the outcome for some <i>x</i>. Formally:<sup id="cite_ref-:1_4-68" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 280">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA280">280</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y_{X}(u)=Y_{Mx}(u)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>X</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>u</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mi>x</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>u</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y_{X}(u)=Y_{Mx}(u)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/e8a0bf8c55ce8f08e266a6e8330ddf0c3184412f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:16.609ex; height:2.843ex;" alt="{\displaystyle Y_{X}(u)=Y_{Mx}(u)}"></span></dd></dl>
<h3><span class="mw-headline" id="Conducting_a_counterfactual">Conducting a counterfactual</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=41" title="Edit section: Conducting a counterfactual">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Examining a counterfactual using a causal model involves three steps.<sup id="cite_ref-FOOTNOTEPearl2009207_14-0" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-FOOTNOTEPearl2009207-14">[14]</a></sup> The approach is valid regardless of the form of the model relationships, linear or otherwise. When the model relationships are fully specified, point values can be computed. In other cases (e.g., when only probabilities are available) a probability-interval statement, such as non-smoker <i>x</i> would have a 10-20% chance of cancer, can be computed.<sup id="cite_ref-:1_4-69" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 279">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA279">279</a></span></sup>
</p><p>Given the model:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y\leftarrow X\rightarrow M\rightarrow Y\leftarrow U}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>M</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>U</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y\leftarrow X\rightarrow M\rightarrow Y\leftarrow U}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/ab9de86d7fc1904998ef3b7868100c3e2ff75c58" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:24.208ex; height:2.176ex;" alt="{\displaystyle Y\leftarrow X\rightarrow M\rightarrow Y\leftarrow U}"></span></dd></dl>
<p>the equations for calculating the values of A and C derived from regression analysis or another technique can be applied, substituting known values from an observation and fixing the value of other variables (the counterfactual).<sup id="cite_ref-:1_4-70" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 278">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA278">278</a></span></sup>
</p>
<h4><span class="mw-headline" id="Abduct">Abduct</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=42" title="Edit section: Abduct">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Apply <a href="https://en.wikipedia.org/wiki/Abductive_reasoning" title="Abductive reasoning">abductive reasoning</a> (<a href="https://en.wikipedia.org/wiki/Logical_inference" class="mw-redirect" title="Logical inference">logical inference</a> that uses observation to find the simplest/most likely explanation) to estimate <i>u</i>, the proxy for the unobserved variables on the specific observation that supports the counterfactual.<sup id="cite_ref-:1_4-71" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 278">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA278">278</a></span></sup> Compute the probability of <i>u</i> given the propositional evidence.
</p>
<h4><span class="mw-headline" id="Act">Act</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=43" title="Edit section: Act">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>For a specific observation, use the do operator to establish the counterfactual (e.g., <i>m</i>=0), modifying the equations accordingly.<sup id="cite_ref-:1_4-72" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 278">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA278">278</a></span></sup>
</p>
<h4><span class="mw-headline" id="Predict">Predict</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=44" title="Edit section: Predict">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Calculate the values of the output (<i>y</i>) using the modified equations.<sup id="cite_ref-:1_4-73" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 278">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA278">278</a></span></sup>
</p>
<h3><span class="mw-headline" id="Mediation">Mediation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=45" title="Edit section: Mediation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Direct and indirect (mediated) causes can only be distinguished via conducting counterfactuals.<sup id="cite_ref-:1_4-74" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 301">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA301">301</a></span></sup> Understanding mediation requires holding the mediator constant while intervening on the direct cause. In the model
</p><p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y\leftarrow M\leftarrow X\rightarrow Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>M</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
        <mo stretchy="false"><!--  --></mo>
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y\leftarrow M\leftarrow X\rightarrow Y}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/aba71ebb7eb28bc61f6b2c4a695563f960973ede" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:18.811ex; height:2.176ex;" alt="{\displaystyle Y\leftarrow M\leftarrow X\rightarrow Y}"></span>
</p><p>M mediates X's influence on Y, while X also has an unmediated effect on Y. Thus M is held constant, while do(X) is computed.
</p><p>The Mediation Fallacy instead involves conditioning on the mediator if the mediator and the outcome are confounded, as they are in the above model.
</p><p>For linear models, the indirect effect can be computed by taking the product of all the path coefficients along a mediated pathway. The total indirect effect is computed by the sum of the individual indirect effects. For linear models mediation is indicated when the coefficients of an equation fitted without including the mediator vary significantly from an equation that includes it.<sup id="cite_ref-:1_4-75" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 324">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA324">324</a></span></sup>
</p>
<h4><span class="mw-headline" id="Direct_effect">Direct effect</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=46" title="Edit section: Direct effect">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In experiments on such a model, the controlled direct effect (CDE) is computed by forcing the value of the mediator M (do(M = 0)) and randomly assigning some subjects to each of the values of X (do(X=0), do(X=1), ...) and observing the resulting values of Y.<sup id="cite_ref-:1_4-76" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 317">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA317">317</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle CDE(0)=P(Y=1|do(X=1),do(M=0))-P(Y=1|do(X=0),do(M=0))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
        <mi>D</mi>
        <mi>E</mi>
        <mo stretchy="false">(</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo><!--  --></mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle CDE(0)=P(Y=1|do(X=1),do(M=0))-P(Y=1|do(X=0),do(M=0))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/65c88a0ab669424660409e2df2552c610c19387f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:79.416ex; height:2.843ex;" alt="{\displaystyle CDE(0)=P(Y=1|do(X=1),do(M=0))-P(Y=1|do(X=0),do(M=0))}"></span></dd></dl>
<p>Each value of the mediator has a corresponding CDE.
</p><p>However, a better experiment is to compute the natural direct effect. (NDE) This is the effect determined by leaving the relationship between X and M untouched while intervening on the relationship between X and Y.<sup id="cite_ref-:1_4-77" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 318">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA318">318</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle NDE=P(Y_{M=M0}=1|do(X=1))-P(Y_{M=M0}=1|do(X=0))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>N</mi>
        <mi>D</mi>
        <mi>E</mi>
        <mo>=</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>=</mo>
            <mi>M</mi>
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
        <mo><!--  --></mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>=</mo>
            <mi>M</mi>
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>d</mi>
        <mi>o</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle NDE=P(Y_{M=M0}=1|do(X=1))-P(Y_{M=M0}=1|do(X=0))}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/1f0f3392e40201345d13d323fa5a6b5ce727ce41" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:63.689ex; height:2.843ex;" alt="{\displaystyle NDE=P(Y_{M=M0}=1|do(X=1))-P(Y_{M=M0}=1|do(X=0))}"></span></dd></dl>
<p>For example, consider the direct effect of increasing <a href="https://en.wikipedia.org/wiki/Dental_hygienist" title="Dental hygienist">dental hygienist</a> visits (X) from every other year to every year, which encourages flossing (M). Gums (Y) get healthier, either because of the hygienist (direct) or the flossing (mediator/indirect). The experiment is to continue flossing while skipping the hygienist visit.
</p>
<h4><span class="mw-headline" id="Indirect_effect">Indirect effect</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=47" title="Edit section: Indirect effect">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The indirect effect of X on Y is the "increase we would see in Y while holding X constant and increasing M to whatever value M would attain under a unit increase in X".<sup id="cite_ref-:1_4-78" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 328">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA328">328</a></span></sup>
</p><p>Indirect effects cannot be "controlled" because the direct path cannot be disabled by holding another variable constant. The natural indirect effect (NIE) is the effect on gum health (Y) from flossing (M). The NIE is calculated as the sum of (floss and no-floss cases) of the difference between the probability of flossing given the hygienist and without the hygienist, or:<sup id="cite_ref-:1_4-79" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 321">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA321">321</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle NIE=\sum _{m}[P(M=m|X=1)-P(M=m|X=0)]xxP(Y=1|X=0,M=m)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>N</mi>
        <mi>I</mi>
        <mi>E</mi>
        <mo>=</mo>
        <munder>
          <mo><!--  --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>m</mi>
          </mrow>
        </munder>
        <mo stretchy="false">[</mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo>=</mo>
        <mi>m</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
        <mo><!--  --></mo>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>M</mi>
        <mo>=</mo>
        <mi>m</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mi>x</mi>
        <mi>x</mi>
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mi>M</mi>
        <mo>=</mo>
        <mi>m</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle NIE=\sum _{m}[P(M=m|X=1)-P(M=m|X=0)]xxP(Y=1|X=0,M=m)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/9fe79eecc141edce2e0047bd1cfd9316c73e7883" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:79.397ex; height:5.509ex;" alt="{\displaystyle NIE=\sum _{m}[P(M=m|X=1)-P(M=m|X=0)]xxP(Y=1|X=0,M=m)}"></span></dd></dl>
<p>The above NDE calculation includes counterfactual subscripts (<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle Y_{M=M0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>=</mo>
            <mi>M</mi>
            <mn>0</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y_{M=M0}}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/3f5de47d4d6733ad391edef4a958def757b24691" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.137ex; height:2.509ex;" alt="{\displaystyle Y_{M=M0}}"></span>). For nonlinear models, the seemingly obvious equivalence<sup id="cite_ref-:1_4-80" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 322">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA322">322</a></span></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\mathsf {Total\ effect=Direct\ effect+Indirect\ effect}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="sans-serif">T</mi>
            <mi mathvariant="sans-serif">o</mi>
            <mi mathvariant="sans-serif">t</mi>
            <mi mathvariant="sans-serif">a</mi>
            <mi mathvariant="sans-serif">l</mi>
            <mtext mathvariant="sans-serif">&nbsp;</mtext>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">c</mi>
            <mi mathvariant="sans-serif">t</mi>
            <mo mathvariant="sans-serif">=</mo>
            <mi mathvariant="sans-serif">D</mi>
            <mi mathvariant="sans-serif">i</mi>
            <mi mathvariant="sans-serif">r</mi>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">c</mi>
            <mi mathvariant="sans-serif">t</mi>
            <mtext mathvariant="sans-serif">&nbsp;</mtext>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">c</mi>
            <mi mathvariant="sans-serif">t</mi>
            <mo mathvariant="sans-serif">+</mo>
            <mi mathvariant="sans-serif">I</mi>
            <mi mathvariant="sans-serif">n</mi>
            <mi mathvariant="sans-serif">d</mi>
            <mi mathvariant="sans-serif">i</mi>
            <mi mathvariant="sans-serif">r</mi>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">c</mi>
            <mi mathvariant="sans-serif">t</mi>
            <mtext mathvariant="sans-serif">&nbsp;</mtext>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">c</mi>
            <mi mathvariant="sans-serif">t</mi>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\mathsf {Total\ effect=Direct\ effect+Indirect\ effect}}}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/d4675983a8772b342553a62452a2e8ab38edc19e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:42.834ex; height:2.343ex;" alt="{\displaystyle {\mathsf {Total\ effect=Direct\ effect+Indirect\ effect}}}"></span></dd></dl>
<p>does not apply because of anomalies such as threshold effects and binary values. However,
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\mathsf {Total\ effect}}(X=0\rightarrow X=1)=NDE(X=0\rightarrow X=1)-\ NIE(X=1\rightarrow X=0)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="sans-serif">T</mi>
            <mi mathvariant="sans-serif">o</mi>
            <mi mathvariant="sans-serif">t</mi>
            <mi mathvariant="sans-serif">a</mi>
            <mi mathvariant="sans-serif">l</mi>
            <mtext mathvariant="sans-serif">&nbsp;</mtext>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">f</mi>
            <mi mathvariant="sans-serif">e</mi>
            <mi mathvariant="sans-serif">c</mi>
            <mi mathvariant="sans-serif">t</mi>
          </mrow>
        </mrow>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>N</mi>
        <mi>D</mi>
        <mi>E</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
        <mo><!--  --></mo>
        <mtext>&nbsp;</mtext>
        <mi>N</mi>
        <mi>I</mi>
        <mi>E</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>1</mn>
        <mo stretchy="false"><!--  --></mo>
        <mi>X</mi>
        <mo>=</mo>
        <mn>0</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\mathsf {Total\ effect}}(X=0\rightarrow X=1)=NDE(X=0\rightarrow X=1)-\ NIE(X=1\rightarrow X=0)}</annotation>
  </semantics>
</math></span><img src="./Causal model - Wikipedia_files/a7ac43adc9c0b7825ea42114f153573d4ca4b540" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:82.401ex; height:2.843ex;" alt="{\displaystyle {\mathsf {Total\ effect}}(X=0\rightarrow X=1)=NDE(X=0\rightarrow X=1)-\ NIE(X=1\rightarrow X=0)}"></span></dd></dl>
<p>works for all model relationships (linear and nonlinear). It allows NDE to then be calculated directly from observational data, without interventions or use of counterfactual subscripts.<sup id="cite_ref-:1_4-81" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 326">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA326">326</a></span></sup>
</p>
<h2><span class="mw-headline" id="Transportability">Transportability</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=48" title="Edit section: Transportability">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Causal models provide a vehicle for integrating data across datasets, known as transport, even though the causal models (and the associated data) differ. E.g., survey data can be merged with randomized, controlled trial data.<sup id="cite_ref-:1_4-82" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 352">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA352">352</a></span></sup> Transport offers a solution to the question of <a href="https://en.wikipedia.org/wiki/External_validity" title="External validity">external validity</a>, whether a study can be applied in a different context.
</p><p>Where two models match on all relevant variables and data from one model is known to be unbiased, data from one population can be used to draw conclusions about the other. In other cases, where data is known to be biased, reweighting can allow the dataset to be transported. In a third case, conclusions can be drawn from an incomplete dataset. In some cases, data from studies of multiple populations can be combined (via transportation) to allow conclusions about an unmeasured population. In some cases, combining estimates (e.g., P(W|X)) from multiple studies can increase the precision of a conclusion.<sup id="cite_ref-:1_4-83" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 355">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA355">355</a></span></sup>
</p><p>Do-calculus provides a general criterion for transport: A target variable can be transformed into another expression via a series of do-operations that does not involve any "difference-producing" variables (those that distinguish the two populations).<sup id="cite_ref-:1_4-84" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 355">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA355">355</a></span></sup> An analogous rule applies to studies that have relevantly different participants.<sup id="cite_ref-:1_4-85" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 356">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA356">356</a></span></sup>
</p>
<h2><span class="mw-headline" id="Bayesian_network">Bayesian network</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=49" title="Edit section: Bayesian network">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Bayesian_network" title="Bayesian network">Bayesian network</a></div>
<p>Any causal model can be implemented as a Bayesian network. Bayesian networks can be used to provide the inverse probability of an event (given an outcome, what are the probabilities of a specific cause). This requires preparation of a conditional probability table, showing all possible inputs and outcomes with their associated probabilities.<sup id="cite_ref-:1_4-86" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 119">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA119">119</a></span></sup>
</p><p>For example, given a two variable model of Disease and Test (for the disease) the conditional probability table takes the form:<sup id="cite_ref-:1_4-87" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 117">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA117">117</a></span></sup> 
</p>
<table class="wikitable">

<caption>Probability of a positive test for a given disease

</caption>
<tbody><tr>
<th>
</th>
<th colspan="2">Test
</th></tr>

<tr>
<th>Disease
</th>
<th>Positive
</th>
<th>Negative
</th></tr>

<tr>
<td>Negative
</td>
<td>12
</td>
<td>88
</td></tr>

<tr>
<td>Positive
</td>
<td>73
</td>
<td>27
</td></tr></tbody></table>
<p>According to this table, when a patient does not have the disease, the probability of a positive test is 12%.
</p><p>While this is tractable for small problems, as the number of variables and their associated states increase, the probability table (and associated computation time) increases exponentially.<sup id="cite_ref-:1_4-88" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 121">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA121">121</a></span></sup>
</p><p>Bayesian networks are used commercially in applications such as wireless data error correction and DNA analysis.<sup id="cite_ref-:1_4-89" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-:1-4">[4]</a></sup><sup class="reference nowrap"><span title="Page / location: 122">:<a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ&amp;pg=PA122">122</a></span></sup>
</p>
<h2><span id="Invariants.2Fcontext"></span><span class="mw-headline" id="Invariants/context">Invariants/context</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=50" title="Edit section: Invariants/context">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A different conceptualization of causality involves the notion of invariant relationships. In the case of identifying handwritten digits, digit shape controls meaning, thus shape and meaning are the invariants. Changing the shape changes the meaning. Other properties do not (e.g., color). This invariance should carry across datasets generated in different contexts (the non-invariant properties form the context). Rather than learning (assessing causality) using pooled data sets, learning on one and testing on another can help distinguish variant from invariant properties.<sup id="cite_ref-15" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-15">[15]</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=51" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Bayesian_network#Causal_networks" title="Bayesian network">Causal network</a>  a <a href="https://en.wikipedia.org/wiki/Bayesian_network" title="Bayesian network">Bayesian network</a> with an explicit requirement that the relationships be causal</li>
<li><a href="https://en.wikipedia.org/wiki/Structural_equation_modeling" title="Structural equation modeling">Structural equation modeling</a>  a statistical technique for testing and estimating causal relations</li>
<li><a href="https://en.wikipedia.org/wiki/Path_analysis_(statistics)" title="Path analysis (statistics)">Path analysis (statistics)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bayesian_network" title="Bayesian network">Bayesian network</a></li>
<li><a href="https://en.wikipedia.org/wiki/Causal_map" title="Causal map">Causal map</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=52" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class="reflist">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-1" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1133582631">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><cite id="CITEREFKarl_Friston2009" class="citation journal cs1"><a href="https://en.wikipedia.org/wiki/Karl_Friston" class="mw-redirect" title="Karl Friston">Karl Friston</a> (Feb 2009). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2642881">"Causal Modelling and Brain Connectivity in Functional Magnetic Resonance Imaging"</a>. <i><a href="https://en.wikipedia.org/wiki/PLOS_Biology" title="PLOS Biology">PLOS Biology</a></i>. <b>7</b> (2): e1000033. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1371%2Fjournal.pbio.1000033">10.1371/journal.pbio.1000033</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&nbsp;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2642881">2642881</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/19226186">19226186</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PLOS+Biology&amp;rft.atitle=Causal+Modelling+and+Brain+Connectivity+in+Functional+Magnetic+Resonance+Imaging&amp;rft.volume=7&amp;rft.issue=2&amp;rft.pages=e1000033&amp;rft.date=2009-02&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2642881%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F19226186&amp;rft_id=info%3Adoi%2F10.1371%2Fjournal.pbio.1000033&amp;rft.au=Karl+Friston&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2642881&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-FOOTNOTEPearl2009-2"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-FOOTNOTEPearl2009_2-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-FOOTNOTEPearl2009_2-1"><sup><i><b>b</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-FOOTNOTEPearl2009_2-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="https://en.wikipedia.org/wiki/Causal_model#CITEREFPearl2009">Pearl 2009</a>.</span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-3" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFHitchcock2018" class="citation cs2">Hitchcock, Christopher (2018), <a rel="nofollow" class="external text" href="https://plato.stanford.edu/archives/fall2018/entries/causal-models/">"Causal Models"</a>,  in Zalta, Edward N. (ed.), <i>The Stanford Encyclopedia of Philosophy</i> (Fall 2018&nbsp;ed.), Metaphysics Research Lab, Stanford University<span class="reference-accessdate">, retrieved <span class="nowrap">2018-09-08</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Causal+Models&amp;rft.btitle=The+Stanford+Encyclopedia+of+Philosophy&amp;rft.edition=Fall+2018&amp;rft.pub=Metaphysics+Research+Lab%2C+Stanford+University&amp;rft.date=2018&amp;rft.aulast=Hitchcock&amp;rft.aufirst=Christopher&amp;rft_id=https%3A%2F%2Fplato.stanford.edu%2Farchives%2Ffall2018%2Fentries%2Fcausal-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:1-4"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-1"><sup><i><b>b</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-2"><sup><i><b>c</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-3"><sup><i><b>d</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-4"><sup><i><b>e</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-5"><sup><i><b>f</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-6"><sup><i><b>g</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-7"><sup><i><b>h</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-8"><sup><i><b>i</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-9"><sup><i><b>j</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-10"><sup><i><b>k</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-11"><sup><i><b>l</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-12"><sup><i><b>m</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-13"><sup><i><b>n</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-14"><sup><i><b>o</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-15"><sup><i><b>p</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-16"><sup><i><b>q</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-17"><sup><i><b>r</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-18"><sup><i><b>s</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-19"><sup><i><b>t</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-20"><sup><i><b>u</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-21"><sup><i><b>v</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-22"><sup><i><b>w</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-23"><sup><i><b>x</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-24"><sup><i><b>y</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-25"><sup><i><b>z</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-26"><sup><i><b>aa</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-27"><sup><i><b>ab</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-28"><sup><i><b>ac</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-29"><sup><i><b>ad</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-30"><sup><i><b>ae</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-31"><sup><i><b>af</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-32"><sup><i><b>ag</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-33"><sup><i><b>ah</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-34"><sup><i><b>ai</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-35"><sup><i><b>aj</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-36"><sup><i><b>ak</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-37"><sup><i><b>al</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-38"><sup><i><b>am</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-39"><sup><i><b>an</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-40"><sup><i><b>ao</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-41"><sup><i><b>ap</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-42"><sup><i><b>aq</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-43"><sup><i><b>ar</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-44"><sup><i><b>as</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-45"><sup><i><b>at</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-46"><sup><i><b>au</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-47"><sup><i><b>av</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-48"><sup><i><b>aw</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-49"><sup><i><b>ax</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-50"><sup><i><b>ay</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-51"><sup><i><b>az</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-52"><sup><i><b>ba</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-53"><sup><i><b>bb</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-54"><sup><i><b>bc</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-55"><sup><i><b>bd</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-56"><sup><i><b>be</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-57"><sup><i><b>bf</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-58"><sup><i><b>bg</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-59"><sup><i><b>bh</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-60"><sup><i><b>bi</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-61"><sup><i><b>bj</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-62"><sup><i><b>bk</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-63"><sup><i><b>bl</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-64"><sup><i><b>bm</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-65"><sup><i><b>bn</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-66"><sup><i><b>bo</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-67"><sup><i><b>bp</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-68"><sup><i><b>bq</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-69"><sup><i><b>br</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-70"><sup><i><b>bs</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-71"><sup><i><b>bt</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-72"><sup><i><b>bu</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-73"><sup><i><b>bv</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-74"><sup><i><b>bw</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-75"><sup><i><b>bx</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-76"><sup><i><b>by</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-77"><sup><i><b>bz</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-78"><sup><i><b>ca</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-79"><sup><i><b>cb</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-80"><sup><i><b>cc</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-81"><sup><i><b>cd</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-82"><sup><i><b>ce</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-83"><sup><i><b>cf</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-84"><sup><i><b>cg</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-85"><sup><i><b>ch</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-86"><sup><i><b>ci</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-87"><sup><i><b>cj</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-88"><sup><i><b>ck</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-:1_4-89"><sup><i><b>cl</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPearlMackenzie2018" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/Judea_Pearl" title="Judea Pearl">Pearl, Judea</a>; Mackenzie, Dana (2018-05-15). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=9H0dDQAAQBAJ"><i>The Book of Why: The New Science of Cause and Effect</i></a>. Basic Books. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780465097616" title="Special:BookSources/9780465097616"><bdi>9780465097616</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Book+of+Why%3A+The+New+Science+of+Cause+and+Effect&amp;rft.pub=Basic+Books&amp;rft.date=2018-05-15&amp;rft.isbn=9780465097616&amp;rft.aulast=Pearl&amp;rft.aufirst=Judea&amp;rft.au=Mackenzie%2C+Dana&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D9H0dDQAAQBAJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-5" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFOkasha2012" class="citation book cs1">Okasha, Samir (2012-01-12). <a rel="nofollow" class="external text" href="http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199279739.001.0001/oxfordhb-9780199279739-e-0036">"Causation in Biology"</a>.  In Beebee, Helen; Hitchcock, Christopher; Menzies, Peter (eds.). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=yWWEIvNgUQ4C&amp;pg=PA707"><i>The Oxford Handbook of Causation</i></a>. Vol.&nbsp;1. OUP Oxford. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Foxfordhb%2F9780199279739.001.0001">10.1093/oxfordhb/9780199279739.001.0001</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780191629464" title="Special:BookSources/9780191629464"><bdi>9780191629464</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Causation+in+Biology&amp;rft.btitle=The+Oxford+Handbook+of+Causation&amp;rft.pub=OUP+Oxford&amp;rft.date=2012-01-12&amp;rft_id=info%3Adoi%2F10.1093%2Foxfordhb%2F9780199279739.001.0001&amp;rft.isbn=9780191629464&amp;rft.aulast=Okasha&amp;rft.aufirst=Samir&amp;rft_id=http%3A%2F%2Fwww.oxfordhandbooks.com%2Fview%2F10.1093%2Foxfordhb%2F9780199279739.001.0001%2Foxfordhb-9780199279739-e-0036&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-6" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPearl2019" class="citation journal cs1">Pearl, Judea (29 Oct 2019). <a rel="nofollow" class="external text" href="https://ftp.cs.ucla.edu/pub/stat_ser/r485.pdf">"Causal and Counterfactual Inference"</a> <span class="cs1-format">(PDF)</span><span class="reference-accessdate">. Retrieved <span class="nowrap">14 December</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Causal+and+Counterfactual+Inference&amp;rft.date=2019-10-29&amp;rft.aulast=Pearl&amp;rft.aufirst=Judea&amp;rft_id=https%3A%2F%2Fftp.cs.ucla.edu%2Fpub%2Fstat_ser%2Fr485.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span> <span class="cs1-hidden-error citation-comment"><code class="cs1-code">{{<a href="https://en.wikipedia.org/wiki/Template:Cite_journal" title="Template:Cite journal">cite journal</a>}}</code>: </span><span class="cs1-hidden-error citation-comment">Cite journal requires <code class="cs1-code">|journal=</code> (<a href="https://en.wikipedia.org/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-7" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFEpp2004" class="citation book cs1">Epp, Susanna S. (2004). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=skIZAQAAIAAJ&amp;pg=PA25"><i>Discrete Mathematics with Applications</i></a>. Thomson-Brooks/Cole. pp.&nbsp;2526. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780534359454" title="Special:BookSources/9780534359454"><bdi>9780534359454</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Discrete+Mathematics+with+Applications&amp;rft.pages=25-26&amp;rft.pub=Thomson-Brooks%2FCole&amp;rft.date=2004&amp;rft.isbn=9780534359454&amp;rft.aulast=Epp&amp;rft.aufirst=Susanna+S.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DskIZAQAAIAAJ%26pg%3DPA25&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-CR-8"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-CR_8-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-CR_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.istarassessment.org/srdims/causal-reasoning-2/">"Causal Reasoning"</a>. <i>www.istarassessment.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2 March</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.istarassessment.org&amp;rft.atitle=Causal+Reasoning&amp;rft_id=http%3A%2F%2Fwww.istarassessment.org%2Fsrdims%2Fcausal-reasoning-2%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Riegelman-9"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-Riegelman_9-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFRiegelman1979" class="citation journal cs1">Riegelman, R. (1979). "Contributory cause: Unnecessary and insufficient". <i>Postgraduate Medicine</i>. <b>66</b> (2): 177179. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1080%2F00325481.1979.11715231">10.1080/00325481.1979.11715231</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/450828">450828</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Postgraduate+Medicine&amp;rft.atitle=Contributory+cause%3A+Unnecessary+and+insufficient&amp;rft.volume=66&amp;rft.issue=2&amp;rft.pages=177-179&amp;rft.date=1979&amp;rft_id=info%3Adoi%2F10.1080%2F00325481.1979.11715231&amp;rft_id=info%3Apmid%2F450828&amp;rft.aulast=Riegelman&amp;rft.aufirst=R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Katan1986-10"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-Katan1986_10-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFKatan_MB1986" class="citation journal cs1">Katan MB (March 1986). "Apolipoprotein E isoforms, serum cholesterol, and cancer". <i>Lancet</i>. <b>1</b> (8479): 5078. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0140-6736%2886%2992972-7">10.1016/s0140-6736(86)92972-7</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/2869248">2869248</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:38327985">38327985</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Lancet&amp;rft.atitle=Apolipoprotein+E+isoforms%2C+serum+cholesterol%2C+and+cancer&amp;rft.volume=1&amp;rft.issue=8479&amp;rft.pages=507-8&amp;rft.date=1986-03&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A38327985%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F2869248&amp;rft_id=info%3Adoi%2F10.1016%2Fs0140-6736%2886%2992972-7&amp;rft.au=Katan+MB&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-11" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFSmithEbrahim2008" class="citation book cs1">Smith, George Davey; Ebrahim, Shah (2008). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/books/NBK62433/"><i>Mendelian Randomization: Genetic Variants as Instruments for Strengthening Causal Inference in Observational Studies</i></a>. National Academies Press (US).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mendelian+Randomization%3A+Genetic+Variants+as+Instruments+for+Strengthening+Causal+Inference+in+Observational+Studies&amp;rft.pub=National+Academies+Press+%28US%29&amp;rft.date=2008&amp;rft.aulast=Smith&amp;rft.aufirst=George+Davey&amp;rft.au=Ebrahim%2C+Shah&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fbooks%2FNBK62433%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-FOOTNOTEPearl2009[httpbayescsuclaeduBOOK-2Kch3-3pdf_chapter_3-3_Controlling_Confounding_Bias]-12"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-FOOTNOTEPearl2009[httpbayescsuclaeduBOOK-2Kch3-3pdf_chapter_3-3_Controlling_Confounding_Bias]_12-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><a href="https://en.wikipedia.org/wiki/Causal_model#CITEREFPearl2009">Pearl 2009</a>, <a rel="nofollow" class="external text" href="http://bayes.cs.ucla.edu/BOOK-2K/ch3-3.pdf">chapter 3-3 Controlling Confounding Bias</a>.</span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-13" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPearlGlymourJewell2016" class="citation book cs1">Pearl, Judea; Glymour, Madelyn; Jewell, Nicholas P (7 March 2016). <i>Causal Inference in Statistics: A Primer</i>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-119-18684-7" title="Special:BookSources/978-1-119-18684-7"><bdi>978-1-119-18684-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Causal+Inference+in+Statistics%3A+A+Primer&amp;rft.date=2016-03-07&amp;rft.isbn=978-1-119-18684-7&amp;rft.aulast=Pearl&amp;rft.aufirst=Judea&amp;rft.au=Glymour%2C+Madelyn&amp;rft.au=Jewell%2C+Nicholas+P&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
<li id="cite_note-FOOTNOTEPearl2009207-14"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-FOOTNOTEPearl2009207_14-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><a href="https://en.wikipedia.org/wiki/Causal_model#CITEREFPearl2009">Pearl 2009</a>, p.&nbsp;207.</span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-15" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFHao2019" class="citation web cs1">Hao, Karen (May 8, 2019). <a rel="nofollow" class="external text" href="https://www.technologyreview.com/s/613502/deep-learning-could-reveal-why-the-world-works-the-way-it-does/">"Deep learning could reveal why the world works the way it does"</a>. <i>MIT Technology Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">February 10,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=Deep+learning+could+reveal+why+the+world+works+the+way+it+does&amp;rft.date=2019-05-08&amp;rft.aulast=Hao&amp;rft.aufirst=Karen&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F613502%2Fdeep-learning-could-reveal-why-the-world-works-the-way-it-does%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="Sources">Sources</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=53" title="Edit section: Sources">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPearl2009" class="citation book cs1">Pearl, Judea (2009-09-14). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=LLkhAwAAQBAJ"><i>Causality</i></a>. Cambridge University Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9781139643986" title="Special:BookSources/9781139643986"><bdi>9781139643986</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Causality&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2009-09-14&amp;rft.isbn=9781139643986&amp;rft.aulast=Pearl&amp;rft.aufirst=Judea&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DLLkhAwAAQBAJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;action=edit&amp;section=54" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFPearl2010" class="citation journal cs1">Pearl, Judea (2010-02-26). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2836213">"An Introduction to Causal Inference"</a>. <i>The International Journal of Biostatistics</i>. <b>6</b> (2): Article 7. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2202%2F1557-4679.1203">10.2202/1557-4679.1203</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1557-4679">1557-4679</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&nbsp;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2836213">2836213</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/20305706">20305706</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+International+Journal+of+Biostatistics&amp;rft.atitle=An+Introduction+to+Causal+Inference&amp;rft.volume=6&amp;rft.issue=2&amp;rft.pages=Article+7&amp;rft.date=2010-02-26&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2836213%23id-name%3DPMC&amp;rft.issn=1557-4679&amp;rft_id=info%3Apmid%2F20305706&amp;rft_id=info%3Adoi%2F10.2202%2F1557-4679.1203&amp;rft.aulast=Pearl&amp;rft.aufirst=Judea&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2836213&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></li>
<li><a rel="nofollow" class="external text" href="https://philpapers.org/browse/causal-modeling">Causal modeling</a> at <a href="https://en.wikipedia.org/wiki/PhilPapers" title="PhilPapers">PhilPapers</a></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFFalk2019" class="citation magazine cs1">Falk, Dan (2019-03-17). <a rel="nofollow" class="external text" href="https://www.quantamagazine.org/how-artificial-intelligence-is-changing-science-20190311/">"AI Algorithms Are Now Shockingly Good at Doing Science"</a>. <i>Wired</i>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1059-1028">1059-1028</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-03-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=AI+Algorithms+Are+Now+Shockingly+Good+at+Doing+Science&amp;rft.date=2019-03-17&amp;rft.issn=1059-1028&amp;rft.aulast=Falk&amp;rft.aufirst=Dan&amp;rft_id=https%3A%2F%2Fwww.quantamagazine.org%2Fhow-artificial-intelligence-is-changing-science-20190311%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFMaudlin2019" class="citation web cs1">Maudlin, Tim (2019-08-30). <a rel="nofollow" class="external text" href="https://bostonreview.net/science-nature/tim-maudlin-why-world">"The Why of the World"</a>. <i>Boston Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Boston+Review&amp;rft.atitle=The+Why+of+the+World&amp;rft.date=2019-08-30&amp;rft.aulast=Maudlin&amp;rft.aufirst=Tim&amp;rft_id=https%3A%2F%2Fbostonreview.net%2Fscience-nature%2Ftim-maudlin-why-world&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite id="CITEREFHartnett2018" class="citation web cs1">Hartnett, Kevin (15 May 2018). <a rel="nofollow" class="external text" href="https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/">"To Build Truly Intelligent Machines, Teach Them Cause and Effect"</a>. <i>Quanta Magazine</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-09-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Quanta+Magazine&amp;rft.atitle=To+Build+Truly+Intelligent+Machines%2C+Teach+Them+Cause+and+Effect&amp;rft.date=2018-05-15&amp;rft.aulast=Hartnett&amp;rft.aufirst=Kevin&amp;rft_id=https%3A%2F%2Fwww.quantamagazine.org%2Fto-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></li>
<li><sup id="cite_ref-16" class="reference"><a href="https://en.wikipedia.org/wiki/Causal_model#cite_note-16">[1]</a></sup></li></ul>
<div class="mw-references-wrap"><ol class="references">
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Causal_model#cite_ref-16" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1133582631"><cite class="citation cs2"><a rel="nofollow" class="external text" href="https://www.facebook.com/iclr.cc/videos/534780673594799"><i>Learning Representations using Causal Invariance</i></a>, ICLR, February 2020<span class="reference-accessdate">, retrieved <span class="nowrap">2020-02-10</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Learning+Representations+using+Causal+Invariance&amp;rft.pub=ICLR&amp;rft.date=2020-02&amp;rft_id=https%3A%2F%2Fwww.facebook.com%2Ficlr.cc%2Fvideos%2F534780673594799&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACausal+model" class="Z3988"></span></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Parsed by mw2369
Cached time: 20230211210441
Cache expiry: 1814400
Reduced expiry: false
Complications: [varyrevisionsha1, showtoc]
CPU time usage: 0.929 seconds
Real time usage: 1.158 seconds
Preprocessor visited node count: 23657/1000000
Postexpand include size: 160287/2097152 bytes
Template argument size: 50502/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip postexpand size: 67839/5000000 bytes
Lua time usage: 0.404/10.000 seconds
Lua memory usage: 9799388/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  872.718      1 -total
 41.71%  364.011     71 Template:Rp
 40.22%  351.043     71 Template:R/superscript
 21.99%  191.921    213 Template:R/where
 17.74%  154.862      1 Template:Reflist
 10.63%   92.767      5 Template:Cite_journal
  7.83%   68.351     11 Template:Clarify
  6.82%   59.550     11 Template:Fix-span
  6.09%   53.151      1 Template:Short_description
  4.98%   43.489      5 Template:Sfn
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:6672748-0!canonical and timestamp 20230211210439 and revision id 1134560543. Rendering was triggered because: page-view
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> --><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Causal_model&amp;oldid=1134560543">https://en.wikipedia.org/w/index.php?title=Causal_model&amp;oldid=1134560543</a>"</div></div>
					<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="https://en.wikipedia.org/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="https://en.wikipedia.org/wiki/Category:Causal_diagrams" title="Category:Causal diagrams">Causal diagrams</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Causality" title="Category:Causality">Causality</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Formal_epistemology" title="Category:Formal epistemology">Formal epistemology</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Scientific_models" title="Category:Scientific models">Scientific models</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="https://en.wikipedia.org/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_rewrite_from_March_2020" title="Category:Wikipedia articles needing rewrite from March 2020">Wikipedia articles needing rewrite from March 2020</a></li><li><a href="https://en.wikipedia.org/wiki/Category:All_articles_needing_rewrite" title="Category:All articles needing rewrite">All articles needing rewrite</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_clarification_from_January_2019" title="Category:Wikipedia articles needing clarification from January 2019">Wikipedia articles needing clarification from January 2019</a></li></ul></div></div>
					
				</div>
				
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" role="contentinfo">
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 19 January 2023, at 08:01<span class="anonymous-show">&nbsp;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a rel="license" href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License 3.0</a><a rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="https://foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="https://foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia is a registered trademark of the <a href="https://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="https://en.wikipedia.org/wiki/Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimers"><a href="https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-mobileview"><a href="https://en.m.wikipedia.org/w/index.php?title=Causal_model&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	<li id="footer-places-developers"><a href="https://developer.wikimedia.org/">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
<li style="display: none;"><a href="https://en.wikipedia.org/wiki/Causal_model#">Edit preview settings</a></li></ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="./Causal model - Wikipedia_files/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy"></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="./Causal model - Wikipedia_files/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"></a></li>
</ul>

</footer>

		</div>
	</div> 
</div> 

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.929","walltime":"1.158","ppvisitednodes":{"value":23657,"limit":1000000},"postexpandincludesize":{"value":160287,"limit":2097152},"templateargumentsize":{"value":50502,"limit":2097152},"expansiondepth":{"value":17,"limit":100},"expensivefunctioncount":{"value":3,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":67839,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  872.718      1 -total"," 41.71%  364.011     71 Template:Rp"," 40.22%  351.043     71 Template:R/superscript"," 21.99%  191.921    213 Template:R/where"," 17.74%  154.862      1 Template:Reflist"," 10.63%   92.767      5 Template:Cite_journal","  7.83%   68.351     11 Template:Clarify","  6.82%   59.550     11 Template:Fix-span","  6.09%   53.151      1 Template:Short_description","  4.98%   43.489      5 Template:Sfn"]},"scribunto":{"limitreport-timeusage":{"value":"0.404","limit":"10.000"},"limitreport-memusage":{"value":9799388,"limit":52428800},"limitreport-logs":"anchor_id_list = table#1 {\n    [\"CITEREFEpp2004\"] = 1,\n    [\"CITEREFFalk2019\"] = 1,\n    [\"CITEREFHao2019\"] = 1,\n    [\"CITEREFHartnett2018\"] = 1,\n    [\"CITEREFHitchcock2018\"] = 1,\n    [\"CITEREFKarl_Friston2009\"] = 1,\n    [\"CITEREFKatan_MB1986\"] = 1,\n    [\"CITEREFMaudlin2019\"] = 1,\n    [\"CITEREFOkasha2012\"] = 1,\n    [\"CITEREFPearl2009\"] = 1,\n    [\"CITEREFPearl2010\"] = 1,\n    [\"CITEREFPearl2019\"] = 1,\n    [\"CITEREFPearlGlymourJewell2016\"] = 1,\n    [\"CITEREFPearlMackenzie2018\"] = 1,\n    [\"CITEREFRiegelman1979\"] = 1,\n    [\"CITEREFSmithEbrahim2008\"] = 1,\n}\ntemplate_list = table#1 {\n    [\"Citation\"] = 2,\n    [\"Cite book\"] = 6,\n    [\"Cite journal\"] = 5,\n    [\"Cite magazine\"] = 1,\n    [\"Cite web\"] = 4,\n    [\"Clarify\"] = 11,\n    [\"Cleanup rewrite\"] = 1,\n    [\"DEFAULTSORT:Causal Model\"] = 1,\n    [\"Google books\"] = 75,\n    [\"Main\"] = 1,\n    [\"PhilPapers\"] = 1,\n    [\"Quote\"] = 1,\n    [\"Reflist\"] = 1,\n    [\"Rp\"] = 71,\n    [\"Sfn\"] = 5,\n    [\"Short description\"] = 1,\n    [\"Toclimit\"] = 1,\n}\narticle_whitelist = table#1 {\n}\n"},"cachereport":{"origin":"mw2369","timestamp":"20230211210441","ttl":1814400,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Causal model","url":"https:\/\/en.wikipedia.org\/wiki\/Causal_model","sameAs":"http:\/\/www.wikidata.org\/entity\/Q5054567","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q5054567","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2006-08-25T00:50:27Z","dateModified":"2023-01-19T08:01:53Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/1f\/Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png","headline":"abstract model that describes the causal mechanisms, rather than mere correlations, of a system"}</script><script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Causal model","url":"https:\/\/en.wikipedia.org\/wiki\/Causal_model","sameAs":"http:\/\/www.wikidata.org\/entity\/Q5054567","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q5054567","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2006-08-25T00:50:27Z","dateModified":"2023-01-19T08:01:53Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/1f\/Diagram_of_Dynamic_Causal_Modelling_-_Causal_Modelling_and_Brain_Connectivity_in_Functional_Magnetic_Resonance_Imaging_by_Karl_Friston.png","headline":"abstract model that describes the causal mechanisms, rather than mere correlations, of a system"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":101,"wgHostname":"mw2406"});});</script>

<button title="Toggle limited content width" aria-hidden="true" class="mw-ui-icon mw-ui-icon-element mw-ui-button vector-limited-width-toggle" data-event-name="limited-width-toggle-off">Toggle limited content width</button><div id="p-namespaces" style="display: none;"><ul></ul></div><a accesskey="v" href="https://en.wikipedia.org/wiki/Causal_model?action=edit#Do_calculus" class="oo-ui-element-hidden"></a></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>